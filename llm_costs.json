[
  {
    "model": "gpt-4.1",
    "provider": "openai",
    "input": 2e-06,
    "output": 8e-06,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "gpt-4.1-2025-04-14",
    "provider": "openai",
    "input": 2e-06,
    "output": 8e-06,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "gpt-4.1-mini",
    "provider": "openai",
    "input": 4e-07,
    "output": 1.6e-06,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "gpt-4.1-mini-2025-04-14",
    "provider": "openai",
    "input": 4e-07,
    "output": 1.6e-06,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "gpt-4.1-nano",
    "provider": "openai",
    "input": 1e-07,
    "output": 4e-07,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "gpt-4.1-nano-2025-04-14",
    "provider": "openai",
    "input": 1e-07,
    "output": 4e-07,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "gpt-4o",
    "provider": "openai",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-search-preview-2025-03-11",
    "provider": "openai",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-search-preview",
    "provider": "openai",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4.5-preview",
    "provider": "openai",
    "input": 7.5e-05,
    "output": 0.00015,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4.5-preview-2025-02-27",
    "provider": "openai",
    "input": 7.5e-05,
    "output": 0.00015,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-audio-preview",
    "provider": "openai",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-audio-preview-2024-12-17",
    "provider": "openai",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-audio-preview-2024-10-01",
    "provider": "openai",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-mini-audio-preview-2024-12-17",
    "provider": "openai",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-mini",
    "provider": "openai",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-mini-search-preview-2025-03-11",
    "provider": "openai",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-mini-search-preview",
    "provider": "openai",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-mini-2024-07-18",
    "provider": "openai",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "o1-pro",
    "provider": "openai",
    "input": 0.00015,
    "output": 0.0006,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "o1-pro-2025-03-19",
    "provider": "openai",
    "input": 0.00015,
    "output": 0.0006,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "o1",
    "provider": "openai",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "o1-mini",
    "provider": "openai",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536
  },
  {
    "model": "o3",
    "provider": "openai",
    "input": 1e-05,
    "output": 4e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "o3-2025-04-16",
    "provider": "openai",
    "input": 1e-05,
    "output": 4e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "o3-mini",
    "provider": "openai",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "o3-mini-2025-01-31",
    "provider": "openai",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "o4-mini",
    "provider": "openai",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "o4-mini-2025-04-16",
    "provider": "openai",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "o1-mini-2024-09-12",
    "provider": "openai",
    "input": 3e-06,
    "output": 1.2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536
  },
  {
    "model": "o1-preview",
    "provider": "openai",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768
  },
  {
    "model": "o1-preview-2024-09-12",
    "provider": "openai",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768
  },
  {
    "model": "o1-2024-12-17",
    "provider": "openai",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "chatgpt-4o-latest",
    "provider": "openai",
    "input": 5e-06,
    "output": 1.5e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4o-2024-05-13",
    "provider": "openai",
    "input": 5e-06,
    "output": 1.5e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4o-2024-08-06",
    "provider": "openai",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-2024-11-20",
    "provider": "openai",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "gpt-4o-realtime-preview-2024-10-01",
    "provider": "openai",
    "input": 5e-06,
    "output": 2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4o-realtime-preview",
    "provider": "openai",
    "input": 5e-06,
    "output": 2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4o-realtime-preview-2024-12-17",
    "provider": "openai",
    "input": 5e-06,
    "output": 2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4o-mini-realtime-preview",
    "provider": "openai",
    "input": 6e-07,
    "output": 2.4e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4o-mini-realtime-preview-2024-12-17",
    "provider": "openai",
    "input": 6e-07,
    "output": 2.4e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4-turbo-preview",
    "provider": "openai",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4-turbo",
    "provider": "openai",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4-turbo-2024-04-09",
    "provider": "openai",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4-1106-preview",
    "provider": "openai",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4-0125-preview",
    "provider": "openai",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4-vision-preview",
    "provider": "openai",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "gpt-4-1106-vision-preview",
    "provider": "openai",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "ft:gpt-4o-2024-08-06",
    "provider": "openai",
    "input": 3.75e-06,
    "output": 1.5e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "ft:gpt-4o-2024-11-20",
    "provider": "openai",
    "input": 3.75e-06,
    "output": 1.5e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "ft:gpt-4o-mini-2024-07-18",
    "provider": "openai",
    "input": 3e-07,
    "output": 1.2e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/gpt-4o-audio-preview-2024-12-17",
    "provider": "azure",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/gpt-4o-mini-audio-preview-2024-12-17",
    "provider": "azure",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/gpt-4.1",
    "provider": "azure",
    "input": 2e-06,
    "output": 8e-06,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "azure/gpt-4.1-2025-04-14",
    "provider": "azure",
    "input": 2e-06,
    "output": 8e-06,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "azure/gpt-4.1-mini",
    "provider": "azure",
    "input": 4e-07,
    "output": 1.6e-06,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "azure/gpt-4.1-mini-2025-04-14",
    "provider": "azure",
    "input": 4e-07,
    "output": 1.6e-06,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "azure/gpt-4.1-nano",
    "provider": "azure",
    "input": 1e-07,
    "output": 4e-07,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "azure/gpt-4.1-nano-2025-04-14",
    "provider": "azure",
    "input": 1e-07,
    "output": 4e-07,
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768
  },
  {
    "model": "azure/o3",
    "provider": "azure",
    "input": 1e-05,
    "output": 4e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/o3-2025-04-16",
    "provider": "azure",
    "input": 1e-05,
    "output": 4e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/o4-mini",
    "provider": "azure",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/gpt-4o-mini-realtime-preview-2024-12-17",
    "provider": "azure",
    "input": 6e-07,
    "output": 2.4e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17",
    "provider": "azure",
    "input": 6.6e-07,
    "output": 2.64e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/us/gpt-4o-mini-realtime-preview-2024-12-17",
    "provider": "azure",
    "input": 6.6e-07,
    "output": 2.64e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/gpt-4o-realtime-preview-2024-12-17",
    "provider": "azure",
    "input": 5e-06,
    "output": 2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/us/gpt-4o-realtime-preview-2024-12-17",
    "provider": "azure",
    "input": 5.5e-06,
    "output": 2.2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/eu/gpt-4o-realtime-preview-2024-12-17",
    "provider": "azure",
    "input": 5.5e-06,
    "output": 2.2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/gpt-4o-realtime-preview-2024-10-01",
    "provider": "azure",
    "input": 5e-06,
    "output": 2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/us/gpt-4o-realtime-preview-2024-10-01",
    "provider": "azure",
    "input": 5.5e-06,
    "output": 2.2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/eu/gpt-4o-realtime-preview-2024-10-01",
    "provider": "azure",
    "input": 5.5e-06,
    "output": 2.2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/o4-mini-2025-04-16",
    "provider": "azure",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/o3-mini-2025-01-31",
    "provider": "azure",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/us/o3-mini-2025-01-31",
    "provider": "azure",
    "input": 1.21e-06,
    "output": 4.84e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/eu/o3-mini-2025-01-31",
    "provider": "azure",
    "input": 1.21e-06,
    "output": 4.84e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/o3-mini",
    "provider": "azure",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/o1-mini",
    "provider": "azure",
    "input": 1.21e-06,
    "output": 4.84e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536
  },
  {
    "model": "azure/o1-mini-2024-09-12",
    "provider": "azure",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536
  },
  {
    "model": "azure/us/o1-mini-2024-09-12",
    "provider": "azure",
    "input": 1.21e-06,
    "output": 4.84e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536
  },
  {
    "model": "azure/eu/o1-mini-2024-09-12",
    "provider": "azure",
    "input": 1.21e-06,
    "output": 4.84e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536
  },
  {
    "model": "azure/o1",
    "provider": "azure",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/o1-2024-12-17",
    "provider": "azure",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/us/o1-2024-12-17",
    "provider": "azure",
    "input": 1.65e-05,
    "output": 6.6e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/eu/o1-2024-12-17",
    "provider": "azure",
    "input": 1.65e-05,
    "output": 6.6e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "azure/o1-preview",
    "provider": "azure",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768
  },
  {
    "model": "azure/o1-preview-2024-09-12",
    "provider": "azure",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768
  },
  {
    "model": "azure/us/o1-preview-2024-09-12",
    "provider": "azure",
    "input": 1.65e-05,
    "output": 6.6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768
  },
  {
    "model": "azure/eu/o1-preview-2024-09-12",
    "provider": "azure",
    "input": 1.65e-05,
    "output": 6.6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768
  },
  {
    "model": "azure/gpt-4.5-preview",
    "provider": "azure",
    "input": 7.5e-05,
    "output": 0.00015,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/gpt-4o",
    "provider": "azure",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/global/gpt-4o-2024-11-20",
    "provider": "azure",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/gpt-4o-2024-08-06",
    "provider": "azure",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/global/gpt-4o-2024-08-06",
    "provider": "azure",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/gpt-4o-2024-11-20",
    "provider": "azure",
    "input": 2.75e-06,
    "output": 1.1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/us/gpt-4o-2024-11-20",
    "provider": "azure",
    "input": 2.75e-06,
    "output": 1.1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/eu/gpt-4o-2024-11-20",
    "provider": "azure",
    "input": 2.75e-06,
    "output": 1.1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/gpt-4o-2024-05-13",
    "provider": "azure",
    "input": 5e-06,
    "output": 1.5e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/global-standard/gpt-4o-2024-08-06",
    "provider": "azure",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/us/gpt-4o-2024-08-06",
    "provider": "azure",
    "input": 2.75e-06,
    "output": 1.1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/eu/gpt-4o-2024-08-06",
    "provider": "azure",
    "input": 2.75e-06,
    "output": 1.1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/global-standard/gpt-4o-2024-11-20",
    "provider": "azure",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/global-standard/gpt-4o-mini",
    "provider": "azure",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/gpt-4o-mini",
    "provider": "azure",
    "input": 1.65e-07,
    "output": 6.6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/gpt-4o-mini-2024-07-18",
    "provider": "azure",
    "input": 1.65e-07,
    "output": 6.6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/us/gpt-4o-mini-2024-07-18",
    "provider": "azure",
    "input": 1.65e-07,
    "output": 6.6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/eu/gpt-4o-mini-2024-07-18",
    "provider": "azure",
    "input": 1.65e-07,
    "output": 6.6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "azure/gpt-4-turbo-2024-04-09",
    "provider": "azure",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/gpt-4-0125-preview",
    "provider": "azure",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/gpt-4-1106-preview",
    "provider": "azure",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/gpt-4-turbo",
    "provider": "azure",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/gpt-4-turbo-vision-preview",
    "provider": "azure",
    "input": 1e-05,
    "output": 3e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure/command-r-plus",
    "provider": "azure",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/deepseek-r1",
    "provider": "azure_ai",
    "input": 1.35e-06,
    "output": 5.4e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192
  },
  {
    "model": "azure_ai/deepseek-v3",
    "provider": "azure_ai",
    "input": 1.14e-06,
    "output": 4.56e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192
  },
  {
    "model": "azure_ai/mistral-nemo",
    "provider": "azure_ai",
    "input": 1.5e-07,
    "output": 1.5e-07,
    "max_input_tokens": 131072,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/mistral-small-2503",
    "provider": "azure_ai",
    "input": 1e-06,
    "output": 3e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "azure_ai/mistral-large-2407",
    "provider": "azure_ai",
    "input": 2e-06,
    "output": 6e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/mistral-large-latest",
    "provider": "azure_ai",
    "input": 2e-06,
    "output": 6e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/ministral-3b",
    "provider": "azure_ai",
    "input": 4e-08,
    "output": 4e-08,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/Llama-3.2-11B-Vision-Instruct",
    "provider": "azure_ai",
    "input": 3.7e-07,
    "output": 3.7e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "azure_ai/Llama-3.3-70B-Instruct",
    "provider": "azure_ai",
    "input": 7.1e-07,
    "output": 7.1e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "azure_ai/Llama-3.2-90B-Vision-Instruct",
    "provider": "azure_ai",
    "input": 2.04e-06,
    "output": 2.04e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "azure_ai/Meta-Llama-3.1-8B-Instruct",
    "provider": "azure_ai",
    "input": 3e-07,
    "output": 6.1e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "azure_ai/Meta-Llama-3.1-70B-Instruct",
    "provider": "azure_ai",
    "input": 2.68e-06,
    "output": 3.54e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "azure_ai/Meta-Llama-3.1-405B-Instruct",
    "provider": "azure_ai",
    "input": 5.33e-06,
    "output": 1.6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "azure_ai/Phi-4-mini-instruct",
    "provider": "azure_ai",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 131072,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/Phi-4-multimodal-instruct",
    "provider": "azure_ai",
    "input": 8e-08,
    "output": 3.2e-07,
    "max_input_tokens": 131072,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/Phi-3.5-mini-instruct",
    "provider": "azure_ai",
    "input": 1.3e-07,
    "output": 5.2e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/Phi-3.5-vision-instruct",
    "provider": "azure_ai",
    "input": 1.3e-07,
    "output": 5.2e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/Phi-3.5-MoE-instruct",
    "provider": "azure_ai",
    "input": 1.6e-07,
    "output": 6.4e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/Phi-3-mini-128k-instruct",
    "provider": "azure_ai",
    "input": 1.3e-07,
    "output": 5.2e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/Phi-3-small-128k-instruct",
    "provider": "azure_ai",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "azure_ai/Phi-3-medium-128k-instruct",
    "provider": "azure_ai",
    "input": 1.7e-07,
    "output": 6.8e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "claude-instant-1",
    "provider": "anthropic",
    "input": 1.63e-06,
    "output": 5.51e-06,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "mistral/mistral-large-latest",
    "provider": "mistral",
    "input": 2e-06,
    "output": 6e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "mistral/mistral-large-2411",
    "provider": "mistral",
    "input": 2e-06,
    "output": 6e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "mistral/mistral-large-2407",
    "provider": "mistral",
    "input": 3e-06,
    "output": 9e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "mistral/pixtral-large-latest",
    "provider": "mistral",
    "input": 2e-06,
    "output": 6e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "mistral/pixtral-large-2411",
    "provider": "mistral",
    "input": 2e-06,
    "output": 6e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "mistral/pixtral-12b-2409",
    "provider": "mistral",
    "input": 1.5e-07,
    "output": 1.5e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "mistral/open-mistral-nemo",
    "provider": "mistral",
    "input": 3e-07,
    "output": 3e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "mistral/open-mistral-nemo-2407",
    "provider": "mistral",
    "input": 3e-07,
    "output": 3e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "mistral/open-codestral-mamba",
    "provider": "mistral",
    "input": 2.5e-07,
    "output": 2.5e-07,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "mistral/codestral-mamba-latest",
    "provider": "mistral",
    "input": 2.5e-07,
    "output": 2.5e-07,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "xai/grok-beta",
    "provider": "xai",
    "input": 5e-06,
    "output": 1.5e-05,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "xai/grok-3-beta",
    "provider": "xai",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "xai/grok-3-fast-beta",
    "provider": "xai",
    "input": 5e-06,
    "output": 2.5e-05,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "xai/grok-3-fast-latest",
    "provider": "xai",
    "input": 5e-06,
    "output": 2.5e-05,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "xai/grok-3-mini-beta",
    "provider": "xai",
    "input": 3e-07,
    "output": 5e-07,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "xai/grok-3-mini-fast-beta",
    "provider": "xai",
    "input": 6e-07,
    "output": 4e-06,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "xai/grok-3-mini-fast-latest",
    "provider": "xai",
    "input": 6e-07,
    "output": 4e-06,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "xai/grok-2-1212",
    "provider": "xai",
    "input": 2e-06,
    "output": 1e-05,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "xai/grok-2",
    "provider": "xai",
    "input": 2e-06,
    "output": 1e-05,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "xai/grok-2-latest",
    "provider": "xai",
    "input": 2e-06,
    "output": 1e-05,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "deepseek/deepseek-coder",
    "provider": "deepseek",
    "input": 1.4e-07,
    "output": 2.8e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "groq/deepseek-r1-distill-llama-70b",
    "provider": "groq",
    "input": 7.5e-07,
    "output": 9.9e-07,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "groq/llama-3.3-70b-versatile",
    "provider": "groq",
    "input": 5.9e-07,
    "output": 7.9e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192
  },
  {
    "model": "cerebras/llama3.1-8b",
    "provider": "cerebras",
    "input": 1e-07,
    "output": 1e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "cerebras/llama3.1-70b",
    "provider": "cerebras",
    "input": 6e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "cerebras/llama3.3-70b",
    "provider": "cerebras",
    "input": 8.5e-07,
    "output": 1.2e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "claude-instant-1.2",
    "provider": "anthropic",
    "input": 1.63e-07,
    "output": 5.51e-07,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "claude-2",
    "provider": "anthropic",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "claude-2.1",
    "provider": "anthropic",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8191
  },
  {
    "model": "claude-3-haiku-20240307",
    "provider": "anthropic",
    "input": 2.5e-07,
    "output": 1.25e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "claude-3-5-haiku-20241022",
    "provider": "anthropic",
    "input": 8e-07,
    "output": 4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "claude-3-5-haiku-latest",
    "provider": "anthropic",
    "input": 1e-06,
    "output": 5e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "claude-3-opus-latest",
    "provider": "anthropic",
    "input": 1.5e-05,
    "output": 7.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "claude-3-opus-20240229",
    "provider": "anthropic",
    "input": 1.5e-05,
    "output": 7.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "claude-3-sonnet-20240229",
    "provider": "anthropic",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "claude-3-5-sonnet-latest",
    "provider": "anthropic",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "claude-3-5-sonnet-20240620",
    "provider": "anthropic",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "claude-3-7-sonnet-latest",
    "provider": "anthropic",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 128000
  },
  {
    "model": "claude-3-7-sonnet-20250219",
    "provider": "anthropic",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 128000
  },
  {
    "model": "claude-3-5-sonnet-20241022",
    "provider": "anthropic",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-pro",
    "provider": "vertex_ai-language-models",
    "input": 1.25e-06,
    "output": 5e-06,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-pro-002",
    "provider": "vertex_ai-language-models",
    "input": 1.25e-06,
    "output": 5e-06,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-pro-001",
    "provider": "vertex_ai-language-models",
    "input": 1.25e-06,
    "output": 5e-06,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-pro-preview-0514",
    "provider": "vertex_ai-language-models",
    "input": 7.8125e-08,
    "output": 3.125e-07,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-pro-preview-0215",
    "provider": "vertex_ai-language-models",
    "input": 7.8125e-08,
    "output": 3.125e-07,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-pro-preview-0409",
    "provider": "vertex_ai-language-models",
    "input": 7.8125e-08,
    "output": 3.125e-07,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-flash",
    "provider": "vertex_ai-language-models",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-flash-exp-0827",
    "provider": "vertex_ai-language-models",
    "input": 4.688e-09,
    "output": 4.6875e-09,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-flash-002",
    "provider": "vertex_ai-language-models",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-flash-001",
    "provider": "vertex_ai-language-models",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-1.5-flash-preview-0514",
    "provider": "vertex_ai-language-models",
    "input": 7.5e-08,
    "output": 4.6875e-09,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-pro-experimental",
    "provider": "vertex_ai-language-models",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-flash-experimental",
    "provider": "vertex_ai-language-models",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-2.5-pro-exp-03-25",
    "provider": "vertex_ai-language-models",
    "input": 1.25e-06,
    "output": 1e-05,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536
  },
  {
    "model": "gemini-2.0-pro-exp-02-05",
    "provider": "vertex_ai-language-models",
    "input": 1.25e-06,
    "output": 1e-05,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-2.0-flash-exp",
    "provider": "vertex_ai-language-models",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-2.0-flash-001",
    "provider": "vertex_ai-language-models",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-2.0-flash-thinking-exp",
    "provider": "vertex_ai-language-models",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-2.0-flash-thinking-exp-01-21",
    "provider": "vertex_ai-language-models",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536
  },
  {
    "model": "gemini/gemini-2.5-pro-exp-03-25",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536
  },
  {
    "model": "gemini/gemini-2.5-flash-preview-04-17",
    "provider": "gemini",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536
  },
  {
    "model": "gemini-2.5-flash-preview-04-17",
    "provider": "vertex_ai-language-models",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536
  },
  {
    "model": "gemini-2.0-flash",
    "provider": "vertex_ai-language-models",
    "input": 1e-07,
    "output": 4e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-2.0-flash-lite",
    "provider": "vertex_ai-language-models",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-2.0-flash-lite-001",
    "provider": "vertex_ai-language-models",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini-2.5-pro-preview-03-25",
    "provider": "vertex_ai-language-models",
    "input": 1.25e-06,
    "output": 1e-05,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536
  },
  {
    "model": "gemini/gemini-2.0-pro-exp-02-05",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-2.0-flash",
    "provider": "gemini",
    "input": 1e-07,
    "output": 4e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-2.0-flash-lite",
    "provider": "gemini",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-2.0-flash-001",
    "provider": "gemini",
    "input": 1e-07,
    "output": 4e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-2.5-pro-preview-03-25",
    "provider": "gemini",
    "input": 1.25e-06,
    "output": 1e-05,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536
  },
  {
    "model": "gemini/gemini-2.0-flash-exp",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-2.0-flash-lite-preview-02-05",
    "provider": "gemini",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-2.0-flash-thinking-exp",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536
  },
  {
    "model": "gemini/gemini-2.0-flash-thinking-exp-01-21",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536
  },
  {
    "model": "gemini/gemma-3-27b-it",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 131072,
    "max_output_tokens": 8192
  },
  {
    "model": "vertex_ai/claude-3-sonnet",
    "provider": "vertex_ai-anthropic_models",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "vertex_ai/claude-3-sonnet@20240229",
    "provider": "vertex_ai-anthropic_models",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "vertex_ai/claude-3-5-sonnet",
    "provider": "vertex_ai-anthropic_models",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "vertex_ai/claude-3-5-sonnet@20240620",
    "provider": "vertex_ai-anthropic_models",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "vertex_ai/claude-3-5-sonnet-v2",
    "provider": "vertex_ai-anthropic_models",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "vertex_ai/claude-3-5-sonnet-v2@20241022",
    "provider": "vertex_ai-anthropic_models",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "vertex_ai/claude-3-7-sonnet@20250219",
    "provider": "vertex_ai-anthropic_models",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "vertex_ai/claude-3-haiku",
    "provider": "vertex_ai-anthropic_models",
    "input": 2.5e-07,
    "output": 1.25e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "vertex_ai/claude-3-haiku@20240307",
    "provider": "vertex_ai-anthropic_models",
    "input": 2.5e-07,
    "output": 1.25e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "vertex_ai/claude-3-5-haiku",
    "provider": "vertex_ai-anthropic_models",
    "input": 1e-06,
    "output": 5e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "vertex_ai/claude-3-5-haiku@20241022",
    "provider": "vertex_ai-anthropic_models",
    "input": 1e-06,
    "output": 5e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "vertex_ai/claude-3-opus",
    "provider": "vertex_ai-anthropic_models",
    "input": 1.5e-05,
    "output": 7.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "vertex_ai/claude-3-opus@20240229",
    "provider": "vertex_ai-anthropic_models",
    "input": 1.5e-05,
    "output": 7.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas",
    "provider": "vertex_ai-llama_models",
    "input": 2.5e-07,
    "output": 7e-07,
    "max_input_tokens": 10000000,
    "max_output_tokens": 10000000
  },
  {
    "model": "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas",
    "provider": "vertex_ai-llama_models",
    "input": 2.5e-07,
    "output": 7e-07,
    "max_input_tokens": 10000000,
    "max_output_tokens": 10000000
  },
  {
    "model": "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas",
    "provider": "vertex_ai-llama_models",
    "input": 3.5e-07,
    "output": 1.15e-06,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000
  },
  {
    "model": "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas",
    "provider": "vertex_ai-llama_models",
    "input": 3.5e-07,
    "output": 1.15e-06,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000
  },
  {
    "model": "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas",
    "provider": "vertex_ai-llama_models",
    "input": 0,
    "output": 0,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "vertex_ai/mistral-large@latest",
    "provider": "vertex_ai-mistral_models",
    "input": 2e-06,
    "output": 6e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 8191
  },
  {
    "model": "vertex_ai/mistral-large@2411-001",
    "provider": "vertex_ai-mistral_models",
    "input": 2e-06,
    "output": 6e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 8191
  },
  {
    "model": "vertex_ai/mistral-large-2411",
    "provider": "vertex_ai-mistral_models",
    "input": 2e-06,
    "output": 6e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 8191
  },
  {
    "model": "vertex_ai/mistral-large@2407",
    "provider": "vertex_ai-mistral_models",
    "input": 2e-06,
    "output": 6e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 8191
  },
  {
    "model": "vertex_ai/mistral-nemo@latest",
    "provider": "vertex_ai-mistral_models",
    "input": 1.5e-07,
    "output": 1.5e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "vertex_ai/mistral-small-2503",
    "provider": "vertex_ai-mistral_models",
    "input": 1e-06,
    "output": 3e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "vertex_ai/jamba-1.5-mini@001",
    "provider": "vertex_ai-ai21_models",
    "input": 2e-07,
    "output": 4e-07,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "vertex_ai/jamba-1.5-large@001",
    "provider": "vertex_ai-ai21_models",
    "input": 2e-06,
    "output": 8e-06,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "vertex_ai/jamba-1.5",
    "provider": "vertex_ai-ai21_models",
    "input": 2e-07,
    "output": 4e-07,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "vertex_ai/jamba-1.5-mini",
    "provider": "vertex_ai-ai21_models",
    "input": 2e-07,
    "output": 4e-07,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "vertex_ai/jamba-1.5-large",
    "provider": "vertex_ai-ai21_models",
    "input": 2e-06,
    "output": 8e-06,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "vertex_ai/mistral-nemo@2407",
    "provider": "vertex_ai-mistral_models",
    "input": 3e-06,
    "output": 3e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "vertex_ai/codestral@latest",
    "provider": "vertex_ai-mistral_models",
    "input": 2e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "vertex_ai/codestral@2405",
    "provider": "vertex_ai-mistral_models",
    "input": 2e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "vertex_ai/codestral-2501",
    "provider": "vertex_ai-mistral_models",
    "input": 2e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "gemini/gemini-1.5-flash-002",
    "provider": "gemini",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-flash-001",
    "provider": "gemini",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-flash",
    "provider": "gemini",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-flash-latest",
    "provider": "gemini",
    "input": 7.5e-08,
    "output": 3e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-flash-8b",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-flash-8b-exp-0924",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-exp-1114",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-exp-1206",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-flash-exp-0827",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-flash-8b-exp-0827",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-pro",
    "provider": "gemini",
    "input": 3.5e-06,
    "output": 1.05e-05,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-pro-002",
    "provider": "gemini",
    "input": 3.5e-06,
    "output": 1.05e-05,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-pro-001",
    "provider": "gemini",
    "input": 3.5e-06,
    "output": 1.05e-05,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-pro-exp-0801",
    "provider": "gemini",
    "input": 3.5e-06,
    "output": 1.05e-05,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-pro-exp-0827",
    "provider": "gemini",
    "input": 0,
    "output": 0,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192
  },
  {
    "model": "gemini/gemini-1.5-pro-latest",
    "provider": "gemini",
    "input": 3.5e-06,
    "output": 1.05e-06,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "command-a-03-2025",
    "provider": "cohere_chat",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 256000,
    "max_output_tokens": 8000
  },
  {
    "model": "command-r",
    "provider": "cohere_chat",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "command-r-08-2024",
    "provider": "cohere_chat",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "command-r7b-12-2024",
    "provider": "cohere_chat",
    "input": 1.5e-07,
    "output": 3.75e-08,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "command-r-plus",
    "provider": "cohere_chat",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "command-r-plus-08-2024",
    "provider": "cohere_chat",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "openrouter/google/gemini-pro-1.5",
    "provider": "openrouter",
    "input": 2.5e-06,
    "output": 7.5e-06,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  {
    "model": "openrouter/google/gemini-2.0-flash-001",
    "provider": "openrouter",
    "input": 1e-07,
    "output": 4e-07,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192
  },
  {
    "model": "openrouter/anthropic/claude-3-haiku-20240307",
    "provider": "openrouter",
    "input": 2.5e-07,
    "output": 1.25e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "openrouter/anthropic/claude-3-5-haiku-20241022",
    "provider": "openrouter",
    "input": 1e-06,
    "output": 5e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "openrouter/anthropic/claude-3.5-sonnet",
    "provider": "openrouter",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "openrouter/anthropic/claude-3.5-sonnet:beta",
    "provider": "openrouter",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "openrouter/anthropic/claude-3.7-sonnet",
    "provider": "openrouter",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "openrouter/anthropic/claude-3.7-sonnet:beta",
    "provider": "openrouter",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "openrouter/openai/o1",
    "provider": "openrouter",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 100000
  },
  {
    "model": "openrouter/openai/o1-mini",
    "provider": "openrouter",
    "input": 3e-06,
    "output": 1.2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536
  },
  {
    "model": "openrouter/openai/o1-mini-2024-09-12",
    "provider": "openrouter",
    "input": 3e-06,
    "output": 1.2e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536
  },
  {
    "model": "openrouter/openai/o1-preview",
    "provider": "openrouter",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768
  },
  {
    "model": "openrouter/openai/o1-preview-2024-09-12",
    "provider": "openrouter",
    "input": 1.5e-05,
    "output": 6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768
  },
  {
    "model": "openrouter/openai/o3-mini",
    "provider": "openrouter",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536
  },
  {
    "model": "openrouter/openai/o3-mini-high",
    "provider": "openrouter",
    "input": 1.1e-06,
    "output": 4.4e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536
  },
  {
    "model": "openrouter/openai/gpt-4o",
    "provider": "openrouter",
    "input": 2.5e-06,
    "output": 1e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "openrouter/openai/gpt-4o-2024-05-13",
    "provider": "openrouter",
    "input": 5e-06,
    "output": 1.5e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "openrouter/anthropic/claude-3-opus",
    "provider": "openrouter",
    "input": 1.5e-05,
    "output": 7.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "jamba-1.5-mini@001",
    "provider": "ai21",
    "input": 2e-07,
    "output": 4e-07,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "jamba-1.5-large@001",
    "provider": "ai21",
    "input": 2e-06,
    "output": 8e-06,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "jamba-1.5",
    "provider": "ai21",
    "input": 2e-07,
    "output": 4e-07,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "jamba-1.5-mini",
    "provider": "ai21",
    "input": 2e-07,
    "output": 4e-07,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "jamba-1.5-large",
    "provider": "ai21",
    "input": 2e-06,
    "output": 8e-06,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "jamba-large-1.6",
    "provider": "ai21",
    "input": 2e-06,
    "output": 8e-06,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "jamba-mini-1.6",
    "provider": "ai21",
    "input": 2e-07,
    "output": 4e-07,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "ai21.jamba-1-5-large-v1:0",
    "provider": "bedrock",
    "input": 2e-06,
    "output": 8e-06,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "ai21.jamba-1-5-mini-v1:0",
    "provider": "bedrock",
    "input": 2e-07,
    "output": 4e-07,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000
  },
  {
    "model": "mistral.mistral-large-2407-v1:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 9e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 8191
  },
  {
    "model": "amazon.nova-micro-v1:0",
    "provider": "bedrock_converse",
    "input": 3.5e-08,
    "output": 1.4e-07,
    "max_input_tokens": 300000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.amazon.nova-micro-v1:0",
    "provider": "bedrock_converse",
    "input": 3.5e-08,
    "output": 1.4e-07,
    "max_input_tokens": 300000,
    "max_output_tokens": 4096
  },
  {
    "model": "eu.amazon.nova-micro-v1:0",
    "provider": "bedrock_converse",
    "input": 4.6e-08,
    "output": 1.84e-07,
    "max_input_tokens": 300000,
    "max_output_tokens": 4096
  },
  {
    "model": "amazon.nova-lite-v1:0",
    "provider": "bedrock_converse",
    "input": 6e-08,
    "output": 2.4e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.amazon.nova-lite-v1:0",
    "provider": "bedrock_converse",
    "input": 6e-08,
    "output": 2.4e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "eu.amazon.nova-lite-v1:0",
    "provider": "bedrock_converse",
    "input": 7.8e-08,
    "output": 3.12e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "amazon.nova-pro-v1:0",
    "provider": "bedrock_converse",
    "input": 8e-07,
    "output": 3.2e-06,
    "max_input_tokens": 300000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.amazon.nova-pro-v1:0",
    "provider": "bedrock_converse",
    "input": 8e-07,
    "output": 3.2e-06,
    "max_input_tokens": 300000,
    "max_output_tokens": 4096
  },
  {
    "model": "eu.amazon.nova-pro-v1:0",
    "provider": "bedrock_converse",
    "input": 1.05e-06,
    "output": 4.2e-06,
    "max_input_tokens": 300000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.amazon.nova-premier-v1:0",
    "provider": "bedrock_converse",
    "input": 2.5e-06,
    "output": 1.25e-05,
    "max_input_tokens": 1000000,
    "max_output_tokens": 4096
  },
  {
    "model": "anthropic.claude-3-sonnet-20240229-v1:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "anthropic.claude-3-7-sonnet-20250219-v1:0",
    "provider": "bedrock_converse",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "anthropic.claude-3-5-sonnet-20241022-v2:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "anthropic.claude-3-haiku-20240307-v1:0",
    "provider": "bedrock",
    "input": 2.5e-07,
    "output": 1.25e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "anthropic.claude-3-5-haiku-20241022-v1:0",
    "provider": "bedrock",
    "input": 8e-07,
    "output": 4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "anthropic.claude-3-opus-20240229-v1:0",
    "provider": "bedrock",
    "input": 1.5e-05,
    "output": 7.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.anthropic.claude-3-sonnet-20240229-v1:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
    "provider": "bedrock_converse",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "us.anthropic.claude-3-haiku-20240307-v1:0",
    "provider": "bedrock",
    "input": 2.5e-07,
    "output": 1.25e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
    "provider": "bedrock",
    "input": 8e-07,
    "output": 4e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "us.anthropic.claude-3-opus-20240229-v1:0",
    "provider": "bedrock",
    "input": 1.5e-05,
    "output": 7.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "eu.anthropic.claude-3-sonnet-20240229-v1:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "eu.anthropic.claude-3-5-sonnet-20240620-v1:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "eu.anthropic.claude-3-5-sonnet-20241022-v2:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "eu.anthropic.claude-3-haiku-20240307-v1:0",
    "provider": "bedrock",
    "input": 2.5e-07,
    "output": 1.25e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "eu.anthropic.claude-3-5-haiku-20241022-v1:0",
    "provider": "bedrock",
    "input": 2.5e-07,
    "output": 1.25e-06,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  {
    "model": "eu.anthropic.claude-3-opus-20240229-v1:0",
    "provider": "bedrock",
    "input": 1.5e-05,
    "output": 7.5e-05,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "anthropic.claude-v1",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/us-east-1/anthropic.claude-v1",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/us-west-2/anthropic.claude-v1",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/ap-northeast-1/anthropic.claude-v1",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/eu-central-1/anthropic.claude-v1",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "anthropic.claude-v2",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/us-east-1/anthropic.claude-v2",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/us-west-2/anthropic.claude-v2",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/ap-northeast-1/anthropic.claude-v2",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/eu-central-1/anthropic.claude-v2",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "anthropic.claude-v2:1",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/us-east-1/anthropic.claude-v2:1",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/us-west-2/anthropic.claude-v2:1",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/ap-northeast-1/anthropic.claude-v2:1",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/eu-central-1/anthropic.claude-v2:1",
    "provider": "bedrock",
    "input": 8e-06,
    "output": 2.4e-05,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "anthropic.claude-instant-v1",
    "provider": "bedrock",
    "input": 8e-07,
    "output": 2.4e-06,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/us-east-1/anthropic.claude-instant-v1",
    "provider": "bedrock",
    "input": 8e-07,
    "output": 2.4e-06,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/us-west-2/anthropic.claude-instant-v1",
    "provider": "bedrock",
    "input": 8e-07,
    "output": 2.4e-06,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/ap-northeast-1/anthropic.claude-instant-v1",
    "provider": "bedrock",
    "input": 2.23e-06,
    "output": 7.55e-06,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "bedrock/eu-central-1/anthropic.claude-instant-v1",
    "provider": "bedrock",
    "input": 2.48e-06,
    "output": 8.38e-06,
    "max_input_tokens": 100000,
    "max_output_tokens": 8191
  },
  {
    "model": "cohere.command-r-plus-v1:0",
    "provider": "bedrock",
    "input": 3e-06,
    "output": 1.5e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "cohere.command-r-v1:0",
    "provider": "bedrock",
    "input": 5e-07,
    "output": 1.5e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.deepseek.r1-v1:0",
    "provider": "bedrock_converse",
    "input": 1.35e-06,
    "output": 5.4e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "meta.llama3-3-70b-instruct-v1:0",
    "provider": "bedrock_converse",
    "input": 7.2e-07,
    "output": 7.2e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "meta.llama3-1-8b-instruct-v1:0",
    "provider": "bedrock",
    "input": 2.2e-07,
    "output": 2.2e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "us.meta.llama3-1-8b-instruct-v1:0",
    "provider": "bedrock",
    "input": 2.2e-07,
    "output": 2.2e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "meta.llama3-1-70b-instruct-v1:0",
    "provider": "bedrock",
    "input": 9.9e-07,
    "output": 9.9e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "us.meta.llama3-1-70b-instruct-v1:0",
    "provider": "bedrock",
    "input": 9.9e-07,
    "output": 9.9e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 2048
  },
  {
    "model": "meta.llama3-1-405b-instruct-v1:0",
    "provider": "bedrock",
    "input": 5.32e-06,
    "output": 1.6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.meta.llama3-1-405b-instruct-v1:0",
    "provider": "bedrock",
    "input": 5.32e-06,
    "output": 1.6e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "meta.llama3-2-1b-instruct-v1:0",
    "provider": "bedrock",
    "input": 1e-07,
    "output": 1e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.meta.llama3-2-1b-instruct-v1:0",
    "provider": "bedrock",
    "input": 1e-07,
    "output": 1e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "eu.meta.llama3-2-1b-instruct-v1:0",
    "provider": "bedrock",
    "input": 1.3e-07,
    "output": 1.3e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "meta.llama3-2-3b-instruct-v1:0",
    "provider": "bedrock",
    "input": 1.5e-07,
    "output": 1.5e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.meta.llama3-2-3b-instruct-v1:0",
    "provider": "bedrock",
    "input": 1.5e-07,
    "output": 1.5e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "eu.meta.llama3-2-3b-instruct-v1:0",
    "provider": "bedrock",
    "input": 1.9e-07,
    "output": 1.9e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "meta.llama3-2-11b-instruct-v1:0",
    "provider": "bedrock",
    "input": 3.5e-07,
    "output": 3.5e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.meta.llama3-2-11b-instruct-v1:0",
    "provider": "bedrock",
    "input": 3.5e-07,
    "output": 3.5e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "meta.llama3-2-90b-instruct-v1:0",
    "provider": "bedrock",
    "input": 2e-06,
    "output": 2e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.meta.llama3-2-90b-instruct-v1:0",
    "provider": "bedrock",
    "input": 2e-06,
    "output": 2e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "us.meta.llama3-3-70b-instruct-v1:0",
    "provider": "bedrock_converse",
    "input": 7.2e-07,
    "output": 7.2e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096
  },
  {
    "model": "deepinfra/01-ai/Yi-6B-200K",
    "provider": "deepinfra",
    "input": 1.3e-07,
    "output": 1.3e-07,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "deepinfra/01-ai/Yi-34B-200K",
    "provider": "deepinfra",
    "input": 6e-07,
    "output": 6e-07,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096
  },
  {
    "model": "perplexity/llama-3.1-70b-instruct",
    "provider": "perplexity",
    "input": 1e-06,
    "output": 1e-06,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "perplexity/llama-3.1-8b-instruct",
    "provider": "perplexity",
    "input": 2e-07,
    "output": 2e-07,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "perplexity/llama-3.1-sonar-huge-128k-online",
    "provider": "perplexity",
    "input": 5e-06,
    "output": 5e-06,
    "max_input_tokens": 127072,
    "max_output_tokens": 127072
  },
  {
    "model": "perplexity/llama-3.1-sonar-large-128k-online",
    "provider": "perplexity",
    "input": 1e-06,
    "output": 1e-06,
    "max_input_tokens": 127072,
    "max_output_tokens": 127072
  },
  {
    "model": "perplexity/llama-3.1-sonar-large-128k-chat",
    "provider": "perplexity",
    "input": 1e-06,
    "output": 1e-06,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "perplexity/llama-3.1-sonar-small-128k-chat",
    "provider": "perplexity",
    "input": 2e-07,
    "output": 2e-07,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "perplexity/llama-3.1-sonar-small-128k-online",
    "provider": "perplexity",
    "input": 2e-07,
    "output": 2e-07,
    "max_input_tokens": 127072,
    "max_output_tokens": 127072
  },
  {
    "model": "fireworks_ai/accounts/fireworks/models/deepseek-v3",
    "provider": "fireworks_ai",
    "input": 9e-07,
    "output": 9e-07,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192
  },
  {
    "model": "fireworks_ai/accounts/fireworks/models/deepseek-r1",
    "provider": "fireworks_ai",
    "input": 3e-06,
    "output": 8e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 20480
  },
  {
    "model": "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic",
    "provider": "fireworks_ai",
    "input": 5.5e-07,
    "output": 2.19e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 20480
  },
  {
    "model": "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct",
    "provider": "fireworks_ai",
    "input": 3e-06,
    "output": 3e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384
  },
  {
    "model": "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic",
    "provider": "fireworks_ai",
    "input": 2.2e-07,
    "output": 8.8e-07,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic",
    "provider": "fireworks_ai",
    "input": 1.5e-07,
    "output": 6e-07,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072
  },
  {
    "model": "databricks/databricks-claude-3-7-sonnet",
    "provider": "databricks",
    "input": 2.5e-06,
    "output": 0.00017857,
    "max_input_tokens": 200000,
    "max_output_tokens": 128000
  },
  {
    "model": "databricks/databricks-meta-llama-3-1-405b-instruct",
    "provider": "databricks",
    "input": 5e-06,
    "output": 1.500002e-05,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "databricks/databricks-meta-llama-3-1-70b-instruct",
    "provider": "databricks",
    "input": 1.00002e-06,
    "output": 2.99999e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "databricks/databricks-meta-llama-3-3-70b-instruct",
    "provider": "databricks",
    "input": 1.00002e-06,
    "output": 2.99999e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "databricks/databricks-meta-llama-3-70b-instruct",
    "provider": "databricks",
    "input": 1.00002e-06,
    "output": 2.99999e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  },
  {
    "model": "sambanova/Meta-Llama-3.1-70B-Instruct",
    "provider": "sambanova",
    "input": 6e-07,
    "output": 1.2e-06,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000
  }
]
