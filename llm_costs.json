{
  "ai21.jamba-1-5-large-v1:0": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "bedrock",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000008
  },
  "ai21.jamba-1-5-mini-v1:0": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 4E-7
  },
  "us.writer.palmyra-x4-v1:0": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_pdf_input": true
  },
  "us.writer.palmyra-x5-v1:0": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_pdf_input": true
  },
  "writer.palmyra-x4-v1:0": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_pdf_input": true
  },
  "writer.palmyra-x5-v1:0": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_pdf_input": true
  },
  "amazon.nova-lite-v1:0": {
    "input_cost_per_token": 6E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 2.4E-7,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "amazon.nova-2-lite-v1:0": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "amazon.nova-2-pro-preview-20251202-v1:0": {
    "cache_read_input_token_cost": 5.46875E-7,
    "input_cost_per_token": 0.0000021875,
    "input_cost_per_image_token": 0.0000021875,
    "input_cost_per_audio_token": 0.0000021875,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000175,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "apac.amazon.nova-2-lite-v1:0": {
    "cache_read_input_token_cost": 8.25E-8,
    "input_cost_per_token": 3.3E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.00000275,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "apac.amazon.nova-2-pro-preview-20251202-v1:0": {
    "cache_read_input_token_cost": 5.46875E-7,
    "input_cost_per_token": 0.0000021875,
    "input_cost_per_image_token": 0.0000021875,
    "input_cost_per_audio_token": 0.0000021875,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000175,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "eu.amazon.nova-2-lite-v1:0": {
    "cache_read_input_token_cost": 8.25E-8,
    "input_cost_per_token": 3.3E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.00000275,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "eu.amazon.nova-2-pro-preview-20251202-v1:0": {
    "cache_read_input_token_cost": 5.46875E-7,
    "input_cost_per_token": 0.0000021875,
    "input_cost_per_image_token": 0.0000021875,
    "input_cost_per_audio_token": 0.0000021875,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000175,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "us.amazon.nova-2-lite-v1:0": {
    "cache_read_input_token_cost": 8.25E-8,
    "input_cost_per_token": 3.3E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.00000275,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "us.amazon.nova-2-pro-preview-20251202-v1:0": {
    "cache_read_input_token_cost": 5.46875E-7,
    "input_cost_per_token": 0.0000021875,
    "input_cost_per_image_token": 0.0000021875,
    "input_cost_per_audio_token": 0.0000021875,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000175,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "amazon.nova-micro-v1:0": {
    "input_cost_per_token": 3.5E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 1.4E-7,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true
  },
  "amazon.nova-pro-v1:0": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 0.0000032,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "anthropic.claude-3-5-haiku-20241022-v1:0": {
    "cache_creation_input_token_cost": 0.000001,
    "cache_read_input_token_cost": 8E-8,
    "input_cost_per_token": 8E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "anthropic.claude-haiku-4-5-20251001-v1:0": {
    "cache_creation_input_token_cost": 0.00000125,
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 0.000001,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "anthropic.claude-haiku-4-5@20251001": {
    "cache_creation_input_token_cost": 0.00000125,
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 0.000001,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346,
    "supports_native_streaming": true
  },
  "anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 1000000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.00003,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "cache_creation_input_token_cost_above_1hr": 0.0000075,
    "cache_creation_input_token_cost_above_1hr_above_200k_tokens": 0.000015,
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7
  },
  "anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.00003,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "cache_creation_input_token_cost_above_1hr": 0.0000075,
    "cache_creation_input_token_cost_above_1hr_above_200k_tokens": 0.000015
  },
  "anthropic.claude-3-7-sonnet-20240620-v1:0": {
    "cache_creation_input_token_cost": 0.0000045,
    "cache_read_input_token_cost": 3.6E-7,
    "input_cost_per_token": 0.0000036,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000018,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "anthropic.claude-3-7-sonnet-20250219-v1:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "anthropic.claude-3-opus-20240229-v1:0": {
    "input_cost_per_token": 0.000015,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "anthropic.claude-3-sonnet-20240229-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "anthropic.claude-instant-v1": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.0000024,
    "supports_tool_choice": true
  },
  "anthropic.claude-opus-4-1-20250805-v1:0": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "anthropic.claude-opus-4-20250514-v1:0": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "anthropic.claude-opus-4-5-20251101-v1:0": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "anthropic.claude-opus-4-6-v1": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000125,
    "cache_read_input_token_cost": 5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.000001,
    "input_cost_per_token": 0.000005,
    "input_cost_per_token_above_200k_tokens": 0.00001,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "output_cost_per_token_above_200k_tokens": 0.0000375,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "global.anthropic.claude-opus-4-6-v1": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000125,
    "cache_read_input_token_cost": 5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.000001,
    "input_cost_per_token": 0.000005,
    "input_cost_per_token_above_200k_tokens": 0.00001,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "output_cost_per_token_above_200k_tokens": 0.0000375,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "us.anthropic.claude-opus-4-6-v1": {
    "cache_creation_input_token_cost": 0.000006875,
    "cache_creation_input_token_cost_above_200k_tokens": 0.00001375,
    "cache_read_input_token_cost": 5.5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.0000011,
    "input_cost_per_token": 0.0000055,
    "input_cost_per_token_above_200k_tokens": 0.000011,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000275,
    "output_cost_per_token_above_200k_tokens": 0.00004125,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "eu.anthropic.claude-opus-4-6-v1": {
    "cache_creation_input_token_cost": 0.000006875,
    "cache_creation_input_token_cost_above_200k_tokens": 0.00001375,
    "cache_read_input_token_cost": 5.5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.0000011,
    "input_cost_per_token": 0.0000055,
    "input_cost_per_token_above_200k_tokens": 0.000011,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000275,
    "output_cost_per_token_above_200k_tokens": 0.00004125,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "au.anthropic.claude-opus-4-6-v1": {
    "cache_creation_input_token_cost": 0.000006875,
    "cache_creation_input_token_cost_above_200k_tokens": 0.00001375,
    "cache_read_input_token_cost": 5.5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.0000011,
    "input_cost_per_token": 0.0000055,
    "input_cost_per_token_above_200k_tokens": 0.000011,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000275,
    "output_cost_per_token_above_200k_tokens": 0.00004125,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "anthropic.claude-sonnet-4-20250514-v1:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "anthropic.claude-sonnet-4-5-20250929-v1:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "anthropic.claude-v1": {
    "input_cost_per_token": 0.000008,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000024
  },
  "anthropic.claude-v2:1": {
    "input_cost_per_token": 0.000008,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true
  },
  "apac.amazon.nova-lite-v1:0": {
    "input_cost_per_token": 6.3E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 2.52E-7,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "apac.amazon.nova-micro-v1:0": {
    "input_cost_per_token": 3.7E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 1.48E-7,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true
  },
  "apac.amazon.nova-pro-v1:0": {
    "input_cost_per_token": 8.4E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 0.00000336,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "apac.anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "apac.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "apac.anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "apac.anthropic.claude-haiku-4-5-20251001-v1:0": {
    "cache_creation_input_token_cost": 0.000001375,
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000055,
    "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "apac.anthropic.claude-3-sonnet-20240229-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "apac.anthropic.claude-sonnet-4-20250514-v1:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "au.anthropic.claude-sonnet-4-5-20250929-v1:0": {
    "cache_creation_input_token_cost": 0.000004125,
    "cache_read_input_token_cost": 3.3E-7,
    "input_cost_per_token": 0.0000033,
    "input_cost_per_token_above_200k_tokens": 0.0000066,
    "output_cost_per_token_above_200k_tokens": 0.00002475,
    "cache_creation_input_token_cost_above_200k_tokens": 0.00000825,
    "cache_read_input_token_cost_above_200k_tokens": 6.6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000165,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "azure/codex-mini": {
    "cache_read_input_token_cost": 3.75E-7,
    "input_cost_per_token": 0.0000015,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.000006,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/command-r-plus": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true
  },
  "azure_ai/claude-haiku-4-5": {
    "cache_creation_input_token_cost": 0.00000125,
    "cache_creation_input_token_cost_above_1hr": 0.000002,
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 0.000001,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/claude-opus-4-5": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_1hr": 0.00001,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/claude-opus-4-6": {
    "input_cost_per_token": 0.000005,
    "output_cost_per_token": 0.000025,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_1hr": 0.00001,
    "cache_read_input_token_cost": 5E-7,
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "azure_ai/claude-opus-4-1": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_creation_input_token_cost_above_1hr": 0.00003,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/claude-sonnet-4-5": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/gpt-oss-120b": {
    "input_cost_per_token": 1.5E-7,
    "output_cost_per_token": 6E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "source": "https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "azure/eu/gpt-4o-2024-08-06": {
    "deprecation_date": "2026-02-27",
    "cache_read_input_token_cost": 0.000001375,
    "input_cost_per_token": 0.00000275,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/gpt-4o-2024-11-20": {
    "deprecation_date": "2026-03-01",
    "cache_creation_input_token_cost": 0.00000138,
    "input_cost_per_token": 0.00000275,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/gpt-4o-mini-2024-07-18": {
    "cache_read_input_token_cost": 8.3E-8,
    "input_cost_per_token": 1.65E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6.6E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17": {
    "cache_creation_input_audio_token_cost": 3.3E-7,
    "cache_read_input_token_cost": 3.3E-7,
    "input_cost_per_audio_token": 0.000011,
    "input_cost_per_token": 6.6E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.000022,
    "output_cost_per_token": 0.00000264,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "azure/eu/gpt-4o-realtime-preview-2024-10-01": {
    "cache_creation_input_audio_token_cost": 0.000022,
    "cache_read_input_token_cost": 0.00000275,
    "input_cost_per_audio_token": 0.00011,
    "input_cost_per_token": 0.0000055,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00022,
    "output_cost_per_token": 0.000022,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "azure/eu/gpt-4o-realtime-preview-2024-12-17": {
    "cache_read_input_audio_token_cost": 0.0000025,
    "cache_read_input_token_cost": 0.00000275,
    "input_cost_per_audio_token": 0.000044,
    "input_cost_per_token": 0.0000055,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.000022,
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "azure/eu/gpt-5-2025-08-07": {
    "cache_read_input_token_cost": 1.375E-7,
    "input_cost_per_token": 0.000001375,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/gpt-5-mini-2025-08-07": {
    "cache_read_input_token_cost": 2.75E-8,
    "input_cost_per_token": 2.75E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000022,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/gpt-5.1": {
    "cache_read_input_token_cost": 1.4E-7,
    "input_cost_per_token": 0.00000138,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/gpt-5.1-chat": {
    "cache_read_input_token_cost": 1.4E-7,
    "input_cost_per_token": 0.00000138,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/gpt-5.1-codex": {
    "cache_read_input_token_cost": 1.4E-7,
    "input_cost_per_token": 0.00000138,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000011,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/gpt-5.1-codex-mini": {
    "cache_read_input_token_cost": 2.8E-8,
    "input_cost_per_token": 2.75E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.0000022,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/gpt-5-nano-2025-08-07": {
    "cache_read_input_token_cost": 5.5E-9,
    "input_cost_per_token": 5.5E-8,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4.4E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/o1-2024-12-17": {
    "cache_read_input_token_cost": 0.00000825,
    "input_cost_per_token": 0.0000165,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.000066,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/eu/o1-mini-2024-09-12": {
    "cache_read_input_token_cost": 6.05E-7,
    "input_cost_per_token": 0.00000121,
    "input_cost_per_token_batches": 6.05E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.00000484,
    "output_cost_per_token_batches": 0.00000242,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_vision": false
  },
  "azure/eu/o1-preview-2024-09-12": {
    "cache_read_input_token_cost": 0.00000825,
    "input_cost_per_token": 0.0000165,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000066,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_vision": false
  },
  "azure/eu/o3-mini-2025-01-31": {
    "cache_read_input_token_cost": 6.05E-7,
    "input_cost_per_token": 0.00000121,
    "input_cost_per_token_batches": 6.05E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.00000484,
    "output_cost_per_token_batches": 0.00000242,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure/global-standard/gpt-4o-2024-08-06": {
    "cache_read_input_token_cost": 0.00000125,
    "deprecation_date": "2026-02-27",
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/global-standard/gpt-4o-2024-11-20": {
    "cache_read_input_token_cost": 0.00000125,
    "deprecation_date": "2026-03-01",
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/global-standard/gpt-4o-mini": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/global/gpt-4o-2024-08-06": {
    "deprecation_date": "2026-02-27",
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/global/gpt-4o-2024-11-20": {
    "deprecation_date": "2026-03-01",
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/global/gpt-5.1": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/global/gpt-5.1-chat": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/global/gpt-5.1-codex": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/global/gpt-5.1-codex-mini": {
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000002,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4-0125-preview": {
    "input_cost_per_token": 0.00001,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "azure/gpt-4-1106-preview": {
    "input_cost_per_token": 0.00001,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "azure/gpt-4-turbo": {
    "input_cost_per_token": 0.00001,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "azure/gpt-4-turbo-2024-04-09": {
    "input_cost_per_token": 0.00001,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4-turbo-vision-preview": {
    "input_cost_per_token": 0.00001,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4.1": {
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "litellm_provider": "azure",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": false
  },
  "azure/gpt-4.1-2025-04-14": {
    "deprecation_date": "2026-11-04",
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "litellm_provider": "azure",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": false
  },
  "azure/gpt-4.1-mini": {
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 4E-7,
    "input_cost_per_token_batches": 2E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0000016,
    "output_cost_per_token_batches": 8E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": false
  },
  "azure/gpt-4.1-mini-2025-04-14": {
    "deprecation_date": "2026-11-04",
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 4E-7,
    "input_cost_per_token_batches": 2E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0000016,
    "output_cost_per_token_batches": 8E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": false
  },
  "azure/gpt-4.1-nano": {
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 1E-7,
    "input_cost_per_token_batches": 5E-8,
    "litellm_provider": "azure",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "output_cost_per_token_batches": 2E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4.1-nano-2025-04-14": {
    "deprecation_date": "2026-11-04",
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 1E-7,
    "input_cost_per_token_batches": 5E-8,
    "litellm_provider": "azure",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "output_cost_per_token_batches": 2E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4.5-preview": {
    "cache_read_input_token_cost": 0.0000375,
    "input_cost_per_token": 0.000075,
    "input_cost_per_token_batches": 0.0000375,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_batches": 0.000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4o": {
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4o-2024-05-13": {
    "input_cost_per_token": 0.000005,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4o-2024-08-06": {
    "deprecation_date": "2026-02-27",
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4o-2024-11-20": {
    "deprecation_date": "2026-03-01",
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.00000275,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-audio-2025-08-28": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure/gpt-audio-mini-2025-10-06": {
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure/gpt-4o-audio-preview-2024-12-17": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure/gpt-4o-mini": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 1.65E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6.6E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4o-mini-2024-07-18": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 1.65E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6.6E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-4o-mini-audio-preview-2024-12-17": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure/gpt-4o-mini-realtime-preview-2024-12-17": {
    "cache_creation_input_audio_token_cost": 3E-7,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "azure/gpt-4o-realtime-preview-2024-10-01": {
    "cache_creation_input_audio_token_cost": 0.00002,
    "cache_read_input_token_cost": 0.0000025,
    "input_cost_per_audio_token": 0.0001,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.0002,
    "output_cost_per_token": 0.00002,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "azure/gpt-4o-realtime-preview-2024-12-17": {
    "cache_read_input_token_cost": 0.0000025,
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00002,
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "azure/gpt-5.1-2025-11-13": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_priority": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_priority": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_priority": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-chat-2025-11-13": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_priority": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_priority": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_priority": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-2025-11-13": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_priority": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_priority": 0.0000025,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_priority": 0.00002,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-mini-2025-11-13": {
    "cache_read_input_token_cost": 2.5E-8,
    "cache_read_input_token_cost_priority": 4.5E-8,
    "input_cost_per_token": 2.5E-7,
    "input_cost_per_token_priority": 4.5E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000002,
    "output_cost_per_token_priority": 0.0000036,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-2025-08-07": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-chat": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "source": "https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-chat-latest": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-codex": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-mini": {
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-mini-2025-08-07": {
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-nano": {
    "cache_read_input_token_cost": 5E-9,
    "input_cost_per_token": 5E-8,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-nano-2025-08-07": {
    "cache_read_input_token_cost": 5E-9,
    "input_cost_per_token": 5E-8,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5-pro": {
    "input_cost_per_token": 0.000015,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "source": "https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-sold-directly-by-azure?pivots=azure-openai&tabs=global-standard-aoai%2Cstandard-chat-completions%2Cglobal-standard#gpt-5",
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-chat": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-max": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.1-codex-mini": {
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000002,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2": {
    "cache_read_input_token_cost": 1.75E-7,
    "input_cost_per_token": 0.00000175,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-2025-12-11": {
    "cache_read_input_token_cost": 1.75E-7,
    "cache_read_input_token_cost_priority": 3.5E-7,
    "input_cost_per_token": 0.00000175,
    "input_cost_per_token_priority": 0.0000035,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "output_cost_per_token_priority": 0.000028,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-chat": {
    "cache_read_input_token_cost": 1.75E-7,
    "cache_read_input_token_cost_priority": 3.5E-7,
    "input_cost_per_token": 0.00000175,
    "input_cost_per_token_priority": 0.0000035,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "output_cost_per_token_priority": 0.000028,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-chat-2025-12-11": {
    "cache_read_input_token_cost": 1.75E-7,
    "cache_read_input_token_cost_priority": 3.5E-7,
    "input_cost_per_token": 0.00000175,
    "input_cost_per_token_priority": 0.0000035,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "output_cost_per_token_priority": 0.000028,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-codex": {
    "cache_read_input_token_cost": 1.75E-7,
    "input_cost_per_token": 0.00000175,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000014,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/gpt-5.2-pro": {
    "input_cost_per_token": 0.000021,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "azure/gpt-5.2-pro-2025-12-11": {
    "input_cost_per_token": 0.000021,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "azure/o1": {
    "cache_read_input_token_cost": 0.0000075,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/o1-2024-12-17": {
    "cache_read_input_token_cost": 0.0000075,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/o1-mini": {
    "cache_read_input_token_cost": 6.05E-7,
    "input_cost_per_token": 0.00000121,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.00000484,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": false
  },
  "azure/o1-mini-2024-09-12": {
    "cache_read_input_token_cost": 5.5E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": false
  },
  "azure/o1-preview": {
    "cache_read_input_token_cost": 0.0000075,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": false
  },
  "azure/o1-preview-2024-09-12": {
    "cache_read_input_token_cost": 0.0000075,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": false
  },
  "azure/o3": {
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/o3-2025-04-16": {
    "deprecation_date": "2026-04-16",
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/o3-deep-research": {
    "cache_read_input_token_cost": 0.0000025,
    "input_cost_per_token": 0.00001,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.00004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "azure/o3-mini": {
    "cache_read_input_token_cost": 5.5E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure/o3-mini-2025-01-31": {
    "cache_read_input_token_cost": 5.5E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure/o3-pro": {
    "input_cost_per_token": 0.00002,
    "input_cost_per_token_batches": 0.00001,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.00008,
    "output_cost_per_token_batches": 0.00004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/o3-pro-2025-06-10": {
    "input_cost_per_token": 0.00002,
    "input_cost_per_token_batches": 0.00001,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.00008,
    "output_cost_per_token_batches": 0.00004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/o4-mini": {
    "cache_read_input_token_cost": 2.75E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/o4-mini-2025-04-16": {
    "cache_read_input_token_cost": 2.75E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-4.1-2025-04-14": {
    "deprecation_date": "2026-11-04",
    "cache_read_input_token_cost": 5.5E-7,
    "input_cost_per_token": 0.0000022,
    "input_cost_per_token_batches": 0.0000011,
    "litellm_provider": "azure",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0000088,
    "output_cost_per_token_batches": 0.0000044,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": false
  },
  "azure/us/gpt-4.1-mini-2025-04-14": {
    "deprecation_date": "2026-11-04",
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token": 4.4E-7,
    "input_cost_per_token_batches": 2.2E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.00000176,
    "output_cost_per_token_batches": 8.8E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": false
  },
  "azure/us/gpt-4.1-nano-2025-04-14": {
    "deprecation_date": "2026-11-04",
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 1.1E-7,
    "input_cost_per_token_batches": 6E-8,
    "litellm_provider": "azure",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4.4E-7,
    "output_cost_per_token_batches": 2.2E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-4o-2024-08-06": {
    "deprecation_date": "2026-02-27",
    "cache_read_input_token_cost": 0.000001375,
    "input_cost_per_token": 0.00000275,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-4o-2024-11-20": {
    "deprecation_date": "2026-03-01",
    "cache_creation_input_token_cost": 0.00000138,
    "input_cost_per_token": 0.00000275,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-4o-mini-2024-07-18": {
    "cache_read_input_token_cost": 8.3E-8,
    "input_cost_per_token": 1.65E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6.6E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-4o-mini-realtime-preview-2024-12-17": {
    "cache_creation_input_audio_token_cost": 3.3E-7,
    "cache_read_input_token_cost": 3.3E-7,
    "input_cost_per_audio_token": 0.000011,
    "input_cost_per_token": 6.6E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.000022,
    "output_cost_per_token": 0.00000264,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "azure/us/gpt-4o-realtime-preview-2024-10-01": {
    "cache_creation_input_audio_token_cost": 0.000022,
    "cache_read_input_token_cost": 0.00000275,
    "input_cost_per_audio_token": 0.00011,
    "input_cost_per_token": 0.0000055,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00022,
    "output_cost_per_token": 0.000022,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "azure/us/gpt-4o-realtime-preview-2024-12-17": {
    "cache_read_input_audio_token_cost": 0.0000025,
    "cache_read_input_token_cost": 0.00000275,
    "input_cost_per_audio_token": 0.000044,
    "input_cost_per_token": 0.0000055,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.000022,
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "azure/us/gpt-5-2025-08-07": {
    "cache_read_input_token_cost": 1.375E-7,
    "input_cost_per_token": 0.000001375,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-5-mini-2025-08-07": {
    "cache_read_input_token_cost": 2.75E-8,
    "input_cost_per_token": 2.75E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000022,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-5-nano-2025-08-07": {
    "cache_read_input_token_cost": 5.5E-9,
    "input_cost_per_token": 5.5E-8,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4.4E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-5.1": {
    "cache_read_input_token_cost": 1.4E-7,
    "input_cost_per_token": 0.00000138,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-5.1-chat": {
    "cache_read_input_token_cost": 1.4E-7,
    "input_cost_per_token": 0.00000138,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000011,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-5.1-codex": {
    "cache_read_input_token_cost": 1.4E-7,
    "input_cost_per_token": 0.00000138,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000011,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/gpt-5.1-codex-mini": {
    "cache_read_input_token_cost": 2.8E-8,
    "input_cost_per_token": 2.75E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.0000022,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/o1-2024-12-17": {
    "cache_read_input_token_cost": 0.00000825,
    "input_cost_per_token": 0.0000165,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.000066,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/o1-mini-2024-09-12": {
    "cache_read_input_token_cost": 6.05E-7,
    "input_cost_per_token": 0.00000121,
    "input_cost_per_token_batches": 6.05E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.00000484,
    "output_cost_per_token_batches": 0.00000242,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_vision": false
  },
  "azure/us/o1-preview-2024-09-12": {
    "cache_read_input_token_cost": 0.00000825,
    "input_cost_per_token": 0.0000165,
    "litellm_provider": "azure",
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000066,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_vision": false
  },
  "azure/us/o3-2025-04-16": {
    "deprecation_date": "2026-04-16",
    "cache_read_input_token_cost": 5.5E-7,
    "input_cost_per_token": 0.0000022,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000088,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure/us/o3-mini-2025-01-31": {
    "cache_read_input_token_cost": 6.05E-7,
    "input_cost_per_token": 0.00000121,
    "input_cost_per_token_batches": 6.05E-7,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.00000484,
    "output_cost_per_token_batches": 0.00000242,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure/us/o4-mini-2025-04-16": {
    "cache_read_input_token_cost": 3.1E-7,
    "input_cost_per_token": 0.00000121,
    "litellm_provider": "azure",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.00000484,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/Llama-3.2-11B-Vision-Instruct": {
    "input_cost_per_token": 3.7E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 3.7E-7,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/Llama-3.2-90B-Vision-Instruct": {
    "input_cost_per_token": 0.00000204,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 0.00000204,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/Llama-3.3-70B-Instruct": {
    "input_cost_per_token": 7.1E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 7.1E-7,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8": {
    "input_cost_per_token": 0.00000141,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 1000000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 3.5E-7,
    "source": "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/Llama-4-Scout-17B-16E-Instruct": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 10000000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 7.8E-7,
    "source": "https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/Meta-Llama-3.1-405B-Instruct": {
    "input_cost_per_token": 0.00000533,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 0.000016,
    "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice",
    "supports_tool_choice": true
  },
  "azure_ai/Meta-Llama-3.1-70B-Instruct": {
    "input_cost_per_token": 0.00000268,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 0.00000354,
    "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice",
    "supports_tool_choice": true
  },
  "azure_ai/Meta-Llama-3.1-8B-Instruct": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 6.1E-7,
    "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice",
    "supports_tool_choice": true
  },
  "azure_ai/Phi-3-medium-128k-instruct": {
    "input_cost_per_token": 1.7E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6.8E-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure_ai/Phi-3-mini-128k-instruct": {
    "input_cost_per_token": 1.3E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 5.2E-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure_ai/Phi-3-small-128k-instruct": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure_ai/Phi-3.5-MoE-instruct": {
    "input_cost_per_token": 1.6E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6.4E-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure_ai/Phi-3.5-mini-instruct": {
    "input_cost_per_token": 1.3E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 5.2E-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "azure_ai/Phi-3.5-vision-instruct": {
    "input_cost_per_token": 1.3E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 5.2E-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/Phi-4-mini-instruct": {
    "input_cost_per_token": 7.5E-8,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112",
    "supports_function_calling": true
  },
  "azure_ai/Phi-4-multimodal-instruct": {
    "input_cost_per_audio_token": 0.000004,
    "input_cost_per_token": 8E-8,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3.2E-7,
    "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112",
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_vision": true
  },
  "azure_ai/Phi-4-mini-reasoning": {
    "input_cost_per_token": 8E-8,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3.2E-7,
    "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/microsoft/",
    "supports_function_calling": true
  },
  "azure_ai/MAI-DS-R1": {
    "input_cost_per_token": 0.00000135,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000054,
    "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/microsoft/",
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "azure_ai/deepseek-v3.2": {
    "input_cost_per_token": 5.8E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000168,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "azure_ai/deepseek-v3.2-speciale": {
    "input_cost_per_token": 5.8E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000168,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "azure_ai/deepseek-r1": {
    "input_cost_per_token": 0.00000135,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000054,
    "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367",
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "azure_ai/deepseek-v3": {
    "input_cost_per_token": 0.00000114,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000456,
    "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438",
    "supports_tool_choice": true
  },
  "azure_ai/deepseek-v3-0324": {
    "input_cost_per_token": 0.00000114,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000456,
    "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "azure_ai/embed-v-4-0": {
    "input_cost_per_token": 1.2E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "mode": "embedding",
    "output_cost_per_token": 0.0,
    "output_vector_size": 3072,
    "source": "https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice",
    "supported_endpoints": [
      "/v1/embeddings"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supports_embedding_image_input": true
  },
  "azure_ai/global/grok-3": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "azure_ai/global/grok-3-mini": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.00000127,
    "source": "https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "azure_ai/grok-3": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/grok/",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "azure_ai/grok-3-mini": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.00000127,
    "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/grok/",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "azure_ai/grok-4": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/grok/",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "azure_ai/grok-4-fast-non-reasoning": {
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 5E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "azure_ai/grok-4-fast-reasoning": {
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 5E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/grok/",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "azure_ai/grok-code-fast-1": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "source": "https://azure.microsoft.com/en-us/pricing/details/ai-foundry-models/grok/",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "azure_ai/kimi-k2.5": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "source": "https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/kimi-k2-5-now-in-microsoft-foundry/4492321",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "azure_ai/ministral-3b": {
    "input_cost_per_token": 4E-8,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 4E-8,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "azure_ai/mistral-large-2407": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "azure_ai/mistral-large-latest": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "azure_ai/mistral-large-3": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 256000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "source": "https://azure.microsoft.com/en-us/blog/introducing-mistral-large-3-in-microsoft-foundry-open-capable-and-ready-for-production-workloads/",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "azure_ai/mistral-medium-2505": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "azure_ai/mistral-nemo": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1.5E-7,
    "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice",
    "supports_function_calling": true
  },
  "azure_ai/mistral-small-2503": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "azure_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.01475,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.01475,
    "supports_tool_choice": true
  },
  "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.0455,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.0455
  },
  "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.0455,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.0455,
    "supports_tool_choice": true
  },
  "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.008194,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.008194,
    "supports_tool_choice": true
  },
  "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.02527,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.02527
  },
  "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.02527,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.02527,
    "supports_tool_choice": true
  },
  "bedrock/ap-northeast-1/anthropic.claude-instant-v1": {
    "input_cost_per_token": 0.00000223,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.00000755,
    "supports_tool_choice": true
  },
  "bedrock/ap-northeast-1/anthropic.claude-v1": {
    "input_cost_per_token": 0.000008,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true
  },
  "bedrock/ap-northeast-1/anthropic.claude-v2:1": {
    "input_cost_per_token": 0.000008,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true
  },
  "bedrock/ap-northeast-1/deepseek.v3.2": {
    "input_cost_per_token": 7.4E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000222,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/ap-northeast-1/minimax.minimax-m2.1": {
    "input_cost_per_token": 3.6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/ap-northeast-1/moonshotai.kimi-k2-thinking": {
    "input_cost_per_token": 7.3E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.00000303,
    "supports_function_calling": true,
    "supports_reasoning": true
  },
  "bedrock/ap-northeast-1/moonshotai.kimi-k2.5": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000036,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/ap-northeast-1/qwen.qwen3-coder-next": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/moonshotai.kimi-k2-thinking": {
    "input_cost_per_token": 7.3E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.00000303,
    "supports_function_calling": true,
    "supports_reasoning": true
  },
  "bedrock/moonshotai.kimi-k2.5": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.00000303,
    "source": "https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "bedrock/ap-south-1/deepseek.v3.2": {
    "input_cost_per_token": 7.4E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000222,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/ap-south-1/minimax.minimax-m2.1": {
    "input_cost_per_token": 3.6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/ap-south-1/moonshotai.kimi-k2-thinking": {
    "input_cost_per_token": 7.1E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.00000294,
    "supports_function_calling": true,
    "supports_reasoning": true
  },
  "bedrock/ap-south-1/moonshotai.kimi-k2.5": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000036,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/ap-south-1/qwen.qwen3-coder-next": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/ap-southeast-3/deepseek.v3.2": {
    "input_cost_per_token": 7.4E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000222,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/ap-southeast-3/minimax.minimax-m2.1": {
    "input_cost_per_token": 3.6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/ap-southeast-3/moonshotai.kimi-k2.5": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000036,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/ap-southeast-3/qwen.qwen3-coder-next": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-north-1/deepseek.v3.2": {
    "input_cost_per_token": 7.4E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000222,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-north-1/minimax.minimax-m2.1": {
    "input_cost_per_token": 3.6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-north-1/moonshotai.kimi-k2.5": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000036,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.01635,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.01635,
    "supports_tool_choice": true
  },
  "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.0415,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.0415
  },
  "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.0415,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.0415,
    "supports_tool_choice": true
  },
  "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.009083,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.009083,
    "supports_tool_choice": true
  },
  "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.02305,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.02305
  },
  "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.02305,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.02305,
    "supports_tool_choice": true
  },
  "bedrock/eu-central-1/anthropic.claude-instant-v1": {
    "input_cost_per_token": 0.00000248,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.00000838,
    "supports_tool_choice": true
  },
  "bedrock/eu-central-1/anthropic.claude-v1": {
    "input_cost_per_token": 0.000008,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000024
  },
  "bedrock/eu-central-1/anthropic.claude-v2:1": {
    "input_cost_per_token": 0.000008,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true
  },
  "bedrock/eu-central-1/minimax.minimax-m2.1": {
    "input_cost_per_token": 3.6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-central-1/qwen.qwen3-coder-next": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-west-1/minimax.minimax-m2.1": {
    "input_cost_per_token": 3.6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-west-1/qwen.qwen3-coder-next": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-west-2/minimax.minimax-m2.1": {
    "input_cost_per_token": 4.7E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000186,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-west-2/qwen.qwen3-coder-next": {
    "input_cost_per_token": 7.8E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000186,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-south-1/minimax.minimax-m2.1": {
    "input_cost_per_token": 3.6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/eu-south-1/qwen.qwen3-coder-next": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "metadata": {
      "notes": "Anthropic via Invoke route does not currently support pdf input."
    },
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "bedrock/sa-east-1/deepseek.v3.2": {
    "input_cost_per_token": 7.4E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000222,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/sa-east-1/minimax.minimax-m2.1": {
    "input_cost_per_token": 3.6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/sa-east-1/moonshotai.kimi-k2-thinking": {
    "input_cost_per_token": 7.3E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.00000303,
    "supports_function_calling": true,
    "supports_reasoning": true
  },
  "bedrock/sa-east-1/moonshotai.kimi-k2.5": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000036,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/sa-east-1/qwen.qwen3-coder-next": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000144,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.011,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.011,
    "supports_tool_choice": true
  },
  "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.0175,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.0175
  },
  "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.0175,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.0175,
    "supports_tool_choice": true
  },
  "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.00611,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.00611,
    "supports_tool_choice": true
  },
  "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.00972,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.00972
  },
  "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.00972,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.00972,
    "supports_tool_choice": true
  },
  "bedrock/us-east-1/anthropic.claude-instant-v1": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.0000024,
    "supports_tool_choice": true
  },
  "bedrock/us-east-1/anthropic.claude-v1": {
    "input_cost_per_token": 0.000008,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true
  },
  "bedrock/us-east-1/anthropic.claude-v2:1": {
    "input_cost_per_token": 0.000008,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true
  },
  "bedrock/us-east-1/deepseek.v3.2": {
    "input_cost_per_token": 6.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000185,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-east-1/minimax.minimax-m2.1": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-east-1/moonshotai.kimi-k2-thinking": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "supports_function_calling": true,
    "supports_reasoning": true
  },
  "bedrock/us-east-1/moonshotai.kimi-k2.5": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-east-1/qwen.qwen3-coder-next": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-east-2/deepseek.v3.2": {
    "input_cost_per_token": 6.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000185,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-east-2/minimax.minimax-m2.1": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-east-2/moonshotai.kimi-k2-thinking": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "supports_function_calling": true,
    "supports_reasoning": true
  },
  "bedrock/us-east-2/moonshotai.kimi-k2.5": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-east-2/qwen.qwen3-coder-next": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-gov-east-1/amazon.nova-pro-v1:0": {
    "input_cost_per_token": 9.6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 0.00000384,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "bedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.0000036,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000018,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "bedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "bedrock/us-gov-east-1/claude-sonnet-4-5-20250929-v1:0": {
    "input_cost_per_token": 0.0000033,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.0000165,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "bedrock/us-gov-west-1/amazon.nova-pro-v1:0": {
    "input_cost_per_token": 9.6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 0.00000384,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "bedrock/us-gov-west-1/anthropic.claude-3-7-sonnet-20250219-v1:0": {
    "cache_creation_input_token_cost": 0.0000045,
    "cache_read_input_token_cost": 3.6E-7,
    "input_cost_per_token": 0.0000036,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000018,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "bedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.0000036,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000018,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "bedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "bedrock/us-gov-west-1/claude-sonnet-4-5-20250929-v1:0": {
    "input_cost_per_token": 0.0000033,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.0000165,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.011,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.011,
    "supports_tool_choice": true
  },
  "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.0175,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.0175
  },
  "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.0175,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.0175,
    "supports_tool_choice": true
  },
  "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1": {
    "input_cost_per_second": 0.00611,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.00611,
    "supports_tool_choice": true
  },
  "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1": {
    "input_cost_per_second": 0.00972,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.00972
  },
  "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1": {
    "input_cost_per_second": 0.00972,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_second": 0.00972,
    "supports_tool_choice": true
  },
  "bedrock/us-west-2/anthropic.claude-instant-v1": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.0000024,
    "supports_tool_choice": true
  },
  "bedrock/us-west-2/anthropic.claude-v1": {
    "input_cost_per_token": 0.000008,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true
  },
  "bedrock/us-west-2/anthropic.claude-v2:1": {
    "input_cost_per_token": 0.000008,
    "litellm_provider": "bedrock",
    "max_input_tokens": 100000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000024,
    "supports_tool_choice": true
  },
  "bedrock/us-west-2/deepseek.v3.2": {
    "input_cost_per_token": 6.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000185,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-west-2/minimax.minimax-m2.1": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-west-2/moonshotai.kimi-k2-thinking": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "supports_function_calling": true,
    "supports_reasoning": true
  },
  "bedrock/us-west-2/moonshotai.kimi-k2.5": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us-west-2/qwen.qwen3-coder-next": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "bedrock/us.anthropic.claude-3-5-haiku-20241022-v1:0": {
    "cache_creation_input_token_cost": 0.000001,
    "cache_read_input_token_cost": 8E-8,
    "input_cost_per_token": 8E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "cerebras/llama-3.3-70b": {
    "input_cost_per_token": 8.5E-7,
    "litellm_provider": "cerebras",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "cerebras/llama3.1-70b": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "cerebras",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "cerebras/llama3.1-8b": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "cerebras",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "cerebras/gpt-oss-120b": {
    "input_cost_per_token": 3.5E-7,
    "litellm_provider": "cerebras",
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 7.5E-7,
    "source": "https://www.cerebras.ai/blog/openai-gpt-oss-120b-runs-fastest-on-cerebras",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "cerebras/qwen-3-32b": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "cerebras",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 8E-7,
    "source": "https://inference-docs.cerebras.ai/support/pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "cerebras/zai-glm-4.6": {
    "deprecation_date": "2026-01-20",
    "input_cost_per_token": 0.00000225,
    "litellm_provider": "cerebras",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00000275,
    "source": "https://www.cerebras.ai/pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "cerebras/zai-glm-4.7": {
    "input_cost_per_token": 0.00000225,
    "litellm_provider": "cerebras",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00000275,
    "source": "https://www.cerebras.ai/pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "chatgpt-4o-latest": {
    "input_cost_per_token": 0.000005,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "claude-3-5-haiku-20241022": {
    "cache_creation_input_token_cost": 0.000001,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 8E-8,
    "deprecation_date": "2025-10-01",
    "input_cost_per_token": 8E-7,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 264
  },
  "claude-3-5-haiku-latest": {
    "cache_creation_input_token_cost": 0.00000125,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 1E-7,
    "deprecation_date": "2025-10-01",
    "input_cost_per_token": 0.000001,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 264
  },
  "claude-haiku-4-5-20251001": {
    "cache_creation_input_token_cost": 0.00000125,
    "cache_creation_input_token_cost_above_1hr": 0.000002,
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 0.000001,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_computer_use": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "claude-haiku-4-5": {
    "cache_creation_input_token_cost": 0.00000125,
    "cache_creation_input_token_cost_above_1hr": 0.000002,
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 0.000001,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_computer_use": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "claude-3-5-sonnet-20240620": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 3E-7,
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 0.000003,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-3-5-sonnet-20241022": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 3E-7,
    "deprecation_date": "2025-10-01",
    "input_cost_per_token": 0.000003,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-3-5-sonnet-latest": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 3E-7,
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 0.000003,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-3-7-sonnet-20250219": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 3E-7,
    "deprecation_date": "2026-02-19",
    "input_cost_per_token": 0.000003,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-3-7-sonnet-latest": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 3E-7,
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 0.000003,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-3-haiku-20240307": {
    "cache_creation_input_token_cost": 3E-7,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 3E-8,
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00000125,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 264
  },
  "claude-3-opus-20240229": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 0.0000015,
    "deprecation_date": "2026-05-01",
    "input_cost_per_token": 0.000015,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 395
  },
  "claude-3-opus-latest": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 0.0000015,
    "deprecation_date": "2025-03-01",
    "input_cost_per_token": 0.000015,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 395
  },
  "claude-4-opus-20250514": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-4-sonnet-20250514": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost": 3E-7,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-sonnet-4-5": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "claude-sonnet-4-5-20250929": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 346
  },
  "claude-sonnet-4-5-20250929-v1:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-1": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_creation_input_token_cost_above_1hr": 0.00003,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-1-20250805": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_creation_input_token_cost_above_1hr": 0.00003,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "deprecation_date": "2026-08-05",
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-20250514": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_creation_input_token_cost_above_1hr": 0.00003,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "deprecation_date": "2026-05-14",
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-5-20251101": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_1hr": 0.00001,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-5": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_1hr": 0.00001,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-6": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000125,
    "cache_creation_input_token_cost_above_1hr": 0.00001,
    "cache_read_input_token_cost": 5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.000001,
    "input_cost_per_token": 0.000005,
    "input_cost_per_token_above_200k_tokens": 0.00001,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "output_cost_per_token_above_200k_tokens": 0.0000375,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "fast/claude-opus-4-6": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000125,
    "cache_creation_input_token_cost_above_1hr": 0.00001,
    "cache_read_input_token_cost": 5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.000001,
    "input_cost_per_token": 0.00003,
    "input_cost_per_token_above_200k_tokens": 0.00001,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_above_200k_tokens": 0.0000375,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "us/claude-opus-4-6": {
    "cache_creation_input_token_cost": 0.000006875,
    "cache_creation_input_token_cost_above_200k_tokens": 0.00001375,
    "cache_creation_input_token_cost_above_1hr": 0.000011,
    "cache_read_input_token_cost": 5.5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.0000011,
    "input_cost_per_token": 0.0000055,
    "input_cost_per_token_above_200k_tokens": 0.000011,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000275,
    "output_cost_per_token_above_200k_tokens": 0.00004125,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "fast/us/claude-opus-4-6": {
    "cache_creation_input_token_cost": 0.000006875,
    "cache_creation_input_token_cost_above_200k_tokens": 0.00001375,
    "cache_creation_input_token_cost_above_1hr": 0.000011,
    "cache_read_input_token_cost": 5.5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.0000011,
    "input_cost_per_token": 0.00003,
    "input_cost_per_token_above_200k_tokens": 0.000011,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_above_200k_tokens": 0.00004125,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "claude-opus-4-6-20260205": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000125,
    "cache_creation_input_token_cost_above_1hr": 0.00001,
    "cache_read_input_token_cost": 5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.000001,
    "input_cost_per_token": 0.000005,
    "input_cost_per_token_above_200k_tokens": 0.00001,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "output_cost_per_token_above_200k_tokens": 0.0000375,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "fast/claude-opus-4-6-20260205": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000125,
    "cache_creation_input_token_cost_above_1hr": 0.00001,
    "cache_read_input_token_cost": 5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.000001,
    "input_cost_per_token": 0.00003,
    "input_cost_per_token_above_200k_tokens": 0.00001,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_above_200k_tokens": 0.0000375,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "us/claude-opus-4-6-20260205": {
    "cache_creation_input_token_cost": 0.000006875,
    "cache_creation_input_token_cost_above_200k_tokens": 0.00001375,
    "cache_creation_input_token_cost_above_1hr": 0.000011,
    "cache_read_input_token_cost": 5.5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.0000011,
    "input_cost_per_token": 0.0000055,
    "input_cost_per_token_above_200k_tokens": 0.000011,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000275,
    "output_cost_per_token_above_200k_tokens": 0.00004125,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "claude-sonnet-4-20250514": {
    "deprecation_date": "2026-05-14",
    "cache_creation_input_token_cost": 0.00000375,
    "cache_creation_input_token_cost_above_1hr": 0.000006,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "codex-mini-latest": {
    "cache_read_input_token_cost": 3.75E-7,
    "input_cost_per_token": 0.0000015,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.000006,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "cohere.command-r-plus-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_tool_choice": true
  },
  "cohere.command-r-v1:0": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "supports_tool_choice": true
  },
  "cohere.embed-v4:0": {
    "input_cost_per_token": 1.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "mode": "embedding",
    "output_cost_per_token": 0.0,
    "output_vector_size": 1536,
    "supports_embedding_image_input": true
  },
  "cohere/embed-v4.0": {
    "input_cost_per_token": 1.2E-7,
    "litellm_provider": "cohere",
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "mode": "embedding",
    "output_cost_per_token": 0.0,
    "output_vector_size": 1536,
    "supports_embedding_image_input": true
  },
  "command-a-03-2025": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "cohere_chat",
    "max_input_tokens": 256000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "command-r": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "cohere_chat",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "command-r-08-2024": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "cohere_chat",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "command-r-plus": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "cohere_chat",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "command-r-plus-08-2024": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "cohere_chat",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "command-r7b-12-2024": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "cohere_chat",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3.75E-8,
    "source": "https://docs.cohere.com/v2/docs/command-r7b",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "deepseek-chat": {
    "cache_read_input_token_cost": 2.8E-8,
    "input_cost_per_token": 2.8E-7,
    "litellm_provider": "deepseek",
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 4.2E-7,
    "source": "https://api-docs.deepseek.com/quick_start/pricing",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "deepseek-reasoner": {
    "cache_read_input_token_cost": 2.8E-8,
    "input_cost_per_token": 2.8E-7,
    "litellm_provider": "deepseek",
    "max_input_tokens": 131072,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 4.2E-7,
    "source": "https://api-docs.deepseek.com/quick_start/pricing",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false
  },
  "dashscope/qwen-coder": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "dashscope",
    "max_input_tokens": 1000000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "dashscope/qwen-flash": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 997952,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 5E-8,
        "output_cost_per_token": 4E-7,
        "range": [
          0,
          256000.0
        ]
      },
      {
        "input_cost_per_token": 2.5E-7,
        "output_cost_per_token": 0.000002,
        "range": [
          256000.0,
          1000000.0
        ]
      }
    ]
  },
  "dashscope/qwen-flash-2025-07-28": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 997952,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 5E-8,
        "output_cost_per_token": 4E-7,
        "range": [
          0,
          256000.0
        ]
      },
      {
        "input_cost_per_token": 2.5E-7,
        "output_cost_per_token": 0.000002,
        "range": [
          256000.0,
          1000000.0
        ]
      }
    ]
  },
  "dashscope/qwen-plus": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "dashscope",
    "max_input_tokens": 129024,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "dashscope/qwen-plus-2025-01-25": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "dashscope",
    "max_input_tokens": 129024,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "dashscope/qwen-plus-2025-04-28": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "dashscope",
    "max_input_tokens": 129024,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.000004,
    "output_cost_per_token": 0.0000012,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "dashscope/qwen-plus-2025-07-14": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "dashscope",
    "max_input_tokens": 129024,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.000004,
    "output_cost_per_token": 0.0000012,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "dashscope/qwen-plus-2025-07-28": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 997952,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 4E-7,
        "output_cost_per_reasoning_token": 0.000004,
        "output_cost_per_token": 0.0000012,
        "range": [
          0,
          256000.0
        ]
      },
      {
        "input_cost_per_token": 0.0000012,
        "output_cost_per_reasoning_token": 0.000012,
        "output_cost_per_token": 0.0000036,
        "range": [
          256000.0,
          1000000.0
        ]
      }
    ]
  },
  "dashscope/qwen-plus-2025-09-11": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 997952,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 4E-7,
        "output_cost_per_reasoning_token": 0.000004,
        "output_cost_per_token": 0.0000012,
        "range": [
          0,
          256000.0
        ]
      },
      {
        "input_cost_per_token": 0.0000012,
        "output_cost_per_reasoning_token": 0.000012,
        "output_cost_per_token": 0.0000036,
        "range": [
          256000.0,
          1000000.0
        ]
      }
    ]
  },
  "dashscope/qwen-plus-latest": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 997952,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 4E-7,
        "output_cost_per_reasoning_token": 0.000004,
        "output_cost_per_token": 0.0000012,
        "range": [
          0,
          256000.0
        ]
      },
      {
        "input_cost_per_token": 0.0000012,
        "output_cost_per_reasoning_token": 0.000012,
        "output_cost_per_token": 0.0000036,
        "range": [
          256000.0,
          1000000.0
        ]
      }
    ]
  },
  "dashscope/qwen-turbo": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "dashscope",
    "max_input_tokens": 129024,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_reasoning_token": 5E-7,
    "output_cost_per_token": 2E-7,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "dashscope/qwen-turbo-2024-11-01": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "dashscope",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 2E-7,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "dashscope/qwen-turbo-2025-04-28": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "dashscope",
    "max_input_tokens": 1000000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_reasoning_token": 5E-7,
    "output_cost_per_token": 2E-7,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "dashscope/qwen-turbo-latest": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "dashscope",
    "max_input_tokens": 1000000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_reasoning_token": 5E-7,
    "output_cost_per_token": 2E-7,
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "dashscope/qwen3-30b-a3b": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 129024,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "dashscope/qwen3-coder-flash": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 997952,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "cache_read_input_token_cost": 8E-8,
        "input_cost_per_token": 3E-7,
        "output_cost_per_token": 0.0000015,
        "range": [
          0,
          32000.0
        ]
      },
      {
        "cache_read_input_token_cost": 1.2E-7,
        "input_cost_per_token": 5E-7,
        "output_cost_per_token": 0.0000025,
        "range": [
          32000.0,
          128000.0
        ]
      },
      {
        "cache_read_input_token_cost": 2E-7,
        "input_cost_per_token": 8E-7,
        "output_cost_per_token": 0.000004,
        "range": [
          128000.0,
          256000.0
        ]
      },
      {
        "cache_read_input_token_cost": 4E-7,
        "input_cost_per_token": 0.0000016,
        "output_cost_per_token": 0.0000096,
        "range": [
          256000.0,
          1000000.0
        ]
      }
    ]
  },
  "dashscope/qwen3-coder-flash-2025-07-28": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 997952,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 3E-7,
        "output_cost_per_token": 0.0000015,
        "range": [
          0,
          32000.0
        ]
      },
      {
        "input_cost_per_token": 5E-7,
        "output_cost_per_token": 0.0000025,
        "range": [
          32000.0,
          128000.0
        ]
      },
      {
        "input_cost_per_token": 8E-7,
        "output_cost_per_token": 0.000004,
        "range": [
          128000.0,
          256000.0
        ]
      },
      {
        "input_cost_per_token": 0.0000016,
        "output_cost_per_token": 0.0000096,
        "range": [
          256000.0,
          1000000.0
        ]
      }
    ]
  },
  "dashscope/qwen3-coder-plus": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 997952,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "cache_read_input_token_cost": 1E-7,
        "input_cost_per_token": 0.000001,
        "output_cost_per_token": 0.000005,
        "range": [
          0,
          32000.0
        ]
      },
      {
        "cache_read_input_token_cost": 1.8E-7,
        "input_cost_per_token": 0.0000018,
        "output_cost_per_token": 0.000009,
        "range": [
          32000.0,
          128000.0
        ]
      },
      {
        "cache_read_input_token_cost": 3E-7,
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "range": [
          128000.0,
          256000.0
        ]
      },
      {
        "cache_read_input_token_cost": 6E-7,
        "input_cost_per_token": 0.000006,
        "output_cost_per_token": 0.00006,
        "range": [
          256000.0,
          1000000.0
        ]
      }
    ]
  },
  "dashscope/qwen3-coder-plus-2025-07-22": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 997952,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 0.000001,
        "output_cost_per_token": 0.000005,
        "range": [
          0,
          32000.0
        ]
      },
      {
        "input_cost_per_token": 0.0000018,
        "output_cost_per_token": 0.000009,
        "range": [
          32000.0,
          128000.0
        ]
      },
      {
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "range": [
          128000.0,
          256000.0
        ]
      },
      {
        "input_cost_per_token": 0.000006,
        "output_cost_per_token": 0.00006,
        "range": [
          256000.0,
          1000000.0
        ]
      }
    ]
  },
  "dashscope/qwen3-max-preview": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 258048,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 0.0000012,
        "output_cost_per_token": 0.000006,
        "range": [
          0,
          32000.0
        ]
      },
      {
        "input_cost_per_token": 0.0000024,
        "output_cost_per_token": 0.000012,
        "range": [
          32000.0,
          128000.0
        ]
      },
      {
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "range": [
          128000.0,
          252000.0
        ]
      }
    ]
  },
  "dashscope/qwen3-max": {
    "litellm_provider": "dashscope",
    "max_input_tokens": 258048,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "source": "https://www.alibabacloud.com/help/en/model-studio/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "tiered_pricing": [
      {
        "input_cost_per_token": 0.0000012,
        "output_cost_per_token": 0.000006,
        "range": [
          0,
          32000.0
        ]
      },
      {
        "input_cost_per_token": 0.0000024,
        "output_cost_per_token": 0.000012,
        "range": [
          32000.0,
          128000.0
        ]
      },
      {
        "input_cost_per_token": 0.000003,
        "output_cost_per_token": 0.000015,
        "range": [
          128000.0,
          252000.0
        ]
      }
    ]
  },
  "databricks/databricks-claude-3-7-sonnet": {
    "input_cost_per_token": 0.0000029999900000000002,
    "input_dbu_cost_per_token": 0.000042857,
    "litellm_provider": "databricks",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.000015000020000000002,
    "output_dbu_cost_per_token": 0.000214286,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "databricks/databricks-claude-haiku-4-5": {
    "input_cost_per_token": 0.00000100002,
    "input_dbu_cost_per_token": 0.000014286,
    "litellm_provider": "databricks",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.00000500003,
    "output_dbu_cost_per_token": 0.000071429,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "databricks/databricks-claude-opus-4": {
    "input_cost_per_token": 0.000015000020000000002,
    "input_dbu_cost_per_token": 0.000214286,
    "litellm_provider": "databricks",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.00007500003000000001,
    "output_dbu_cost_per_token": 0.001071429,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "databricks/databricks-claude-opus-4-1": {
    "input_cost_per_token": 0.000015000020000000002,
    "input_dbu_cost_per_token": 0.000214286,
    "litellm_provider": "databricks",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.00007500003000000001,
    "output_dbu_cost_per_token": 0.001071429,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "databricks/databricks-claude-opus-4-5": {
    "input_cost_per_token": 0.00000500003,
    "input_dbu_cost_per_token": 0.000071429,
    "litellm_provider": "databricks",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.000025000010000000002,
    "output_dbu_cost_per_token": 0.000357143,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "databricks/databricks-claude-sonnet-4": {
    "input_cost_per_token": 0.0000029999900000000002,
    "input_dbu_cost_per_token": 0.000042857,
    "litellm_provider": "databricks",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.000015000020000000002,
    "output_dbu_cost_per_token": 0.000214286,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "databricks/databricks-claude-sonnet-4-1": {
    "input_cost_per_token": 0.0000029999900000000002,
    "input_dbu_cost_per_token": 0.000042857,
    "litellm_provider": "databricks",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.000015000020000000002,
    "output_dbu_cost_per_token": 0.000214286,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "databricks/databricks-claude-sonnet-4-5": {
    "input_cost_per_token": 0.0000029999900000000002,
    "input_dbu_cost_per_token": 0.000042857,
    "litellm_provider": "databricks",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.000015000020000000002,
    "output_dbu_cost_per_token": 0.000214286,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "databricks/databricks-gemini-2-5-flash": {
    "input_cost_per_token": 3.0001999999999996E-7,
    "input_dbu_cost_per_token": 0.000004285999999999999,
    "litellm_provider": "databricks",
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_tokens": 65535,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.00000249998,
    "output_dbu_cost_per_token": 0.000035714,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "databricks/databricks-gemini-2-5-pro": {
    "input_cost_per_token": 0.00000124999,
    "input_dbu_cost_per_token": 0.000017857,
    "litellm_provider": "databricks",
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.000009999990000000002,
    "output_dbu_cost_per_token": 0.000142857,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "databricks/databricks-gemma-3-12b": {
    "input_cost_per_token": 1.5000999999999998E-7,
    "input_dbu_cost_per_token": 0.0000021429999999999996,
    "litellm_provider": "databricks",
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 5.0001E-7,
    "output_dbu_cost_per_token": 0.000007143,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
  },
  "databricks/databricks-gpt-5": {
    "input_cost_per_token": 0.00000124999,
    "input_dbu_cost_per_token": 0.000017857,
    "litellm_provider": "databricks",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.000009999990000000002,
    "output_dbu_cost_per_token": 0.000142857,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving"
  },
  "databricks/databricks-gpt-5-1": {
    "input_cost_per_token": 0.00000124999,
    "input_dbu_cost_per_token": 0.000017857,
    "litellm_provider": "databricks",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.000009999990000000002,
    "output_dbu_cost_per_token": 0.000142857,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving"
  },
  "databricks/databricks-gpt-5-mini": {
    "input_cost_per_token": 2.4997000000000006E-7,
    "input_dbu_cost_per_token": 0.000003571,
    "litellm_provider": "databricks",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.0000019999700000000004,
    "output_dbu_cost_per_token": 0.000028571,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving"
  },
  "databricks/databricks-gpt-5-nano": {
    "input_cost_per_token": 4.998E-8,
    "input_dbu_cost_per_token": 7.14E-7,
    "litellm_provider": "databricks",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 3.9998000000000007E-7,
    "output_dbu_cost_per_token": 0.000005714000000000001,
    "source": "https://www.databricks.com/product/pricing/proprietary-foundation-model-serving"
  },
  "databricks/databricks-gpt-oss-120b": {
    "input_cost_per_token": 1.5000999999999998E-7,
    "input_dbu_cost_per_token": 0.0000021429999999999996,
    "litellm_provider": "databricks",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 5.9997E-7,
    "output_dbu_cost_per_token": 0.000008571,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
  },
  "databricks/databricks-gpt-oss-20b": {
    "input_cost_per_token": 7E-8,
    "input_dbu_cost_per_token": 0.000001,
    "litellm_provider": "databricks",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 3.0001999999999996E-7,
    "output_dbu_cost_per_token": 0.000004285999999999999,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
  },
  "databricks/databricks-llama-4-maverick": {
    "input_cost_per_token": 5.0001E-7,
    "input_dbu_cost_per_token": 0.000007143,
    "litellm_provider": "databricks",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Databricks documentation now provides both DBU costs (_dbu_cost_per_token) and dollar costs(_cost_per_token)."
    },
    "mode": "chat",
    "output_cost_per_token": 0.0000015000300000000002,
    "output_dbu_cost_per_token": 0.000021429,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true
  },
  "databricks/databricks-meta-llama-3-1-405b-instruct": {
    "input_cost_per_token": 0.00000500003,
    "input_dbu_cost_per_token": 0.000071429,
    "litellm_provider": "databricks",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.000015000020000000002,
    "output_dbu_cost_per_token": 0.000214286,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true
  },
  "databricks/databricks-meta-llama-3-1-8b-instruct": {
    "input_cost_per_token": 1.5000999999999998E-7,
    "input_dbu_cost_per_token": 0.0000021429999999999996,
    "litellm_provider": "databricks",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 4.5003000000000007E-7,
    "output_dbu_cost_per_token": 0.000006429000000000001,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving"
  },
  "databricks/databricks-meta-llama-3-3-70b-instruct": {
    "input_cost_per_token": 5.0001E-7,
    "input_dbu_cost_per_token": 0.000007143,
    "litellm_provider": "databricks",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.0000015000300000000002,
    "output_dbu_cost_per_token": 0.000021429,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true
  },
  "databricks/databricks-meta-llama-3-70b-instruct": {
    "input_cost_per_token": 0.00000100002,
    "input_dbu_cost_per_token": 0.000014286,
    "litellm_provider": "databricks",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "metadata": {
      "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
    },
    "mode": "chat",
    "output_cost_per_token": 0.0000029999900000000002,
    "output_dbu_cost_per_token": 0.000042857,
    "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
    "supports_tool_choice": true
  },
  "deepinfra/NousResearch/Hermes-3-Llama-3.1-405B": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 0.000001,
    "output_cost_per_token": 0.000001,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/NousResearch/Hermes-3-Llama-3.1-70B": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 3E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": false
  },
  "deepinfra/Qwen/QwQ-32B": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1.5E-7,
    "output_cost_per_token": 4E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/Qwen/Qwen2.5-VL-32B-Instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 6E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "deepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 9E-8,
    "output_cost_per_token": 6E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000029,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 4E-7,
    "output_cost_per_token": 0.0000016,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 2.9E-7,
    "output_cost_per_token": 0.0000012,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/Qwen/Qwen3-Next-80B-A3B-Instruct": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 1.4E-7,
    "output_cost_per_token": 0.0000014,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/Qwen/Qwen3-Next-80B-A3B-Thinking": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 1.4E-7,
    "output_cost_per_token": 0.0000014,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/Sao10K/L3.1-70B-Euryale-v2.2": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 6.5E-7,
    "output_cost_per_token": 7.5E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": false
  },
  "deepinfra/Sao10K/L3.3-70B-Euryale-v2.3": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 6.5E-7,
    "output_cost_per_token": 7.5E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": false
  },
  "deepinfra/anthropic/claude-3-7-sonnet-latest": {
    "max_tokens": 200000,
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "input_cost_per_token": 0.0000033,
    "output_cost_per_token": 0.0000165,
    "cache_read_input_token_cost": 3.3E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/anthropic/claude-4-opus": {
    "max_tokens": 200000,
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "input_cost_per_token": 0.0000165,
    "output_cost_per_token": 0.0000825,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/anthropic/claude-4-sonnet": {
    "max_tokens": 200000,
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "input_cost_per_token": 0.0000033,
    "output_cost_per_token": 0.0000165,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/deepseek-ai/DeepSeek-R1": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 7E-7,
    "output_cost_per_token": 0.0000024,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/deepseek-ai/DeepSeek-R1-0528": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 5E-7,
    "output_cost_per_token": 0.00000215,
    "cache_read_input_token_cost": 4E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 6E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": false
  },
  "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2.7E-7,
    "output_cost_per_token": 2.7E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/deepseek-ai/DeepSeek-V3": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 3.8E-7,
    "output_cost_per_token": 8.9E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/deepseek-ai/DeepSeek-V3-0324": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 2.5E-7,
    "output_cost_per_token": 8.8E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/deepseek-ai/DeepSeek-V3.1": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 2.7E-7,
    "output_cost_per_token": 0.000001,
    "cache_read_input_token_cost": 2.16E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true,
    "supports_reasoning": true
  },
  "deepinfra/deepseek-ai/DeepSeek-V3.1-Terminus": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 2.7E-7,
    "output_cost_per_token": 0.000001,
    "cache_read_input_token_cost": 2.16E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/google/gemini-2.0-flash-001": {
    "deprecation_date": "2026-03-31",
    "max_tokens": 1000000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 4E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/google/gemini-2.5-flash": {
    "max_tokens": 1000000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000025,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/google/gemini-2.5-pro": {
    "max_tokens": 1000000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "input_cost_per_token": 0.00000125,
    "output_cost_per_token": 0.00001,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/google/gemma-3-12b-it": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 5E-8,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/google/gemma-3-27b-it": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-8,
    "output_cost_per_token": 1.6E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/google/gemma-3-4b-it": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 4E-8,
    "output_cost_per_token": 8E-8,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 4.9E-8,
    "output_cost_per_token": 4.9E-8,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": false
  },
  "deepinfra/meta-llama/Llama-3.2-3B-Instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-8,
    "output_cost_per_token": 2E-8,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/meta-llama/Llama-3.3-70B-Instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2.3E-7,
    "output_cost_per_token": 4E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1.3E-7,
    "output_cost_per_token": 3.9E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
    "max_tokens": 1048576,
    "max_input_tokens": 1048576,
    "max_output_tokens": 1048576,
    "input_cost_per_token": 1.5E-7,
    "output_cost_per_token": 6E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
    "max_tokens": 327680,
    "max_input_tokens": 327680,
    "max_output_tokens": 327680,
    "input_cost_per_token": 8E-8,
    "output_cost_per_token": 3E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/meta-llama/Llama-Guard-3-8B": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 5.5E-8,
    "output_cost_per_token": 5.5E-8,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": false
  },
  "deepinfra/meta-llama/Llama-Guard-4-12B": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 1.8E-7,
    "output_cost_per_token": 1.8E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": false
  },
  "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 4E-7,
    "output_cost_per_token": 4E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 2.8E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 3E-8,
    "output_cost_per_token": 5E-8,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-8,
    "output_cost_per_token": 3E-8,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/mistralai/Mistral-Nemo-Instruct-2407": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-8,
    "output_cost_per_token": 4E-8,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 7.5E-8,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/moonshotai/Kimi-K2-Instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 5E-7,
    "output_cost_per_token": 0.000002,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/moonshotai/Kimi-K2-Instruct-0905": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 5E-7,
    "output_cost_per_token": 0.000002,
    "cache_read_input_token_cost": 4E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 6E-7,
    "output_cost_per_token": 6E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/nvidia/Llama-3.3-Nemotron-Super-49B-v1.5": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 4E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/nvidia/NVIDIA-Nemotron-Nano-9B-v2": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 4E-8,
    "output_cost_per_token": 1.6E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/openai/gpt-oss-120b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 5E-8,
    "output_cost_per_token": 4.5E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/openai/gpt-oss-20b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 4E-8,
    "output_cost_per_token": 1.5E-7,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepinfra/zai-org/GLM-4.5": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 4E-7,
    "output_cost_per_token": 0.0000016,
    "litellm_provider": "deepinfra",
    "mode": "chat",
    "supports_tool_choice": true
  },
  "deepseek/deepseek-chat": {
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 2.8E-8,
    "input_cost_per_token": 2.8E-7,
    "input_cost_per_token_cache_hit": 2.8E-8,
    "litellm_provider": "deepseek",
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 4.2E-7,
    "source": "https://api-docs.deepseek.com/quick_start/pricing",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "deepseek/deepseek-coder": {
    "input_cost_per_token": 1.4E-7,
    "input_cost_per_token_cache_hit": 1.4E-8,
    "litellm_provider": "deepseek",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 2.8E-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true
  },
  "deepseek/deepseek-reasoner": {
    "cache_read_input_token_cost": 2.8E-8,
    "input_cost_per_token": 2.8E-7,
    "input_cost_per_token_cache_hit": 2.8E-8,
    "litellm_provider": "deepseek",
    "max_input_tokens": 131072,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 4.2E-7,
    "source": "https://api-docs.deepseek.com/quick_start/pricing",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_assistant_prefill": true,
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false
  },
  "deepseek/deepseek-v3.2": {
    "input_cost_per_token": 2.8E-7,
    "input_cost_per_token_cache_hit": 2.8E-8,
    "litellm_provider": "deepseek",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "deepseek.v3-v1:0": {
    "input_cost_per_token": 5.8E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 163840,
    "max_output_tokens": 81920,
    "max_tokens": 81920,
    "mode": "chat",
    "output_cost_per_token": 0.00000168,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "deepseek.v3.2": {
    "input_cost_per_token": 6.2E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000185,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "glm-4-7-251222": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "volcengine",
    "max_input_tokens": 204800,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "kimi-k2-thinking-251104": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "volcengine",
    "max_input_tokens": 229376,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "eu.amazon.nova-lite-v1:0": {
    "input_cost_per_token": 7.8E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 3.12E-7,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "eu.amazon.nova-micro-v1:0": {
    "input_cost_per_token": 4.6E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 1.84E-7,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true
  },
  "eu.amazon.nova-pro-v1:0": {
    "input_cost_per_token": 0.00000105,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 0.0000042,
    "source": "https://aws.amazon.com/bedrock/pricing/",
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "eu.anthropic.claude-3-5-haiku-20241022-v1:0": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000125,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "eu.anthropic.claude-haiku-4-5-20251001-v1:0": {
    "cache_creation_input_token_cost": 0.000001375,
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token": 0.0000011,
    "deprecation_date": "2026-10-15",
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000055,
    "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "eu.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "eu.anthropic.claude-3-7-sonnet-20250219-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "eu.anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "eu.anthropic.claude-3-opus-20240229-v1:0": {
    "input_cost_per_token": 0.000015,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "eu.anthropic.claude-3-sonnet-20240229-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "eu.anthropic.claude-opus-4-1-20250805-v1:0": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "eu.anthropic.claude-opus-4-20250514-v1:0": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "eu.anthropic.claude-sonnet-4-20250514-v1:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "eu.anthropic.claude-sonnet-4-5-20250929-v1:0": {
    "cache_creation_input_token_cost": 0.000004125,
    "cache_read_input_token_cost": 3.3E-7,
    "input_cost_per_token": 0.0000033,
    "input_cost_per_token_above_200k_tokens": 0.0000066,
    "output_cost_per_token_above_200k_tokens": 0.00002475,
    "cache_creation_input_token_cost_above_200k_tokens": 0.00000825,
    "cache_read_input_token_cost_above_200k_tokens": 6.6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000165,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "eu.meta.llama3-2-1b-instruct-v1:0": {
    "input_cost_per_token": 1.3E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1.3E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "eu.meta.llama3-2-3b-instruct-v1:0": {
    "input_cost_per_token": 1.9E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1.9E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "eu.mistral.pixtral-large-2502-v1:0": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 20480,
    "max_tokens": 20480,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 160000,
    "max_output_tokens": 160000,
    "max_tokens": 160000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-basic": {
    "input_cost_per_token": 5.5E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 20480,
    "max_tokens": 20480,
    "mode": "chat",
    "output_cost_per_token": 0.00000219,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-v3": {
    "input_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 9E-7,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-v3-0324": {
    "input_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 9E-7,
    "source": "https://fireworks.ai/models/fireworks/deepseek-v3-0324",
    "supports_response_schema": true,
    "supports_tool_choice": false
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-v3p1": {
    "input_cost_per_token": 5.6E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000168,
    "source": "https://fireworks.ai/pricing",
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-v3p1-terminus": {
    "input_cost_per_token": 5.6E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000168,
    "source": "https://fireworks.ai/pricing",
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-v3p2": {
    "input_cost_per_token": 5.6E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000168,
    "source": "https://fireworks.ai/models/fireworks/deepseek-v3p2",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/glm-4p5": {
    "input_cost_per_token": 5.5E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 96000,
    "max_tokens": 96000,
    "mode": "chat",
    "output_cost_per_token": 0.00000219,
    "source": "https://fireworks.ai/models/fireworks/glm-4p5",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/glm-4p5-air": {
    "input_cost_per_token": 2.2E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 96000,
    "max_tokens": 96000,
    "mode": "chat",
    "output_cost_per_token": 8.8E-7,
    "source": "https://artificialanalysis.ai/models/glm-4-5-air",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/glm-4p6": {
    "input_cost_per_token": 5.5E-7,
    "output_cost_per_token": 0.00000219,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 202800,
    "max_output_tokens": 202800,
    "max_tokens": 202800,
    "mode": "chat",
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/gpt-oss-120b": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/gpt-oss-20b": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2E-7,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://fireworks.ai/models/fireworks/kimi-k2-instruct",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/kimi-k2-instruct-0905": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 262144,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://app.fireworks.ai/models/fireworks/kimi-k2-instruct-0905",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/kimi-k2-thinking": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "fireworks_ai/accounts/fireworks/models/kimi-k2p5": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "source": "https://fireworks.ai/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic": {
    "input_cost_per_token": 2.2E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 8.8E-7,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false
  },
  "fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "fireworks_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "source": "https://fireworks.ai/pricing",
    "supports_response_schema": true,
    "supports_tool_choice": false
  },
  "ft:gpt-4o-2024-08-06": {
    "cache_read_input_token_cost": 0.000001875,
    "input_cost_per_token": 0.00000375,
    "input_cost_per_token_batches": 0.000001875,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "output_cost_per_token_batches": 0.0000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "ft:gpt-4o-2024-11-20": {
    "cache_creation_input_token_cost": 0.000001875,
    "input_cost_per_token": 0.00000375,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "ft:gpt-4o-mini-2024-07-18": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 3E-7,
    "input_cost_per_token_batches": 1.5E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "output_cost_per_token_batches": 6E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "ft:gpt-4.1-2025-04-14": {
    "cache_read_input_token_cost": 7.5E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_batches": 0.0000015,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000012,
    "output_cost_per_token_batches": 0.000006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "ft:gpt-4.1-mini-2025-04-14": {
    "cache_read_input_token_cost": 2E-7,
    "input_cost_per_token": 8E-7,
    "input_cost_per_token_batches": 4E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0000032,
    "output_cost_per_token_batches": 0.0000016,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "ft:gpt-4.1-nano-2025-04-14": {
    "cache_read_input_token_cost": 5E-8,
    "input_cost_per_token": 2E-7,
    "input_cost_per_token_batches": 1E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 8E-7,
    "output_cost_per_token_batches": 4E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "ft:o4-mini-2025-04-16": {
    "cache_read_input_token_cost": 0.000001,
    "input_cost_per_token": 0.000004,
    "input_cost_per_token_batches": 0.000002,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.000016,
    "output_cost_per_token_batches": 0.000008,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "gemini-1.5-flash": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 0.000002,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
    "input_cost_per_character": 1.875E-8,
    "input_cost_per_character_above_128k_tokens": 2.5E-7,
    "input_cost_per_image": 0.00002,
    "input_cost_per_image_above_128k_tokens": 0.00004,
    "input_cost_per_token": 7.5E-8,
    "input_cost_per_token_above_128k_tokens": 0.000001,
    "input_cost_per_video_per_second": 0.00002,
    "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 7.5E-8,
    "output_cost_per_character_above_128k_tokens": 1.5E-7,
    "output_cost_per_token": 3E-7,
    "output_cost_per_token_above_128k_tokens": 6E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-flash-001": {
    "deprecation_date": "2025-05-24",
    "input_cost_per_audio_per_second": 0.000002,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
    "input_cost_per_character": 1.875E-8,
    "input_cost_per_character_above_128k_tokens": 2.5E-7,
    "input_cost_per_image": 0.00002,
    "input_cost_per_image_above_128k_tokens": 0.00004,
    "input_cost_per_token": 7.5E-8,
    "input_cost_per_token_above_128k_tokens": 0.000001,
    "input_cost_per_video_per_second": 0.00002,
    "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 7.5E-8,
    "output_cost_per_character_above_128k_tokens": 1.5E-7,
    "output_cost_per_token": 3E-7,
    "output_cost_per_token_above_128k_tokens": 6E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-flash-002": {
    "deprecation_date": "2025-09-24",
    "input_cost_per_audio_per_second": 0.000002,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
    "input_cost_per_character": 1.875E-8,
    "input_cost_per_character_above_128k_tokens": 2.5E-7,
    "input_cost_per_image": 0.00002,
    "input_cost_per_image_above_128k_tokens": 0.00004,
    "input_cost_per_token": 7.5E-8,
    "input_cost_per_token_above_128k_tokens": 0.000001,
    "input_cost_per_video_per_second": 0.00002,
    "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 7.5E-8,
    "output_cost_per_character_above_128k_tokens": 1.5E-7,
    "output_cost_per_token": 3E-7,
    "output_cost_per_token_above_128k_tokens": 6E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-flash-exp-0827": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 0.000002,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
    "input_cost_per_character": 1.875E-8,
    "input_cost_per_character_above_128k_tokens": 2.5E-7,
    "input_cost_per_image": 0.00002,
    "input_cost_per_image_above_128k_tokens": 0.00004,
    "input_cost_per_token": 4.688E-9,
    "input_cost_per_token_above_128k_tokens": 0.000001,
    "input_cost_per_video_per_second": 0.00002,
    "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 1.875E-8,
    "output_cost_per_character_above_128k_tokens": 3.75E-8,
    "output_cost_per_token": 4.6875E-9,
    "output_cost_per_token_above_128k_tokens": 9.375E-9,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-flash-preview-0514": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 0.000002,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.000004,
    "input_cost_per_character": 1.875E-8,
    "input_cost_per_character_above_128k_tokens": 2.5E-7,
    "input_cost_per_image": 0.00002,
    "input_cost_per_image_above_128k_tokens": 0.00004,
    "input_cost_per_token": 7.5E-8,
    "input_cost_per_token_above_128k_tokens": 0.000001,
    "input_cost_per_video_per_second": 0.00002,
    "input_cost_per_video_per_second_above_128k_tokens": 0.00004,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 1.875E-8,
    "output_cost_per_character_above_128k_tokens": 3.75E-8,
    "output_cost_per_token": 4.6875E-9,
    "output_cost_per_token_above_128k_tokens": 9.375E-9,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-pro": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125E-7,
    "input_cost_per_character_above_128k_tokens": 6.25E-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_128k_tokens": 0.0000025,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 0.000005,
    "output_cost_per_token_above_128k_tokens": 0.00001,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-pro-001": {
    "deprecation_date": "2025-05-24",
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125E-7,
    "input_cost_per_character_above_128k_tokens": 6.25E-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_128k_tokens": 0.0000025,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 0.000005,
    "output_cost_per_token_above_128k_tokens": 0.00001,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-pro-002": {
    "deprecation_date": "2025-09-24",
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125E-7,
    "input_cost_per_character_above_128k_tokens": 6.25E-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_128k_tokens": 0.0000025,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 0.000005,
    "output_cost_per_token_above_128k_tokens": 0.00001,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-pro-preview-0215": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125E-7,
    "input_cost_per_character_above_128k_tokens": 6.25E-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 7.8125E-8,
    "input_cost_per_token_above_128k_tokens": 1.5625E-7,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 3.125E-7,
    "output_cost_per_token_above_128k_tokens": 6.25E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gemini-1.5-pro-preview-0409": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125E-7,
    "input_cost_per_character_above_128k_tokens": 6.25E-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 7.8125E-8,
    "input_cost_per_token_above_128k_tokens": 1.5625E-7,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 3.125E-7,
    "output_cost_per_token_above_128k_tokens": 6.25E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "gemini-1.5-pro-preview-0514": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 0.00003125,
    "input_cost_per_audio_per_second_above_128k_tokens": 0.0000625,
    "input_cost_per_character": 3.125E-7,
    "input_cost_per_character_above_128k_tokens": 6.25E-7,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 7.8125E-8,
    "input_cost_per_token_above_128k_tokens": 1.5625E-7,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0.00000125,
    "output_cost_per_character_above_128k_tokens": 0.0000025,
    "output_cost_per_token": 3.125E-7,
    "output_cost_per_token_above_128k_tokens": 6.25E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gemini-2.0-flash": {
    "cache_read_input_token_cost": 2.5E-8,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-001": {
    "cache_read_input_token_cost": 3.75E-8,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-exp": {
    "cache_read_input_token_cost": 3.75E-8,
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 1.5E-7,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 6E-7,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-lite": {
    "cache_read_input_token_cost": 1.875E-8,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7.5E-8,
    "input_cost_per_token": 7.5E-8,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 50,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-lite-001": {
    "cache_read_input_token_cost": 1.875E-8,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7.5E-8,
    "input_cost_per_token": 7.5E-8,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 50,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-live-preview-04-09": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.000003,
    "input_cost_per_image": 0.000003,
    "input_cost_per_token": 5E-7,
    "input_cost_per_video_per_second": 0.000003,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_audio_token": 0.000012,
    "output_cost_per_token": 0.000002,
    "rpm": 10,
    "source": "https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini#gemini-2-0-flash-live-preview-04-09",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini-2.0-flash-preview-image-generation": {
    "deprecation_date": "2025-11-14",
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-thinking-exp": {
    "deprecation_date": "2025-12-02",
    "cache_read_input_token_cost": 0.0,
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-thinking-exp-01-21": {
    "deprecation_date": "2025-12-02",
    "cache_read_input_token_cost": 0.0,
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 65536,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": false,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-pro-exp-02-05": {
    "cache_read_input_token_cost": 3.125E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash": {
    "cache_read_input_token_cost": 3E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-image-preview": {
    "deprecation_date": "2026-01-15",
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_image_token": 3E-7,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "image_generation",
    "output_cost_per_image": 0.039,
    "output_cost_per_image_token": 0.00003,
    "output_cost_per_reasoning_token": 0.00003,
    "output_cost_per_token": 0.00003,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000
  },
  "gemini-2.5-flash-lite": {
    "cache_read_input_token_cost": 1E-8,
    "input_cost_per_audio_token": 3E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4E-7,
    "output_cost_per_token": 4E-7,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-lite-preview-09-2025": {
    "cache_read_input_token_cost": 1E-8,
    "input_cost_per_audio_token": 3E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4E-7,
    "output_cost_per_token": 4E-7,
    "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-preview-09-2025": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-live-2.5-flash-preview-native-audio-09-2025": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.000003,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_audio_token": 0.000012,
    "output_cost_per_token": 0.000002,
    "source": "https://ai.google.dev/gemini-api/docs/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini/gemini-live-2.5-flash-preview-native-audio-09-2025": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.000003,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_audio_token": 0.000012,
    "output_cost_per_token": 0.000002,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000
  },
  "gemini-2.5-flash-lite-preview-06-17": {
    "deprecation_date": "2025-11-18",
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_audio_token": 5E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4E-7,
    "output_cost_per_token": 4E-7,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-preview-04-17": {
    "cache_read_input_token_cost": 3.75E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000035,
    "output_cost_per_token": 6E-7,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-preview-05-20": {
    "deprecation_date": "2025-11-18",
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-pro": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "cache_creation_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3-pro-preview": {
    "cache_read_input_token_cost": 2E-7,
    "cache_read_input_token_cost_above_200k_tokens": 4E-7,
    "cache_creation_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_above_200k_tokens": 0.000004,
    "input_cost_per_token_batches": 0.000001,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.000012,
    "output_cost_per_token_above_200k_tokens": 0.000018,
    "output_cost_per_token_batches": 0.000006,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "supports_native_streaming": true
  },
  "vertex_ai/gemini-3-pro-preview": {
    "cache_read_input_token_cost": 2E-7,
    "cache_read_input_token_cost_above_200k_tokens": 4E-7,
    "cache_creation_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_above_200k_tokens": 0.000004,
    "input_cost_per_token_batches": 0.000001,
    "litellm_provider": "vertex_ai",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.000012,
    "output_cost_per_token_above_200k_tokens": 0.000018,
    "output_cost_per_token_batches": 0.000006,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "supports_native_streaming": true
  },
  "vertex_ai/gemini-3-flash-preview": {
    "cache_read_input_token_cost": 5E-8,
    "input_cost_per_token": 5E-7,
    "input_cost_per_audio_token": 0.000001,
    "litellm_provider": "vertex_ai",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "supports_native_streaming": true
  },
  "gemini-2.5-pro-exp-03-25": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-pro-preview-03-25": {
    "deprecation_date": "2025-12-02",
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_audio_token": 0.00000125,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-pro-preview-05-06": {
    "deprecation_date": "2025-12-02",
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_audio_token": 0.00000125,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supported_regions": [
      "global"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-pro-preview-06-05": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_audio_token": 0.00000125,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-pro-preview-tts": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "audio"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-robotics-er-1.5-preview": {
    "cache_read_input_token_cost": 0,
    "input_cost_per_token": 3E-7,
    "input_cost_per_audio_token": 0.000001,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_tokens": 65535,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "output_cost_per_reasoning_token": 0.0000025,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-robotics-er-1-5-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "video",
      "audio"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true
  },
  "gemini/gemini-robotics-er-1.5-preview": {
    "cache_read_input_token_cost": 0,
    "input_cost_per_token": 3E-7,
    "input_cost_per_audio_token": 0.000001,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_tokens": 65535,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "output_cost_per_reasoning_token": 0.0000025,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-robotics-er-1-5-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "video",
      "audio"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000,
    "rpm": 10
  },
  "gemini-2.5-computer-use-preview-10-2025": {
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "vertex_ai-language-models",
    "max_images_per_prompt": 3000,
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/computer-use",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-flash-experimental": {
    "input_cost_per_character": 0,
    "input_cost_per_token": 0,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_token": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
    "supports_function_calling": false,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "gemini-pro-experimental": {
    "input_cost_per_character": 0,
    "input_cost_per_token": 0,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_token": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
    "supports_function_calling": false,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "gemini/gemini-1.5-flash": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_token": 7.5E-8,
    "input_cost_per_token_above_128k_tokens": 1.5E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "output_cost_per_token_above_128k_tokens": 6E-7,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-flash-001": {
    "cache_creation_input_token_cost": 0.000001,
    "cache_read_input_token_cost": 1.875E-8,
    "deprecation_date": "2025-05-24",
    "input_cost_per_token": 7.5E-8,
    "input_cost_per_token_above_128k_tokens": 1.5E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "output_cost_per_token_above_128k_tokens": 6E-7,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-flash-002": {
    "cache_creation_input_token_cost": 0.000001,
    "cache_read_input_token_cost": 1.875E-8,
    "deprecation_date": "2025-09-24",
    "input_cost_per_token": 7.5E-8,
    "input_cost_per_token_above_128k_tokens": 1.5E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "output_cost_per_token_above_128k_tokens": 6E-7,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-flash-8b": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 4000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-flash-8b-exp-0827": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 4000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-flash-8b-exp-0924": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 4000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-flash-exp-0827": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-flash-latest": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_token": 7.5E-8,
    "input_cost_per_token_above_128k_tokens": 1.5E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "output_cost_per_token_above_128k_tokens": 6E-7,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-pro": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_token": 0.0000035,
    "input_cost_per_token_above_128k_tokens": 0.000007,
    "litellm_provider": "gemini",
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000105,
    "output_cost_per_token_above_128k_tokens": 0.000021,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-pro-001": {
    "deprecation_date": "2025-05-24",
    "input_cost_per_token": 0.0000035,
    "input_cost_per_token_above_128k_tokens": 0.000007,
    "litellm_provider": "gemini",
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000105,
    "output_cost_per_token_above_128k_tokens": 0.000021,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-pro-002": {
    "deprecation_date": "2025-09-24",
    "input_cost_per_token": 0.0000035,
    "input_cost_per_token_above_128k_tokens": 0.000007,
    "litellm_provider": "gemini",
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000105,
    "output_cost_per_token_above_128k_tokens": 0.000021,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-pro-exp-0801": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_token": 0.0000035,
    "input_cost_per_token_above_128k_tokens": 0.000007,
    "litellm_provider": "gemini",
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000105,
    "output_cost_per_token_above_128k_tokens": 0.000021,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-pro-exp-0827": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-1.5-pro-latest": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_token": 0.0000035,
    "input_cost_per_token_above_128k_tokens": 0.000007,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000105,
    "output_cost_per_token_above_128k_tokens": 0.000021,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-2.0-flash": {
    "cache_read_input_token_cost": 2.5E-8,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "rpm": 10000,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000
  },
  "gemini/gemini-2.0-flash-001": {
    "cache_read_input_token_cost": 2.5E-8,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "rpm": 10000,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000
  },
  "gemini/gemini-2.0-flash-exp": {
    "cache_read_input_token_cost": 0.0,
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 10,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 4000000
  },
  "gemini/gemini-2.0-flash-lite": {
    "cache_read_input_token_cost": 1.875E-8,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7.5E-8,
    "input_cost_per_token": 7.5E-8,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 50,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "rpm": 4000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 4000000
  },
  "gemini/gemini-2.0-flash-lite-preview-02-05": {
    "deprecation_date": "2025-12-02",
    "cache_read_input_token_cost": 1.875E-8,
    "input_cost_per_audio_token": 7.5E-8,
    "input_cost_per_token": 7.5E-8,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "rpm": 60000,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000
  },
  "gemini/gemini-2.0-flash-live-001": {
    "deprecation_date": "2025-12-09",
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.0000021,
    "input_cost_per_image": 0.0000021,
    "input_cost_per_token": 3.5E-7,
    "input_cost_per_video_per_second": 0.0000021,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_audio_token": 0.0000085,
    "output_cost_per_token": 0.0000015,
    "rpm": 10,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2-0-flash-live-001",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini/gemini-2.0-flash-preview-image-generation": {
    "deprecation_date": "2025-11-14",
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "rpm": 10000,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000
  },
  "gemini/gemini-2.0-flash-thinking-exp": {
    "deprecation_date": "2025-12-02",
    "cache_read_input_token_cost": 0.0,
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 65536,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 10,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 4000000
  },
  "gemini/gemini-2.0-flash-thinking-exp-01-21": {
    "deprecation_date": "2025-12-02",
    "cache_read_input_token_cost": 0.0,
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 65536,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 10,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 4000000
  },
  "gemini/gemini-2.0-pro-exp-02-05": {
    "cache_read_input_token_cost": 0.0,
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 2,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 1000000
  },
  "gemini/gemini-2.5-flash": {
    "cache_read_input_token_cost": 3E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000
  },
  "gemini/gemini-2.5-flash-image-preview": {
    "deprecation_date": "2026-01-15",
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "image_generation",
    "output_cost_per_image": 0.039,
    "output_cost_per_image_token": 0.00003,
    "output_cost_per_reasoning_token": 0.00003,
    "output_cost_per_token": 0.00003,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000
  },
  "gemini/gemini-2.5-flash-lite": {
    "cache_read_input_token_cost": 1E-8,
    "input_cost_per_audio_token": 3E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4E-7,
    "output_cost_per_token": 4E-7,
    "rpm": 15,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini/gemini-2.5-flash-lite-preview-09-2025": {
    "cache_read_input_token_cost": 1E-8,
    "input_cost_per_audio_token": 3E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4E-7,
    "output_cost_per_token": 4E-7,
    "rpm": 15,
    "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini/gemini-2.5-flash-preview-09-2025": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "rpm": 15,
    "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini/gemini-flash-latest": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "rpm": 15,
    "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini/gemini-flash-lite-latest": {
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_audio_token": 3E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4E-7,
    "output_cost_per_token": 4E-7,
    "rpm": 15,
    "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini/gemini-2.5-flash-lite-preview-06-17": {
    "deprecation_date": "2025-11-18",
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_audio_token": 5E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4E-7,
    "output_cost_per_token": 4E-7,
    "rpm": 15,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini/gemini-2.5-flash-preview-04-17": {
    "cache_read_input_token_cost": 3.75E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000035,
    "output_cost_per_token": 6E-7,
    "rpm": 10,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini/gemini-2.5-flash-preview-05-20": {
    "deprecation_date": "2025-11-18",
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "rpm": 10,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini/gemini-2.5-pro": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 2000,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 800000
  },
  "gemini/gemini-2.5-computer-use-preview-10-2025": {
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "gemini",
    "max_images_per_prompt": 3000,
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 2000,
    "source": "https://ai.google.dev/gemini-api/docs/computer-use",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 800000
  },
  "gemini/gemini-3-pro-preview": {
    "cache_read_input_token_cost": 2E-7,
    "cache_read_input_token_cost_above_200k_tokens": 4E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_above_200k_tokens": 0.000004,
    "input_cost_per_token_batches": 0.000001,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.000012,
    "output_cost_per_token_above_200k_tokens": 0.000018,
    "output_cost_per_token_batches": 0.000006,
    "rpm": 2000,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 800000
  },
  "gemini/gemini-3-flash-preview": {
    "cache_read_input_token_cost": 5E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 5E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.000003,
    "output_cost_per_token": 0.000003,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing/gemini-3",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "supports_native_streaming": true,
    "tpm": 800000
  },
  "gemini-3-flash-preview": {
    "cache_read_input_token_cost": 5E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 5E-7,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.000003,
    "output_cost_per_token": 0.000003,
    "source": "https://ai.google.dev/pricing/gemini-3",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "supports_native_streaming": true
  },
  "gemini/gemini-2.5-pro-exp-03-25": {
    "cache_read_input_token_cost": 0.0,
    "input_cost_per_token": 0.0,
    "input_cost_per_token_above_200k_tokens": 0.0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "output_cost_per_token_above_200k_tokens": 0.0,
    "rpm": 5,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini/gemini-2.5-pro-preview-03-25": {
    "deprecation_date": "2025-12-02",
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 10000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000
  },
  "gemini/gemini-2.5-pro-preview-05-06": {
    "deprecation_date": "2025-12-02",
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 10000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000
  },
  "gemini/gemini-2.5-pro-preview-06-05": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 10000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000
  },
  "gemini/gemini-2.5-pro-preview-tts": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 10000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "audio"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 10000000
  },
  "gemini/gemini-exp-1114": {
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "metadata": {
      "notes": "Rate limits not documented for gemini-exp-1114. Assuming same as gemini-1.5-pro.",
      "supports_tool_choice": true
    },
    "mode": "chat",
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemini-exp-1206": {
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "metadata": {
      "notes": "Rate limits not documented for gemini-exp-1206. Assuming same as gemini-1.5-pro.",
      "supports_tool_choice": true
    },
    "mode": "chat",
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "rpm": 1000,
    "source": "https://ai.google.dev/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tpm": 4000000
  },
  "gemini/gemma-3-27b-it": {
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "gemini",
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://aistudio.google.com",
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "github_copilot/claude-haiku-4.5": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 16000,
    "max_tokens": 16000,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": true
  },
  "github_copilot/claude-opus-4.5": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 16000,
    "max_tokens": 16000,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": true
  },
  "github_copilot/claude-opus-4.6-fast": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 16000,
    "max_tokens": 16000,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": true
  },
  "github_copilot/claude-sonnet-4": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 16000,
    "max_tokens": 16000,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": true
  },
  "github_copilot/claude-sonnet-4.5": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 16000,
    "max_tokens": 16000,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": true
  },
  "github_copilot/gemini-2.5-pro": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": true
  },
  "github_copilot/gemini-3-pro-preview": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": true
  },
  "github_copilot/gpt-4.1": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "github_copilot/gpt-4.1-2025-04-14": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "github_copilot/gpt-5": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "github_copilot/gpt-5-mini": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "github_copilot/gpt-5.1": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "github_copilot/gpt-5.1-codex-max": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "github_copilot/gpt-5.2": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "github_copilot/gpt-5.3-codex": {
    "litellm_provider": "github_copilot",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "chatgpt/gpt-5.2-codex": {
    "litellm_provider": "chatgpt",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "chatgpt/gpt-5.2": {
    "litellm_provider": "chatgpt",
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "responses",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "chatgpt/gpt-5.1-codex-max": {
    "litellm_provider": "chatgpt",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "chatgpt/gpt-5.1-codex-mini": {
    "litellm_provider": "chatgpt",
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "responses",
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "gigachat/GigaChat-2-Lite": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "gigachat",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true,
    "supports_system_messages": true
  },
  "gigachat/GigaChat-2-Max": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "gigachat",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_vision": true
  },
  "gigachat/GigaChat-2-Pro": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "gigachat",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_vision": true
  },
  "gmi/anthropic/claude-opus-4.5": {
    "input_cost_per_token": 0.000005,
    "litellm_provider": "gmi",
    "max_input_tokens": 409600,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "supports_function_calling": true,
    "supports_vision": true
  },
  "gmi/anthropic/claude-sonnet-4.5": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "gmi",
    "max_input_tokens": 409600,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_vision": true
  },
  "gmi/anthropic/claude-sonnet-4": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "gmi",
    "max_input_tokens": 409600,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_vision": true
  },
  "gmi/anthropic/claude-opus-4": {
    "input_cost_per_token": 0.000015,
    "litellm_provider": "gmi",
    "max_input_tokens": 409600,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_function_calling": true,
    "supports_vision": true
  },
  "gmi/openai/gpt-5.2": {
    "input_cost_per_token": 0.00000175,
    "litellm_provider": "gmi",
    "max_input_tokens": 409600,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "supports_function_calling": true
  },
  "gmi/openai/gpt-5.1": {
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "gmi",
    "max_input_tokens": 409600,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true
  },
  "gmi/openai/gpt-5": {
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "gmi",
    "max_input_tokens": 409600,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true
  },
  "gmi/openai/gpt-4o": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "gmi",
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_vision": true
  },
  "gmi/openai/gpt-4o-mini": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "gmi",
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_vision": true
  },
  "gmi/deepseek-ai/DeepSeek-V3.2": {
    "input_cost_per_token": 2.8E-7,
    "litellm_provider": "gmi",
    "max_input_tokens": 163840,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_function_calling": true
  },
  "gmi/deepseek-ai/DeepSeek-V3-0324": {
    "input_cost_per_token": 2.8E-7,
    "litellm_provider": "gmi",
    "max_input_tokens": 163840,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 8.8E-7,
    "supports_function_calling": true
  },
  "gmi/google/gemini-3-pro-preview": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "gmi",
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.000012,
    "supports_function_calling": true,
    "supports_vision": true
  },
  "gmi/google/gemini-3-flash-preview": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "gmi",
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_vision": true
  },
  "gmi/moonshotai/Kimi-K2-Thinking": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "gmi",
    "max_input_tokens": 262144,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.0000012
  },
  "gmi/MiniMaxAI/MiniMax-M2.1": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gmi",
    "max_input_tokens": 196608,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.0000012
  },
  "gmi/Qwen/Qwen3-VL-235B-A22B-Instruct-FP8": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gmi",
    "max_input_tokens": 262144,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.0000014,
    "supports_vision": true
  },
  "gmi/zai-org/GLM-4.7-FP8": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "gmi",
    "max_input_tokens": 202752,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000002
  },
  "google.gemma-3-12b-it": {
    "input_cost_per_token": 9E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 2.9E-7,
    "supports_system_messages": true,
    "supports_vision": true
  },
  "google.gemma-3-27b-it": {
    "input_cost_per_token": 2.3E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 3.8E-7,
    "supports_system_messages": true,
    "supports_vision": true
  },
  "google.gemma-3-4b-it": {
    "input_cost_per_token": 4E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 8E-8,
    "supports_system_messages": true,
    "supports_vision": true
  },
  "global.anthropic.claude-sonnet-4-5-20250929-v1:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "global.anthropic.claude-sonnet-4-20250514-v1:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "global.anthropic.claude-haiku-4-5-20251001-v1:0": {
    "cache_creation_input_token_cost": 0.00000125,
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 0.000001,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "global.amazon.nova-2-lite-v1:0": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "gpt-4-0125-preview": {
    "deprecation_date": "2026-03-26",
    "input_cost_per_token": 0.00001,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-1106-preview": {
    "deprecation_date": "2026-03-26",
    "input_cost_per_token": 0.00001,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-1106-vision-preview": {
    "deprecation_date": "2024-12-06",
    "input_cost_per_token": 0.00001,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4-turbo": {
    "input_cost_per_token": 0.00001,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4-turbo-2024-04-09": {
    "input_cost_per_token": 0.00001,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4-turbo-preview": {
    "input_cost_per_token": 0.00001,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-vision-preview": {
    "deprecation_date": "2024-12-06",
    "input_cost_per_token": 0.00001,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4.1": {
    "cache_read_input_token_cost": 5E-7,
    "cache_read_input_token_cost_priority": 8.75E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "input_cost_per_token_priority": 0.0000035,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "output_cost_per_token_priority": 0.000014,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4.1-2025-04-14": {
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4.1-mini": {
    "cache_read_input_token_cost": 1E-7,
    "cache_read_input_token_cost_priority": 1.75E-7,
    "input_cost_per_token": 4E-7,
    "input_cost_per_token_batches": 2E-7,
    "input_cost_per_token_priority": 7E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0000016,
    "output_cost_per_token_batches": 8E-7,
    "output_cost_per_token_priority": 0.0000028,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4.1-mini-2025-04-14": {
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 4E-7,
    "input_cost_per_token_batches": 2E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0000016,
    "output_cost_per_token_batches": 8E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4.1-nano": {
    "cache_read_input_token_cost": 2.5E-8,
    "cache_read_input_token_cost_priority": 5E-8,
    "input_cost_per_token": 1E-7,
    "input_cost_per_token_batches": 5E-8,
    "input_cost_per_token_priority": 2E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "output_cost_per_token_batches": 2E-7,
    "output_cost_per_token_priority": 8E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4.1-nano-2025-04-14": {
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 1E-7,
    "input_cost_per_token_batches": 5E-8,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "output_cost_per_token_batches": 2E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4.5-preview": {
    "cache_read_input_token_cost": 0.0000375,
    "input_cost_per_token": 0.000075,
    "input_cost_per_token_batches": 0.0000375,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_batches": 0.000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4.5-preview-2025-02-27": {
    "cache_read_input_token_cost": 0.0000375,
    "deprecation_date": "2025-07-14",
    "input_cost_per_token": 0.000075,
    "input_cost_per_token_batches": 0.0000375,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_batches": 0.000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o": {
    "cache_read_input_token_cost": 0.00000125,
    "cache_read_input_token_cost_priority": 0.000002125,
    "input_cost_per_token": 0.0000025,
    "input_cost_per_token_batches": 0.00000125,
    "input_cost_per_token_priority": 0.00000425,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_batches": 0.000005,
    "output_cost_per_token_priority": 0.000017,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4o-2024-05-13": {
    "input_cost_per_token": 0.000005,
    "input_cost_per_token_batches": 0.0000025,
    "input_cost_per_token_priority": 0.00000875,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "output_cost_per_token_batches": 0.0000075,
    "output_cost_per_token_priority": 0.00002625,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o-2024-08-06": {
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.0000025,
    "input_cost_per_token_batches": 0.00000125,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_batches": 0.000005,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4o-2024-11-20": {
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.0000025,
    "input_cost_per_token_batches": 0.00000125,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_batches": 0.000005,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4o-audio-preview": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-audio-preview-2024-10-01": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-audio-preview-2024-12-17": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-audio-preview-2025-06-03": {
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00001,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-audio": {
    "input_cost_per_audio_token": 0.000032,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.000064,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses",
      "/v1/realtime",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-audio-2025-08-28": {
    "input_cost_per_audio_token": 0.000032,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.000064,
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses",
      "/v1/realtime",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-audio-mini": {
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses",
      "/v1/realtime",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-audio-mini-2025-10-06": {
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses",
      "/v1/realtime",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-audio-mini-2025-12-15": {
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses",
      "/v1/realtime",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-4o-mini": {
    "cache_read_input_token_cost": 7.5E-8,
    "cache_read_input_token_cost_priority": 1.25E-7,
    "input_cost_per_token": 1.5E-7,
    "input_cost_per_token_batches": 7.5E-8,
    "input_cost_per_token_priority": 2.5E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "output_cost_per_token_batches": 3E-7,
    "output_cost_per_token_priority": 0.000001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4o-mini-2024-07-18": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 1.5E-7,
    "input_cost_per_token_batches": 7.5E-8,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "output_cost_per_token_batches": 3E-7,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.03,
      "search_context_size_low": 0.025,
      "search_context_size_medium": 0.0275
    },
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-4o-mini-audio-preview": {
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 6E-7,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-mini-audio-preview-2024-12-17": {
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 6E-7,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-mini-realtime-preview": {
    "cache_creation_input_audio_token_cost": 3E-7,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-mini-realtime-preview-2024-12-17": {
    "cache_creation_input_audio_token_cost": 3E-7,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-mini-search-preview": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 1.5E-7,
    "input_cost_per_token_batches": 7.5E-8,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "output_cost_per_token_batches": 3E-7,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.03,
      "search_context_size_low": 0.025,
      "search_context_size_medium": 0.0275
    },
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-4o-mini-search-preview-2025-03-11": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 1.5E-7,
    "input_cost_per_token_batches": 7.5E-8,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "output_cost_per_token_batches": 3E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o-realtime-preview": {
    "cache_read_input_token_cost": 0.0000025,
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00002,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-realtime-preview-2024-10-01": {
    "cache_creation_input_audio_token_cost": 0.00002,
    "cache_read_input_token_cost": 0.0000025,
    "input_cost_per_audio_token": 0.0001,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.0002,
    "output_cost_per_token": 0.00002,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-realtime-preview-2024-12-17": {
    "cache_read_input_token_cost": 0.0000025,
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00002,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-realtime-preview-2025-06-03": {
    "cache_read_input_token_cost": 0.0000025,
    "input_cost_per_audio_token": 0.00004,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00008,
    "output_cost_per_token": 0.00002,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-search-preview": {
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.0000025,
    "input_cost_per_token_batches": 0.00000125,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_batches": 0.000005,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.05,
      "search_context_size_low": 0.03,
      "search_context_size_medium": 0.035
    },
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-4o-search-preview-2025-03-11": {
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.0000025,
    "input_cost_per_token_batches": 0.00000125,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_batches": 0.000005,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_flex": 6.25E-8,
    "cache_read_input_token_cost_priority": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_flex": 6.25E-7,
    "input_cost_per_token_priority": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_flex": 0.000005,
    "output_cost_per_token_priority": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.1": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_priority": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_priority": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_priority": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.1-2025-11-13": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_priority": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_priority": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_priority": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.1-chat-latest": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_priority": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_priority": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_priority": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5.2": {
    "cache_read_input_token_cost": 1.75E-7,
    "cache_read_input_token_cost_priority": 3.5E-7,
    "input_cost_per_token": 0.00000175,
    "input_cost_per_token_priority": 0.0000035,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "output_cost_per_token_priority": 0.000028,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.2-2025-12-11": {
    "cache_read_input_token_cost": 1.75E-7,
    "cache_read_input_token_cost_priority": 3.5E-7,
    "input_cost_per_token": 0.00000175,
    "input_cost_per_token_priority": 0.0000035,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "output_cost_per_token_priority": 0.000028,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5.2-chat-latest": {
    "cache_read_input_token_cost": 1.75E-7,
    "cache_read_input_token_cost_priority": 3.5E-7,
    "input_cost_per_token": 0.00000175,
    "input_cost_per_token_priority": 0.0000035,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "output_cost_per_token_priority": 0.000028,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2-pro": {
    "input_cost_per_token": 0.000021,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5.2-pro-2025-12-11": {
    "input_cost_per_token": 0.000021,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-pro": {
    "input_cost_per_token": 0.000015,
    "input_cost_per_token_batches": 0.0000075,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 272000,
    "max_tokens": 272000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "output_cost_per_token_batches": 0.00006,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-pro-2025-10-06": {
    "input_cost_per_token": 0.000015,
    "input_cost_per_token_batches": 0.0000075,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 272000,
    "max_tokens": 272000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "output_cost_per_token_batches": 0.00006,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-2025-08-07": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_flex": 6.25E-8,
    "cache_read_input_token_cost_priority": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_flex": 6.25E-7,
    "input_cost_per_token_priority": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_flex": 0.000005,
    "output_cost_per_token_priority": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-chat": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5-chat-latest": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5-codex": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-codex": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_priority": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_priority": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_priority": 0.00002,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-codex-max": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.00001,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-codex-mini": {
    "cache_read_input_token_cost": 2.5E-8,
    "cache_read_input_token_cost_priority": 4.5E-8,
    "input_cost_per_token": 2.5E-7,
    "input_cost_per_token_priority": 4.5E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000002,
    "output_cost_per_token_priority": 0.0000036,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2-codex": {
    "cache_read_input_token_cost": 1.75E-7,
    "cache_read_input_token_cost_priority": 3.5E-7,
    "input_cost_per_token": 0.00000175,
    "input_cost_per_token_priority": 0.0000035,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000014,
    "output_cost_per_token_priority": 0.000028,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-mini": {
    "cache_read_input_token_cost": 2.5E-8,
    "cache_read_input_token_cost_flex": 1.25E-8,
    "cache_read_input_token_cost_priority": 4.5E-8,
    "input_cost_per_token": 2.5E-7,
    "input_cost_per_token_flex": 1.25E-7,
    "input_cost_per_token_priority": 4.5E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "output_cost_per_token_flex": 0.000001,
    "output_cost_per_token_priority": 0.0000036,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-mini-2025-08-07": {
    "cache_read_input_token_cost": 2.5E-8,
    "cache_read_input_token_cost_flex": 1.25E-8,
    "cache_read_input_token_cost_priority": 4.5E-8,
    "input_cost_per_token": 2.5E-7,
    "input_cost_per_token_flex": 1.25E-7,
    "input_cost_per_token_priority": 4.5E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "output_cost_per_token_flex": 0.000001,
    "output_cost_per_token_priority": 0.0000036,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "gpt-5-nano": {
    "cache_read_input_token_cost": 5E-9,
    "cache_read_input_token_cost_flex": 2.5E-9,
    "input_cost_per_token": 5E-8,
    "input_cost_per_token_flex": 2.5E-8,
    "input_cost_per_token_priority": 0.0000025,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "output_cost_per_token_flex": 2E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-nano-2025-08-07": {
    "cache_read_input_token_cost": 5E-9,
    "cache_read_input_token_cost_flex": 2.5E-9,
    "input_cost_per_token": 5E-8,
    "input_cost_per_token_flex": 2.5E-8,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "output_cost_per_token_flex": 2E-7,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-realtime-mini": {
    "cache_creation_input_audio_token_cost": 3E-7,
    "cache_read_input_audio_token_cost": 3E-7,
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lemonade/Qwen3-Coder-30B-A3B-Instruct-GGUF": {
    "input_cost_per_token": 0,
    "litellm_provider": "lemonade",
    "max_tokens": 32768,
    "max_input_tokens": 262144,
    "max_output_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "lemonade/gpt-oss-20b-mxfp4-GGUF": {
    "input_cost_per_token": 0,
    "litellm_provider": "lemonade",
    "max_tokens": 32768,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "lemonade/gpt-oss-120b-mxfp-GGUF": {
    "input_cost_per_token": 0,
    "litellm_provider": "lemonade",
    "max_tokens": 32768,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "lemonade/Gemma-3-4b-it-GGUF": {
    "input_cost_per_token": 0,
    "litellm_provider": "lemonade",
    "max_tokens": 8192,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "lemonade/Qwen3-4B-Instruct-2507-GGUF": {
    "input_cost_per_token": 0,
    "litellm_provider": "lemonade",
    "max_tokens": 32768,
    "max_input_tokens": 262144,
    "max_output_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "amazon-nova/nova-micro-v1": {
    "input_cost_per_token": 3.5E-8,
    "litellm_provider": "amazon_nova",
    "max_input_tokens": 128000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 1.4E-7,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true
  },
  "amazon-nova/nova-lite-v1": {
    "input_cost_per_token": 6E-8,
    "litellm_provider": "amazon_nova",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 2.4E-7,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "amazon-nova/nova-premier-v1": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "amazon_nova",
    "max_input_tokens": 1000000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 0.0000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": false,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "amazon-nova/nova-pro-v1": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "amazon_nova",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 0.0000032,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "groq/llama-3.1-8b-instant": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "groq",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 8E-8,
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true
  },
  "groq/llama-3.3-70b-versatile": {
    "input_cost_per_token": 5.9E-7,
    "litellm_provider": "groq",
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 7.9E-7,
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true
  },
  "groq/meta-llama/llama-4-maverick-17b-128e-instruct": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "groq",
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "groq/meta-llama/llama-4-scout-17b-16e-instruct": {
    "input_cost_per_token": 1.1E-7,
    "litellm_provider": "groq",
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 3.4E-7,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "groq/moonshotai/kimi-k2-instruct-0905": {
    "input_cost_per_token": 0.000001,
    "output_cost_per_token": 0.000003,
    "cache_read_input_token_cost": 5E-7,
    "litellm_provider": "groq",
    "max_input_tokens": 262144,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "groq/openai/gpt-oss-120b": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "groq",
    "max_input_tokens": 131072,
    "max_output_tokens": 32766,
    "max_tokens": 32766,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "groq/openai/gpt-oss-20b": {
    "cache_read_input_token_cost": 3.75E-8,
    "input_cost_per_token": 7.5E-8,
    "litellm_provider": "groq",
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "groq/qwen/qwen3-32b": {
    "input_cost_per_token": 2.9E-7,
    "litellm_provider": "groq",
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "mode": "chat",
    "output_cost_per_token": 5.9E-7,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true
  },
  "hyperbolic/Qwen/QwQ-32B": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/Qwen/Qwen2.5-72B-Instruct": {
    "input_cost_per_token": 1.2E-7,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/Qwen/Qwen3-235B-A22B": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/deepseek-ai/DeepSeek-R1-0528": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2.5E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/meta-llama/Llama-3.3-70B-Instruct": {
    "input_cost_per_token": 1.2E-7,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct": {
    "input_cost_per_token": 1.2E-7,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "hyperbolic/moonshotai/Kimi-K2-Instruct": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "hyperbolic",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "jamba-1.5": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "ai21",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_tool_choice": true
  },
  "jamba-1.5-large": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "ai21",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supports_tool_choice": true
  },
  "jamba-1.5-large@001": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "ai21",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supports_tool_choice": true
  },
  "jamba-1.5-mini": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "ai21",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_tool_choice": true
  },
  "jamba-1.5-mini@001": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "ai21",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_tool_choice": true
  },
  "jamba-large-1.6": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "ai21",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supports_tool_choice": true
  },
  "jamba-large-1.7": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "ai21",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supports_tool_choice": true
  },
  "jamba-mini-1.6": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "ai21",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_tool_choice": true
  },
  "jamba-mini-1.7": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "ai21",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_tool_choice": true
  },
  "jp.anthropic.claude-sonnet-4-5-20250929-v1:0": {
    "cache_creation_input_token_cost": 0.000004125,
    "cache_read_input_token_cost": 3.3E-7,
    "input_cost_per_token": 0.0000033,
    "input_cost_per_token_above_200k_tokens": 0.0000066,
    "output_cost_per_token_above_200k_tokens": 0.00002475,
    "cache_creation_input_token_cost_above_200k_tokens": 0.00000825,
    "cache_read_input_token_cost_above_200k_tokens": 6.6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000165,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "jp.anthropic.claude-haiku-4-5-20251001-v1:0": {
    "cache_creation_input_token_cost": 0.000001375,
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000055,
    "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "lambda_ai/deepseek-llama3.3-70b": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/deepseek-r1-0528": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/deepseek-r1-671b": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 8E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/deepseek-v3-0324": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/hermes3-405b": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 8E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/hermes3-70b": {
    "input_cost_per_token": 1.2E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/hermes3-8b": {
    "input_cost_per_token": 2.5E-8,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 4E-8,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/lfm-40b": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/lfm-7b": {
    "input_cost_per_token": 2.5E-8,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 4E-8,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/llama-4-maverick-17b-128e-instruct-fp8": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/llama3.1-405b-instruct-fp8": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 8E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/llama3.1-70b-instruct-fp8": {
    "input_cost_per_token": 1.2E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/llama3.1-8b-instruct": {
    "input_cost_per_token": 2.5E-8,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 4E-8,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/llama3.1-nemotron-70b-instruct-fp8": {
    "input_cost_per_token": 1.2E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/llama3.2-11b-vision-instruct": {
    "input_cost_per_token": 1.5E-8,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2.5E-8,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "lambda_ai/llama3.2-3b-instruct": {
    "input_cost_per_token": 1.5E-8,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2.5E-8,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/llama3.3-70b-instruct-fp8": {
    "input_cost_per_token": 1.2E-7,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/qwen25-coder-32b-instruct": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "lambda_ai/qwen3-32b-fp8": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "lambda_ai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "meta.llama3-1-405b-instruct-v1:0": {
    "input_cost_per_token": 0.00000532,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000016,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "meta.llama3-1-70b-instruct-v1:0": {
    "input_cost_per_token": 9.9E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 9.9E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "meta.llama3-1-8b-instruct-v1:0": {
    "input_cost_per_token": 2.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 2.2E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "meta.llama3-2-11b-instruct-v1:0": {
    "input_cost_per_token": 3.5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3.5E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "meta.llama3-2-1b-instruct-v1:0": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "meta.llama3-2-3b-instruct-v1:0": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1.5E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "meta.llama3-2-90b-instruct-v1:0": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "meta.llama3-3-70b-instruct-v1:0": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 7.2E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "meta.llama4-maverick-17b-instruct-v1:0": {
    "input_cost_per_token": 2.4E-7,
    "input_cost_per_token_batches": 1.2E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 9.7E-7,
    "output_cost_per_token_batches": 4.85E-7,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "meta.llama4-scout-17b-instruct-v1:0": {
    "input_cost_per_token": 1.7E-7,
    "input_cost_per_token_batches": 8.5E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6.6E-7,
    "output_cost_per_token_batches": 3.3E-7,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "meta_llama/Llama-3.3-70B-Instruct": {
    "litellm_provider": "meta_llama",
    "max_input_tokens": 128000,
    "max_output_tokens": 4028,
    "max_tokens": 4028,
    "mode": "chat",
    "source": "https://llama.developer.meta.com/docs/models",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "meta_llama/Llama-3.3-8B-Instruct": {
    "litellm_provider": "meta_llama",
    "max_input_tokens": 128000,
    "max_output_tokens": 4028,
    "max_tokens": 4028,
    "mode": "chat",
    "source": "https://llama.developer.meta.com/docs/models",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
    "litellm_provider": "meta_llama",
    "max_input_tokens": 1000000,
    "max_output_tokens": 4028,
    "max_tokens": 4028,
    "mode": "chat",
    "source": "https://llama.developer.meta.com/docs/models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8": {
    "litellm_provider": "meta_llama",
    "max_input_tokens": 10000000,
    "max_output_tokens": 4028,
    "max_tokens": 4028,
    "mode": "chat",
    "source": "https://llama.developer.meta.com/docs/models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "minimax.minimax-m2": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_system_messages": true
  },
  "minimax.minimax-m2.1": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 196000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "minimax/MiniMax-M2.1": {
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000012,
    "cache_read_input_token_cost": 3E-8,
    "cache_creation_input_token_cost": 3.75E-7,
    "litellm_provider": "minimax",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  "minimax/MiniMax-M2.1-lightning": {
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000024,
    "cache_read_input_token_cost": 3E-8,
    "cache_creation_input_token_cost": 3.75E-7,
    "litellm_provider": "minimax",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  "minimax/MiniMax-M2.5": {
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000012,
    "cache_read_input_token_cost": 3E-8,
    "cache_creation_input_token_cost": 3.75E-7,
    "litellm_provider": "minimax",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  "minimax/MiniMax-M2.5-lightning": {
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000024,
    "cache_read_input_token_cost": 3E-8,
    "cache_creation_input_token_cost": 3.75E-7,
    "litellm_provider": "minimax",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192
  },
  "minimax/MiniMax-M2": {
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000012,
    "cache_read_input_token_cost": 3E-8,
    "cache_creation_input_token_cost": 3.75E-7,
    "litellm_provider": "minimax",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192
  },
  "mistral.magistral-small-2509": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true
  },
  "mistral.ministral-3-14b-instruct": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 2E-7,
    "supports_function_calling": true,
    "supports_system_messages": true
  },
  "mistral.ministral-3-3b-instruct": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "supports_function_calling": true,
    "supports_system_messages": true
  },
  "mistral.ministral-3-8b-instruct": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 1.5E-7,
    "supports_function_calling": true,
    "supports_system_messages": true
  },
  "mistral.mistral-large-2407-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000009,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "mistral.mistral-large-3-675b-instruct": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_system_messages": true
  },
  "mistral.voxtral-mini-3b-2507": {
    "input_cost_per_token": 4E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 4E-8,
    "supports_audio_input": true,
    "supports_system_messages": true
  },
  "mistral.voxtral-small-24b-2507": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_audio_input": true,
    "supports_system_messages": true
  },
  "mistral/codestral-2508": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 9E-7,
    "source": "https://mistral.ai/news/codestral-25-08",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/codestral-mamba-latest": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 2.5E-7,
    "source": "https://mistral.ai/technology/",
    "supports_assistant_prefill": true,
    "supports_tool_choice": true
  },
  "mistral/devstral-medium-2507": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "source": "https://mistral.ai/news/devstral",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/devstral-small-2505": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "source": "https://mistral.ai/news/devstral",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/devstral-small-2507": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "source": "https://mistral.ai/news/devstral",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/labs-devstral-small-2512": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "source": "https://docs.mistral.ai/models/devstral-small-2-25-12",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/devstral-2512": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "source": "https://mistral.ai/news/devstral-2-vibe-cli",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/mistral-large-2407": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000009,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/mistral-large-2411": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/mistral-large-latest": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/mistral-large-3": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 256000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "source": "https://docs.mistral.ai/models/mistral-large-3-25-12",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "mistral/mistral-medium-2505": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 131072,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/mistral-medium-latest": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 131072,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/open-codestral-mamba": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 2.5E-7,
    "source": "https://mistral.ai/technology/",
    "supports_assistant_prefill": true,
    "supports_tool_choice": true
  },
  "mistral/open-mistral-nemo": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "source": "https://mistral.ai/technology/",
    "supports_assistant_prefill": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/open-mistral-nemo-2407": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "source": "https://mistral.ai/technology/",
    "supports_assistant_prefill": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "mistral/pixtral-12b-2409": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.5E-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "mistral/pixtral-large-2411": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "mistral/pixtral-large-latest": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "mistral",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "moonshot.kimi-k2-thinking": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "supports_reasoning": true,
    "supports_system_messages": true
  },
  "moonshotai.kimi-k2.5": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "moonshot/kimi-k2-0711-preview": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "moonshot",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "moonshot/kimi-k2-0905-preview": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "moonshot",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "moonshot/kimi-k2-turbo-preview": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 0.00000115,
    "litellm_provider": "moonshot",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "moonshot/kimi-k2.5": {
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "moonshot",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "source": "https://platform.moonshot.ai/docs/guide/kimi-k2-5-quickstart",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "moonshot/kimi-latest": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 0.000002,
    "litellm_provider": "moonshot",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "moonshot/kimi-latest-128k": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 0.000002,
    "litellm_provider": "moonshot",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "moonshot/kimi-thinking-preview": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "moonshot",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
    "supports_vision": true
  },
  "moonshot/kimi-k2-thinking": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "moonshot",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "moonshot/kimi-k2-thinking-turbo": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 0.00000115,
    "litellm_provider": "moonshot",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "moonshot/moonshot-v1-128k": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "moonshot",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "moonshot/moonshot-v1-128k-0430": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "moonshot",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "moonshot/moonshot-v1-128k-vision-preview": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "moonshot",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "moonshot/moonshot-v1-auto": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "moonshot",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "source": "https://platform.moonshot.ai/docs/pricing",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "nvidia.nemotron-nano-12b-v2": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_system_messages": true,
    "supports_vision": true
  },
  "nvidia.nemotron-nano-9b-v2": {
    "input_cost_per_token": 6E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 2.3E-7,
    "supports_system_messages": true
  },
  "nvidia.nemotron-nano-3-30b": {
    "input_cost_per_token": 6E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 2.4E-7,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "o1": {
    "cache_read_input_token_cost": 0.0000075,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o1-2024-12-17": {
    "cache_read_input_token_cost": 0.0000075,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o1-mini": {
    "cache_read_input_token_cost": 5.5E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_vision": true
  },
  "o1-mini-2024-09-12": {
    "deprecation_date": "2025-10-27",
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.000012,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": true
  },
  "o1-preview": {
    "cache_read_input_token_cost": 0.0000075,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.00006,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": true
  },
  "o1-preview-2024-09-12": {
    "cache_read_input_token_cost": 0.0000075,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.00006,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": true
  },
  "o1-pro": {
    "input_cost_per_token": 0.00015,
    "input_cost_per_token_batches": 0.000075,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.0006,
    "output_cost_per_token_batches": 0.0003,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o1-pro-2025-03-19": {
    "input_cost_per_token": 0.00015,
    "input_cost_per_token_batches": 0.000075,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.0006,
    "output_cost_per_token_batches": 0.0003,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o3": {
    "cache_read_input_token_cost": 5E-7,
    "cache_read_input_token_cost_flex": 2.5E-7,
    "cache_read_input_token_cost_priority": 8.75E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_flex": 0.000001,
    "input_cost_per_token_priority": 0.0000035,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_flex": 0.000004,
    "output_cost_per_token_priority": 0.000014,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "o3-2025-04-16": {
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "o3-deep-research": {
    "cache_read_input_token_cost": 0.0000025,
    "input_cost_per_token": 0.00001,
    "input_cost_per_token_batches": 0.000005,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.00004,
    "output_cost_per_token_batches": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o3-deep-research-2025-06-26": {
    "cache_read_input_token_cost": 0.0000025,
    "input_cost_per_token": 0.00001,
    "input_cost_per_token_batches": 0.000005,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.00004,
    "output_cost_per_token_batches": 0.00002,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o3-mini": {
    "cache_read_input_token_cost": 5.5E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "o3-mini-2025-01-31": {
    "cache_read_input_token_cost": 5.5E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "o3-pro": {
    "input_cost_per_token": 0.00002,
    "input_cost_per_token_batches": 0.00001,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.00008,
    "output_cost_per_token_batches": 0.00004,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o3-pro-2025-06-10": {
    "input_cost_per_token": 0.00002,
    "input_cost_per_token_batches": 0.00001,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.00008,
    "output_cost_per_token_batches": 0.00004,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o4-mini": {
    "cache_read_input_token_cost": 2.75E-7,
    "cache_read_input_token_cost_flex": 1.375E-7,
    "cache_read_input_token_cost_priority": 5E-7,
    "input_cost_per_token": 0.0000011,
    "input_cost_per_token_flex": 5.5E-7,
    "input_cost_per_token_priority": 0.000002,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "output_cost_per_token_flex": 0.0000022,
    "output_cost_per_token_priority": 0.000008,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "o4-mini-2025-04-16": {
    "cache_read_input_token_cost": 2.75E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_service_tier": true,
    "supports_vision": true
  },
  "o4-mini-deep-research": {
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o4-mini-deep-research-2025-06-26": {
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_batches": 0.000001,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.000008,
    "output_cost_per_token_batches": 0.000004,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "oci/meta.llama-3.1-405b-instruct": {
    "input_cost_per_token": 0.00001068,
    "litellm_provider": "oci",
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 0.00001068,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/meta.llama-3.2-90b-vision-instruct": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "oci",
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/meta.llama-3.3-70b-instruct": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "oci",
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 7.2E-7,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/meta.llama-4-maverick-17b-128e-instruct-fp8": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "oci",
    "max_input_tokens": 512000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 7.2E-7,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/meta.llama-4-scout-17b-16e-instruct": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "oci",
    "max_input_tokens": 192000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 7.2E-7,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/xai.grok-3": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "oci",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/xai.grok-3-fast": {
    "input_cost_per_token": 0.000005,
    "litellm_provider": "oci",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/xai.grok-3-mini": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "oci",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 5E-7,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/xai.grok-3-mini-fast": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "oci",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/xai.grok-4": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "oci",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "source": "https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/cohere.command-latest": {
    "input_cost_per_token": 0.00000156,
    "litellm_provider": "oci",
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 0.00000156,
    "source": "https://www.oracle.com/cloud/ai/generative-ai/pricing/",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/cohere.command-a-03-2025": {
    "input_cost_per_token": 0.00000156,
    "litellm_provider": "oci",
    "max_input_tokens": 256000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 0.00000156,
    "source": "https://www.oracle.com/cloud/ai/generative-ai/pricing/",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "oci/cohere.command-plus-latest": {
    "input_cost_per_token": 0.00000156,
    "litellm_provider": "oci",
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 0.00000156,
    "source": "https://www.oracle.com/cloud/ai/generative-ai/pricing/",
    "supports_function_calling": true,
    "supports_response_schema": false
  },
  "ollama/deepseek-v3.1:671b-cloud": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/gpt-oss:120b-cloud": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/gpt-oss:20b-cloud": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "ollama/qwen3-coder:480b-cloud": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "ollama",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_function_calling": true
  },
  "openai.gpt-oss-120b-1:0": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "openai.gpt-oss-20b-1:0": {
    "input_cost_per_token": 7E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "openai.gpt-oss-safeguard-120b": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_system_messages": true
  },
  "openai.gpt-oss-safeguard-20b": {
    "input_cost_per_token": 7E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 2E-7,
    "supports_system_messages": true
  },
  "openrouter/anthropic/claude-3.5-sonnet": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "openrouter",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "openrouter/anthropic/claude-3.7-sonnet": {
    "input_cost_per_image": 0.0048,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "openrouter",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "openrouter/anthropic/claude-opus-4": {
    "input_cost_per_image": 0.0048,
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "openrouter",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "openrouter/anthropic/claude-opus-4.1": {
    "input_cost_per_image": 0.0048,
    "cache_creation_input_token_cost": 0.00001875,
    "cache_creation_input_token_cost_above_1hr": 0.00003,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "openrouter",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "openrouter/anthropic/claude-sonnet-4": {
    "input_cost_per_image": 0.0048,
    "cache_creation_input_token_cost": 0.00000375,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost": 3E-7,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "litellm_provider": "openrouter",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "openrouter/anthropic/claude-opus-4.5": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "openrouter",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "openrouter/anthropic/claude-sonnet-4.5": {
    "input_cost_per_image": 0.0048,
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "max_tokens": 1000000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "openrouter/anthropic/claude-haiku-4.5": {
    "cache_creation_input_token_cost": 0.00000125,
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 0.000001,
    "litellm_provider": "openrouter",
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "max_tokens": 200000,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "openrouter/bytedance/ui-tars-1.5-7b": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 131072,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 2E-7,
    "source": "https://openrouter.ai/api/v1/models/bytedance/ui-tars-1.5-7b",
    "supports_tool_choice": true
  },
  "openrouter/deepseek/deepseek-chat-v3.1": {
    "input_cost_per_token": 2E-7,
    "input_cost_per_token_cache_hit": 2E-8,
    "litellm_provider": "openrouter",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 8E-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/deepseek/deepseek-v3.2": {
    "input_cost_per_token": 2.8E-7,
    "input_cost_per_token_cache_hit": 2.8E-8,
    "litellm_provider": "openrouter",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/deepseek/deepseek-v3.2-exp": {
    "input_cost_per_token": 2E-7,
    "input_cost_per_token_cache_hit": 2E-8,
    "litellm_provider": "openrouter",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": false,
    "supports_tool_choice": true
  },
  "openrouter/google/gemini-2.0-flash-001": {
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "openrouter",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/google/gemini-2.5-flash": {
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "openrouter",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/google/gemini-2.5-pro": {
    "input_cost_per_audio_token": 7E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "openrouter",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/google/gemini-3-pro-preview": {
    "cache_read_input_token_cost": 2E-7,
    "cache_read_input_token_cost_above_200k_tokens": 4E-7,
    "cache_creation_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_token": 0.000002,
    "input_cost_per_token_above_200k_tokens": 0.000004,
    "input_cost_per_token_batches": 0.000001,
    "litellm_provider": "openrouter",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.000012,
    "output_cost_per_token_above_200k_tokens": 0.000018,
    "output_cost_per_token_batches": 0.000006,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "openrouter/google/gemini-3-flash-preview": {
    "cache_read_input_token_cost": 5E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 5E-7,
    "litellm_provider": "openrouter",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.000003,
    "output_cost_per_token": 0.000003,
    "rpm": 2000,
    "source": "https://ai.google.dev/pricing/gemini-3",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 800000
  },
  "openrouter/minimax/minimax-m2": {
    "input_cost_per_token": 2.55E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 204800,
    "max_output_tokens": 204800,
    "max_tokens": 204800,
    "mode": "chat",
    "output_cost_per_token": 0.00000102,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/mistralai/devstral-2512": {
    "input_cost_per_image": 0,
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 262144,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_prompt_caching": false,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "openrouter/mistralai/ministral-3b-2512": {
    "input_cost_per_image": 0,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "supports_function_calling": true,
    "supports_prompt_caching": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/mistralai/ministral-8b-2512": {
    "input_cost_per_image": 0,
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 1.5E-7,
    "supports_function_calling": true,
    "supports_prompt_caching": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/mistralai/ministral-14b-2512": {
    "input_cost_per_image": 0,
    "input_cost_per_token": 2E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 2E-7,
    "supports_function_calling": true,
    "supports_prompt_caching": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/mistralai/mistral-large-2512": {
    "input_cost_per_image": 0,
    "input_cost_per_token": 5E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true,
    "supports_prompt_caching": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/moonshotai/kimi-k2.5": {
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "source": "https://openrouter.ai/moonshotai/kimi-k2.5",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-4.1": {
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "litellm_provider": "openrouter",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-4.1-mini": {
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 4E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0000016,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-4.1-nano": {
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-4o": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "openrouter",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-4o-2024-05-13": {
    "input_cost_per_token": 0.000005,
    "litellm_provider": "openrouter",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-5-chat": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "openrouter",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-codex": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5.2-codex": {
    "cache_read_input_token_cost": 1.75E-7,
    "input_cost_per_token": 0.00000175,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-mini": {
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5-nano": {
    "cache_read_input_token_cost": 5E-9,
    "input_cost_per_token": 5E-8,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-5.2": {
    "input_cost_per_image": 0,
    "cache_read_input_token_cost": 1.75E-7,
    "input_cost_per_token": 0.00000175,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-5.2-chat": {
    "input_cost_per_image": 0,
    "cache_read_input_token_cost": 1.75E-7,
    "input_cost_per_token": 0.00000175,
    "litellm_provider": "openrouter",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000014,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-5.2-pro": {
    "input_cost_per_image": 0,
    "input_cost_per_token": 0.000021,
    "litellm_provider": "openrouter",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000168,
    "supports_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/gpt-oss-120b": {
    "input_cost_per_token": 1.8E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 8E-7,
    "source": "https://openrouter.ai/openai/gpt-oss-120b",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/gpt-oss-20b": {
    "input_cost_per_token": 2E-8,
    "litellm_provider": "openrouter",
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "source": "https://openrouter.ai/openai/gpt-oss-20b",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "openrouter/openai/o1": {
    "cache_read_input_token_cost": 0.0000075,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "openrouter",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.00006,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "openrouter/openai/o3-mini": {
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "openrouter",
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "openrouter/openai/o3-mini-high": {
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "openrouter",
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "openrouter/qwen/qwen3-coder": {
    "input_cost_per_token": 2.2E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 262100,
    "max_output_tokens": 262100,
    "max_tokens": 262100,
    "mode": "chat",
    "output_cost_per_token": 9.5E-7,
    "source": "https://openrouter.ai/qwen/qwen3-coder",
    "supports_tool_choice": true,
    "supports_function_calling": true
  },
  "openrouter/qwen/qwen3-235b-a22b-2507": {
    "input_cost_per_token": 7.1E-8,
    "litellm_provider": "openrouter",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "source": "https://openrouter.ai/qwen/qwen3-235b-a22b-2507",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "openrouter/qwen/qwen3-235b-a22b-thinking-2507": {
    "input_cost_per_token": 1.1E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "source": "https://openrouter.ai/qwen/qwen3-235b-a22b-thinking-2507",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/switchpoint/router": {
    "input_cost_per_token": 8.5E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.0000034,
    "source": "https://openrouter.ai/switchpoint/router",
    "supports_tool_choice": true
  },
  "openrouter/x-ai/grok-4": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "openrouter",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "source": "https://openrouter.ai/x-ai/grok-4",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "openrouter/z-ai/glm-4.6": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 202800,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "mode": "chat",
    "output_cost_per_token": 0.00000175,
    "source": "https://openrouter.ai/z-ai/glm-4.6",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/z-ai/glm-4.6:exacto": {
    "input_cost_per_token": 4.5E-7,
    "litellm_provider": "openrouter",
    "max_input_tokens": 202800,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "mode": "chat",
    "output_cost_per_token": 0.0000019,
    "source": "https://openrouter.ai/z-ai/glm-4.6:exacto",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "openrouter/xiaomi/mimo-v2-flash": {
    "input_cost_per_token": 9E-8,
    "output_cost_per_token": 2.9E-7,
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 0.0,
    "litellm_provider": "openrouter",
    "max_input_tokens": 262144,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_reasoning": true,
    "supports_vision": false,
    "supports_prompt_caching": false
  },
  "openrouter/z-ai/glm-4.7": {
    "input_cost_per_token": 4E-7,
    "output_cost_per_token": 0.0000015,
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 0.0,
    "litellm_provider": "openrouter",
    "max_input_tokens": 202752,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_reasoning": true,
    "supports_vision": true,
    "supports_prompt_caching": false,
    "supports_assistant_prefill": true
  },
  "openrouter/z-ai/glm-4.7-flash": {
    "input_cost_per_token": 7E-8,
    "output_cost_per_token": 4E-7,
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 0.0,
    "litellm_provider": "openrouter",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_reasoning": true,
    "supports_vision": true,
    "supports_prompt_caching": false
  },
  "openrouter/minimax/minimax-m2.1": {
    "input_cost_per_token": 2.7E-7,
    "output_cost_per_token": 0.0000012,
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 0.0,
    "litellm_provider": "openrouter",
    "max_input_tokens": 204000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_reasoning": true,
    "supports_vision": true,
    "supports_prompt_caching": false,
    "supports_computer_use": false
  },
  "ovhcloud/DeepSeek-R1-Distill-Llama-70B": {
    "input_cost_per_token": 6.7E-7,
    "litellm_provider": "ovhcloud",
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "mode": "chat",
    "output_cost_per_token": 6.7E-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/deepseek-r1-distill-llama-70b",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "ovhcloud/Llama-3.1-8B-Instruct": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "ovhcloud",
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/llama-3-1-8b-instruct",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "ovhcloud/Meta-Llama-3_1-70B-Instruct": {
    "input_cost_per_token": 6.7E-7,
    "litellm_provider": "ovhcloud",
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "mode": "chat",
    "output_cost_per_token": 6.7E-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/meta-llama-3-1-70b-instruct",
    "supports_function_calling": false,
    "supports_response_schema": false,
    "supports_tool_choice": false
  },
  "ovhcloud/Meta-Llama-3_3-70B-Instruct": {
    "input_cost_per_token": 6.7E-7,
    "litellm_provider": "ovhcloud",
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "mode": "chat",
    "output_cost_per_token": 6.7E-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/meta-llama-3-3-70b-instruct",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "ovhcloud/Mistral-7B-Instruct-v0.3": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "ovhcloud",
    "max_input_tokens": 127000,
    "max_output_tokens": 127000,
    "max_tokens": 127000,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-7b-instruct-v0-3",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "ovhcloud/Mistral-Nemo-Instruct-2407": {
    "input_cost_per_token": 1.3E-7,
    "litellm_provider": "ovhcloud",
    "max_input_tokens": 118000,
    "max_output_tokens": 118000,
    "max_tokens": 118000,
    "mode": "chat",
    "output_cost_per_token": 1.3E-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-nemo-instruct-2407",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "ovhcloud/Mistral-Small-3.2-24B-Instruct-2506": {
    "input_cost_per_token": 9E-8,
    "litellm_provider": "ovhcloud",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2.8E-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/mistral-small-3-2-24b-instruct-2506",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "ovhcloud/gpt-oss-120b": {
    "input_cost_per_token": 8E-8,
    "litellm_provider": "ovhcloud",
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/gpt-oss-120b",
    "supports_function_calling": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": false
  },
  "ovhcloud/gpt-oss-20b": {
    "input_cost_per_token": 4E-8,
    "litellm_provider": "ovhcloud",
    "max_input_tokens": 131000,
    "max_output_tokens": 131000,
    "max_tokens": 131000,
    "mode": "chat",
    "output_cost_per_token": 1.5E-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/gpt-oss-20b",
    "supports_function_calling": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": false
  },
  "ovhcloud/mamba-codestral-7B-v0.1": {
    "input_cost_per_token": 1.9E-7,
    "litellm_provider": "ovhcloud",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 1.9E-7,
    "source": "https://endpoints.ai.cloud.ovh.net/models/mamba-codestral-7b-v0-1",
    "supports_function_calling": false,
    "supports_response_schema": true,
    "supports_tool_choice": false
  },
  "perplexity/llama-3.1-70b-instruct": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "perplexity",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000001
  },
  "perplexity/llama-3.1-8b-instruct": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "perplexity",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2E-7
  },
  "perplexity/llama-3.1-sonar-huge-128k-online": {
    "deprecation_date": "2025-02-22",
    "input_cost_per_token": 0.000005,
    "litellm_provider": "perplexity",
    "max_input_tokens": 127072,
    "max_output_tokens": 127072,
    "max_tokens": 127072,
    "mode": "chat",
    "output_cost_per_token": 0.000005
  },
  "perplexity/llama-3.1-sonar-large-128k-chat": {
    "deprecation_date": "2025-02-22",
    "input_cost_per_token": 0.000001,
    "litellm_provider": "perplexity",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000001
  },
  "perplexity/llama-3.1-sonar-large-128k-online": {
    "deprecation_date": "2025-02-22",
    "input_cost_per_token": 0.000001,
    "litellm_provider": "perplexity",
    "max_input_tokens": 127072,
    "max_output_tokens": 127072,
    "max_tokens": 127072,
    "mode": "chat",
    "output_cost_per_token": 0.000001
  },
  "perplexity/llama-3.1-sonar-small-128k-chat": {
    "deprecation_date": "2025-02-22",
    "input_cost_per_token": 2E-7,
    "litellm_provider": "perplexity",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 2E-7
  },
  "perplexity/llama-3.1-sonar-small-128k-online": {
    "deprecation_date": "2025-02-22",
    "input_cost_per_token": 2E-7,
    "litellm_provider": "perplexity",
    "max_input_tokens": 127072,
    "max_output_tokens": 127072,
    "max_tokens": 127072,
    "mode": "chat",
    "output_cost_per_token": 2E-7
  },
  "perplexity/sonar": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "perplexity",
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000001,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.012,
      "search_context_size_low": 0.005,
      "search_context_size_medium": 0.008
    },
    "supports_web_search": true
  },
  "perplexity/sonar-deep-research": {
    "citation_cost_per_token": 0.000002,
    "input_cost_per_token": 0.000002,
    "litellm_provider": "perplexity",
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.000003,
    "output_cost_per_token": 0.000008,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.005,
      "search_context_size_low": 0.005,
      "search_context_size_medium": 0.005
    },
    "supports_reasoning": true,
    "supports_web_search": true
  },
  "perplexity/sonar-pro": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "perplexity",
    "max_input_tokens": 200000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.014,
      "search_context_size_low": 0.006,
      "search_context_size_medium": 0.01
    },
    "supports_web_search": true
  },
  "perplexity/sonar-reasoning": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "perplexity",
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.014,
      "search_context_size_low": 0.005,
      "search_context_size_medium": 0.008
    },
    "supports_reasoning": true,
    "supports_web_search": true
  },
  "perplexity/sonar-reasoning-pro": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "perplexity",
    "max_input_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.014,
      "search_context_size_low": 0.006,
      "search_context_size_medium": 0.01
    },
    "supports_reasoning": true,
    "supports_web_search": true
  },
  "qwen.qwen3-coder-480b-a35b-v1:0": {
    "input_cost_per_token": 2.2E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 262000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.0000018,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "qwen.qwen3-235b-a22b-2507-v1:0": {
    "input_cost_per_token": 2.2E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 262144,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 8.8E-7,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "qwen.qwen3-coder-30b-a3b-v1:0": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 262144,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "qwen.qwen3-32b-v1:0": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "qwen.qwen3-next-80b-a3b": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_system_messages": true
  },
  "qwen.qwen3-vl-235b-a22b": {
    "input_cost_per_token": 5.3E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000266,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_vision": true
  },
  "qwen.qwen3-coder-next": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 262144,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "replicate/deepseek-ai/deepseek-v3.1": {
    "input_cost_per_token": 6.72E-7,
    "output_cost_per_token": 0.000002016,
    "litellm_provider": "replicate",
    "mode": "chat",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true
  },
  "sambanova/DeepSeek-R1-Distill-Llama-70B": {
    "input_cost_per_token": 7E-7,
    "litellm_provider": "sambanova",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.0000014,
    "source": "https://cloud.sambanova.ai/plans/pricing"
  },
  "sambanova/Llama-4-Maverick-17B-128E-Instruct": {
    "input_cost_per_token": 6.3E-7,
    "litellm_provider": "sambanova",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "metadata": {
      "notes": "For vision models, images are converted to 6432 input tokens and are billed at that amount"
    },
    "mode": "chat",
    "output_cost_per_token": 0.0000018,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "sambanova/Meta-Llama-3.3-70B-Instruct": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "sambanova",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "source": "https://cloud.sambanova.ai/plans/pricing",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "sambanova/gpt-oss-120b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.0000045,
    "litellm_provider": "sambanova",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_reasoning": true,
    "source": "https://cloud.sambanova.ai/plans/pricing"
  },
  "snowflake/jamba-1.5-large": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 256000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "snowflake/jamba-1.5-mini": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 256000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "snowflake/jamba-instruct": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 256000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "snowflake/llama3.1-405b": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "snowflake/llama3.1-70b": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "snowflake/llama3.1-8b": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "snowflake/llama3.2-1b": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "snowflake/llama3.2-3b": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "snowflake/llama3.3-70b": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "snowflake/mistral-large2": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "snowflake/reka-flash": {
    "litellm_provider": "snowflake",
    "max_input_tokens": 100000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat"
  },
  "together_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "together_ai",
    "max_input_tokens": 262000,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "source": "https://www.together.ai/models/qwen3-235b-a22b-instruct-2507-fp8",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "together_ai/Qwen/Qwen3-235B-A22B-Thinking-2507": {
    "input_cost_per_token": 6.5E-7,
    "litellm_provider": "together_ai",
    "max_input_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "source": "https://www.together.ai/models/qwen3-235b-a22b-thinking-2507",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "together_ai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "together_ai",
    "max_input_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "source": "https://www.together.ai/models/qwen3-coder-480b-a35b-instruct",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "together_ai/deepseek-ai/DeepSeek-R1": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "together_ai",
    "max_input_tokens": 128000,
    "max_output_tokens": 20480,
    "max_tokens": 20480,
    "mode": "chat",
    "output_cost_per_token": 0.000007,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "together_ai/deepseek-ai/DeepSeek-R1-0528-tput": {
    "input_cost_per_token": 5.5E-7,
    "litellm_provider": "together_ai",
    "max_input_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00000219,
    "source": "https://www.together.ai/models/deepseek-r1-0528-throughput",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "together_ai/openai/gpt-oss-120b": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "together_ai",
    "max_input_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "source": "https://www.together.ai/models/gpt-oss-120b",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "together_ai/openai/gpt-oss-20b": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "together_ai",
    "max_input_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2E-7,
    "source": "https://www.together.ai/models/gpt-oss-20b",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "together_ai/zai-org/GLM-4.5-Air-FP8": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "together_ai",
    "max_input_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000011,
    "source": "https://www.together.ai/models/glm-4-5-air",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "together_ai/zai-org/GLM-4.6": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "together_ai",
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "max_tokens": 200000,
    "mode": "chat",
    "output_cost_per_token": 0.0000022,
    "source": "https://www.together.ai/models/glm-4-6",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "together_ai/zai-org/GLM-4.7": {
    "input_cost_per_token": 4.5E-7,
    "litellm_provider": "together_ai",
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "max_tokens": 200000,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "source": "https://www.together.ai/models/glm-4-7",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "together_ai/moonshotai/Kimi-K2.5": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "together_ai",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.0000028,
    "source": "https://www.together.ai/models/kimi-k2-5",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_reasoning": true
  },
  "together_ai/moonshotai/Kimi-K2-Instruct-0905": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "together_ai",
    "max_input_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "source": "https://www.together.ai/models/kimi-k2-0905",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "together_ai/Qwen/Qwen3-Next-80B-A3B-Instruct": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "together_ai",
    "max_input_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "source": "https://www.together.ai/models/qwen3-next-80b-a3b-instruct",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "together_ai/Qwen/Qwen3-Next-80B-A3B-Thinking": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "together_ai",
    "max_input_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "source": "https://www.together.ai/models/qwen3-next-80b-a3b-thinking",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "us.amazon.nova-lite-v1:0": {
    "input_cost_per_token": 6E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 2.4E-7,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "us.amazon.nova-micro-v1:0": {
    "input_cost_per_token": 3.5E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 1.4E-7,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true
  },
  "us.amazon.nova-premier-v1:0": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 0.0000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": false,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "us.amazon.nova-pro-v1:0": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 300000,
    "max_output_tokens": 10000,
    "max_tokens": 10000,
    "mode": "chat",
    "output_cost_per_token": 0.0000032,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "us.anthropic.claude-3-5-haiku-20241022-v1:0": {
    "cache_creation_input_token_cost": 0.000001,
    "cache_read_input_token_cost": 8E-8,
    "input_cost_per_token": 8E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "us.anthropic.claude-haiku-4-5-20251001-v1:0": {
    "cache_creation_input_token_cost": 0.000001375,
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000055,
    "source": "https://aws.amazon.com/about-aws/whats-new/2025/10/claude-4-5-haiku-anthropic-amazon-bedrock",
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "us.anthropic.claude-3-haiku-20240307-v1:0": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00000125,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "us.anthropic.claude-3-opus-20240229-v1:0": {
    "input_cost_per_token": 0.000015,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "us.anthropic.claude-3-sonnet-20240229-v1:0": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "us.anthropic.claude-opus-4-1-20250805-v1:0": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "us.anthropic.claude-sonnet-4-5-20250929-v1:0": {
    "cache_creation_input_token_cost": 0.000004125,
    "cache_read_input_token_cost": 3.3E-7,
    "input_cost_per_token": 0.0000033,
    "input_cost_per_token_above_200k_tokens": 0.0000066,
    "output_cost_per_token_above_200k_tokens": 0.00002475,
    "cache_creation_input_token_cost_above_200k_tokens": 0.00000825,
    "cache_read_input_token_cost_above_200k_tokens": 6.6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000165,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "au.anthropic.claude-haiku-4-5-20251001-v1:0": {
    "cache_creation_input_token_cost": 0.000001375,
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000055,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "us.anthropic.claude-opus-4-20250514-v1:0": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "us.anthropic.claude-opus-4-5-20251101-v1:0": {
    "cache_creation_input_token_cost": 0.000006875,
    "cache_read_input_token_cost": 5.5E-7,
    "input_cost_per_token": 0.0000055,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000275,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "global.anthropic.claude-opus-4-5-20251101-v1:0": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "eu.anthropic.claude-opus-4-5-20251101-v1:0": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "us.anthropic.claude-sonnet-4-20250514-v1:0": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "us.deepseek.r1-v1:0": {
    "input_cost_per_token": 0.00000135,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.0000054,
    "supports_function_calling": false,
    "supports_reasoning": true,
    "supports_tool_choice": false
  },
  "us.deepseek.v3.2": {
    "input_cost_per_token": 6.2E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000185,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "eu.deepseek.v3.2": {
    "input_cost_per_token": 7.4E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "mode": "chat",
    "output_cost_per_token": 0.00000222,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "us.meta.llama3-1-405b-instruct-v1:0": {
    "input_cost_per_token": 0.00000532,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000016,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "us.meta.llama3-1-70b-instruct-v1:0": {
    "input_cost_per_token": 9.9E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 9.9E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "us.meta.llama3-1-8b-instruct-v1:0": {
    "input_cost_per_token": 2.2E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 2.2E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "us.meta.llama3-2-11b-instruct-v1:0": {
    "input_cost_per_token": 3.5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3.5E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "us.meta.llama3-2-1b-instruct-v1:0": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "us.meta.llama3-2-3b-instruct-v1:0": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1.5E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "us.meta.llama3-2-90b-instruct-v1:0": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "bedrock",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "us.meta.llama3-3-70b-instruct-v1:0": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 7.2E-7,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "us.meta.llama4-maverick-17b-instruct-v1:0": {
    "input_cost_per_token": 2.4E-7,
    "input_cost_per_token_batches": 1.2E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 9.7E-7,
    "output_cost_per_token_batches": 4.85E-7,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "us.meta.llama4-scout-17b-instruct-v1:0": {
    "input_cost_per_token": 1.7E-7,
    "input_cost_per_token_batches": 8.5E-8,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6.6E-7,
    "output_cost_per_token_batches": 3.3E-7,
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "us.mistral.pixtral-large-2502-v1:0": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": false
  },
  "v0/v0-1.0-md": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "v0",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "v0/v0-1.5-lg": {
    "input_cost_per_token": 0.000015,
    "litellm_provider": "v0",
    "max_input_tokens": 512000,
    "max_output_tokens": 512000,
    "max_tokens": 512000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "v0/v0-1.5-md": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "v0",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/alibaba/qwen3-coder": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 262144,
    "max_output_tokens": 66536,
    "max_tokens": 66536,
    "mode": "chat",
    "output_cost_per_token": 0.0000016,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/amazon/nova-lite": {
    "input_cost_per_token": 6E-8,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 300000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 2.4E-7,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/amazon/nova-micro": {
    "input_cost_per_token": 3.5E-8,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 1.4E-7,
    "supports_function_calling": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/amazon/nova-pro": {
    "input_cost_per_token": 8E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 300000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000032,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/anthropic/claude-3-haiku": {
    "cache_creation_input_token_cost": 3E-7,
    "cache_read_input_token_cost": 3E-8,
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00000125,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/anthropic/claude-3-opus": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/anthropic/claude-3.5-haiku": {
    "cache_creation_input_token_cost": 0.000001,
    "cache_read_input_token_cost": 8E-8,
    "input_cost_per_token": 8E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/anthropic/claude-3.5-sonnet": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/anthropic/claude-3.7-sonnet": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/anthropic/claude-4-opus": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/anthropic/claude-4-sonnet": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/anthropic/claude-3-5-sonnet": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/anthropic/claude-3-5-sonnet-20241022": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/anthropic/claude-3-7-sonnet": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/anthropic/claude-haiku-4.5": {
    "cache_creation_input_token_cost": 0.00000125,
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 0.000001,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/anthropic/claude-opus-4": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/anthropic/claude-opus-4.1": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/anthropic/claude-opus-4.5": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/anthropic/claude-opus-4.6": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/anthropic/claude-sonnet-4": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/anthropic/claude-sonnet-4.5": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vercel_ai_gateway/cohere/command-a": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 256000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/cohere/command-r": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/cohere/command-r-plus": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/deepseek/deepseek-r1": {
    "input_cost_per_token": 5.5E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.00000219,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/deepseek/deepseek-r1-distill-llama-70b": {
    "input_cost_per_token": 7.5E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 9.9E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/deepseek/deepseek-v3": {
    "input_cost_per_token": 9E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 9E-7,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/google/gemini-2.0-flash": {
    "deprecation_date": "2026-03-31",
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/google/gemini-2.0-flash-lite": {
    "deprecation_date": "2026-03-31",
    "input_cost_per_token": 7.5E-8,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/google/gemini-2.5-flash": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 1000000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/google/gemini-2.5-pro": {
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/meta/llama-3.1-70b": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 7.2E-7,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/meta/llama-3.1-8b": {
    "input_cost_per_token": 5E-8,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131000,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 8E-8,
    "supports_function_calling": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/meta/llama-3.2-11b": {
    "input_cost_per_token": 1.6E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 1.6E-7,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/meta/llama-3.2-1b": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 1E-7
  },
  "vercel_ai_gateway/meta/llama-3.2-3b": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 1.5E-7,
    "supports_function_calling": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/meta/llama-3.2-90b": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 7.2E-7,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/meta/llama-3.3-70b": {
    "input_cost_per_token": 7.2E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 7.2E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/meta/llama-4-maverick": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/meta/llama-4-scout": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/mistral/codestral": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 256000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 9E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/mistral/devstral-small": {
    "input_cost_per_token": 7E-8,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2.8E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/mistral/magistral-medium": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/mistral/magistral-small": {
    "input_cost_per_token": 5E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "supports_function_calling": true
  },
  "vercel_ai_gateway/mistral/ministral-3b": {
    "input_cost_per_token": 4E-8,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 4E-8,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/mistral/ministral-8b": {
    "input_cost_per_token": 1E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 1E-7,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/mistral/pixtral-12b": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 1.5E-7,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/mistral/pixtral-large": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/moonshotai/kimi-k2": {
    "input_cost_per_token": 5.5E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.0000022,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/openai/gpt-4-turbo": {
    "input_cost_per_token": 0.00001,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00003,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/openai/gpt-4.1": {
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/openai/gpt-4.1-mini": {
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 4E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0000016,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/openai/gpt-4.1-nano": {
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 2.5E-8,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/openai/gpt-4o": {
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.0000025,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/openai/gpt-4o-mini": {
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/openai/o1": {
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 0.0000075,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.00006,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/openai/o3": {
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/openai/o3-mini": {
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 5.5E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/openai/o4-mini": {
    "cache_creation_input_token_cost": 0.0,
    "cache_read_input_token_cost": 2.75E-7,
    "input_cost_per_token": 0.0000011,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 0.0000044,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_response_schema": true
  },
  "vercel_ai_gateway/perplexity/sonar": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 127000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "mode": "chat",
    "output_cost_per_token": 0.000001
  },
  "vercel_ai_gateway/perplexity/sonar-pro": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 200000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "mode": "chat",
    "output_cost_per_token": 0.000015
  },
  "vercel_ai_gateway/perplexity/sonar-reasoning": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 127000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "mode": "chat",
    "output_cost_per_token": 0.000005
  },
  "vercel_ai_gateway/perplexity/sonar-reasoning-pro": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 127000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "mode": "chat",
    "output_cost_per_token": 0.000008
  },
  "vercel_ai_gateway/vercel/v0-1.0-md": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/vercel/v0-1.5-md": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_vision": true,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/xai/grok-2": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131072,
    "max_output_tokens": 4000,
    "max_tokens": 4000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/xai/grok-3": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/xai/grok-3-fast": {
    "input_cost_per_token": 0.000005,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "supports_function_calling": true
  },
  "vercel_ai_gateway/xai/grok-3-mini": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 5E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/xai/grok-3-mini-fast": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/xai/grok-4": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/zai/glm-4.5": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.0000022,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/zai/glm-4.5-air": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "vercel_ai_gateway",
    "max_input_tokens": 128000,
    "max_output_tokens": 96000,
    "max_tokens": 96000,
    "mode": "chat",
    "output_cost_per_token": 0.0000011,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vercel_ai_gateway/zai/glm-4.6": {
    "litellm_provider": "vercel_ai_gateway",
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token": 4.5E-7,
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "max_tokens": 200000,
    "mode": "chat",
    "output_cost_per_token": 0.0000018,
    "source": "https://vercel.com/ai-gateway/models/glm-4.6",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/claude-3-5-haiku": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true
  },
  "vertex_ai/claude-3-5-haiku@20241022": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true
  },
  "vertex_ai/claude-haiku-4-5@20251001": {
    "cache_creation_input_token_cost": 0.00000125,
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 0.000001,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000005,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/haiku-4-5",
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_native_streaming": true,
    "supports_vision": true
  },
  "vertex_ai/claude-3-5-sonnet": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-3-5-sonnet-v2": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-3-5-sonnet-v2@20241022": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-3-5-sonnet@20240620": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-3-7-sonnet@20250219": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "vertex_ai/claude-3-haiku": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00000125,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-3-haiku@20240307": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00000125,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-3-opus": {
    "input_cost_per_token": 0.000015,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-3-opus@20240229": {
    "input_cost_per_token": 0.000015,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-3-sonnet": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-3-sonnet@20240229": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-opus-4": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "vertex_ai/claude-opus-4-1": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "input_cost_per_token_batches": 0.0000075,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "output_cost_per_token_batches": 0.0000375,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-opus-4-1@20250805": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "input_cost_per_token_batches": 0.0000075,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "output_cost_per_token_batches": 0.0000375,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-opus-4-5": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "vertex_ai/claude-opus-4-5@20251101": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_read_input_token_cost": 5E-7,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159,
    "supports_native_streaming": true
  },
  "vertex_ai/claude-opus-4-6": {
    "cache_creation_input_token_cost": 0.00000625,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000125,
    "cache_read_input_token_cost": 5E-7,
    "cache_read_input_token_cost_above_200k_tokens": 0.000001,
    "input_cost_per_token": 0.000005,
    "input_cost_per_token_above_200k_tokens": 0.00001,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "output_cost_per_token_above_200k_tokens": 0.0000375,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "vertex_ai/claude-sonnet-4-5": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "input_cost_per_token_batches": 0.0000015,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "output_cost_per_token_batches": 0.0000075,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/claude-sonnet-4-5@20250929": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "input_cost_per_token_batches": 0.0000015,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "output_cost_per_token_batches": 0.0000075,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_native_streaming": true
  },
  "vertex_ai/claude-opus-4@20250514": {
    "cache_creation_input_token_cost": 0.00001875,
    "cache_read_input_token_cost": 0.0000015,
    "input_cost_per_token": 0.000015,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 0.000075,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "vertex_ai/claude-sonnet-4": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "vertex_ai/claude-sonnet-4@20250514": {
    "cache_creation_input_token_cost": 0.00000375,
    "cache_read_input_token_cost": 3E-7,
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_200k_tokens": 0.000006,
    "output_cost_per_token_above_200k_tokens": 0.0000225,
    "cache_creation_input_token_cost_above_200k_tokens": 0.0000075,
    "cache_read_input_token_cost_above_200k_tokens": 6E-7,
    "litellm_provider": "vertex_ai-anthropic_models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "vertex_ai/mistralai/codestral-2@001": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 9E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/codestral-2": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 9E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/codestral-2@001": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 9E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistralai/codestral-2": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 9E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/codestral-2501": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/codestral@2405": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/codestral@latest": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/deepseek-ai/deepseek-v3.1-maas": {
    "input_cost_per_token": 0.00000135,
    "litellm_provider": "vertex_ai-deepseek_models",
    "max_input_tokens": 163840,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0000054,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supported_regions": [
      "us-west2"
    ],
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "vertex_ai/deepseek-ai/deepseek-v3.2-maas": {
    "input_cost_per_token": 5.6E-7,
    "input_cost_per_token_batches": 2.8E-7,
    "litellm_provider": "vertex_ai-deepseek_models",
    "max_input_tokens": 163840,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.00000168,
    "output_cost_per_token_batches": 8.4E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supported_regions": [
      "us-west2"
    ],
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "vertex_ai/jamba-1.5": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "vertex_ai-ai21_models",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_tool_choice": true
  },
  "vertex_ai/jamba-1.5-large": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vertex_ai-ai21_models",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supports_tool_choice": true
  },
  "vertex_ai/jamba-1.5-large@001": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vertex_ai-ai21_models",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000008,
    "supports_tool_choice": true
  },
  "vertex_ai/jamba-1.5-mini": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "vertex_ai-ai21_models",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_tool_choice": true
  },
  "vertex_ai/jamba-1.5-mini@001": {
    "input_cost_per_token": 2E-7,
    "litellm_provider": "vertex_ai-ai21_models",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 4E-7,
    "supports_tool_choice": true
  },
  "vertex_ai/meta/llama-3.1-405b-instruct-maas": {
    "input_cost_per_token": 0.000005,
    "litellm_provider": "vertex_ai-llama_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 0.000016,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/meta/llama-3.1-70b-instruct-maas": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "vertex_ai-llama_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/meta/llama-3.1-8b-instruct-maas": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "vertex_ai-llama_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "metadata": {
      "notes": "VertexAI states that The Llama 3.1 API service for llama-3.1-70b-instruct-maas and llama-3.1-8b-instruct-maas are in public preview and at no cost."
    },
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "vertex_ai-llama_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "metadata": {
      "notes": "VertexAI states that The Llama 3.2 API service is at no cost during public preview, and will be priced as per dollar-per-1M-tokens at GA."
    },
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas": {
    "input_cost_per_token": 3.5E-7,
    "litellm_provider": "vertex_ai-llama_models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "max_tokens": 1000000,
    "mode": "chat",
    "output_cost_per_token": 0.00000115,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas": {
    "input_cost_per_token": 3.5E-7,
    "litellm_provider": "vertex_ai-llama_models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 1000000,
    "max_tokens": 1000000,
    "mode": "chat",
    "output_cost_per_token": 0.00000115,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "vertex_ai-llama_models",
    "max_input_tokens": 10000000,
    "max_output_tokens": 10000000,
    "max_tokens": 10000000,
    "mode": "chat",
    "output_cost_per_token": 7E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "vertex_ai-llama_models",
    "max_input_tokens": 10000000,
    "max_output_tokens": 10000000,
    "max_tokens": 10000000,
    "mode": "chat",
    "output_cost_per_token": 7E-7,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "code"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/minimaxai/minimax-m2-maas": {
    "input_cost_per_token": 3E-7,
    "litellm_provider": "vertex_ai-minimax_models",
    "max_input_tokens": 196608,
    "max_output_tokens": 196608,
    "max_tokens": 196608,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/moonshotai/kimi-k2-thinking-maas": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "vertex_ai-moonshot_models",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "vertex_ai/zai-org/glm-4.7-maas": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "vertex_ai-zai_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000022,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "vertex_ai/zai-org/glm-5-maas": {
    "cache_read_input_token_cost": 1E-7,
    "input_cost_per_token": 0.000001,
    "litellm_provider": "vertex_ai-zai_models",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000032,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#glm-models",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistral-medium-3": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistral-medium-3@001": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistralai/mistral-medium-3": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistralai/mistral-medium-3@001": {
    "input_cost_per_token": 4E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000002,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistral-large-2411": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistral-large@2407": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistral-large@2411-001": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistral-large@latest": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 8191,
    "max_tokens": 8191,
    "mode": "chat",
    "output_cost_per_token": 0.000006,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistral-nemo@2407": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistral-nemo@latest": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.5E-7,
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/mistral-small-2503": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "vertex_ai-mistral_models",
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.000003,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "vertex_ai/openai/gpt-oss-120b-maas": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vertex_ai-openai_models",
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 6E-7,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/gpt-oss-120b-maas",
    "supports_reasoning": true
  },
  "vertex_ai/openai/gpt-oss-20b-maas": {
    "input_cost_per_token": 7.5E-8,
    "litellm_provider": "vertex_ai-openai_models",
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "source": "https://console.cloud.google.com/vertex-ai/publishers/openai/model-garden/gpt-oss-120b-maas",
    "supports_reasoning": true
  },
  "vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas": {
    "input_cost_per_token": 2.5E-7,
    "litellm_provider": "vertex_ai-qwen_models",
    "max_input_tokens": 262144,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.000001,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_regions": [
      "global"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas": {
    "input_cost_per_token": 0.000001,
    "litellm_provider": "vertex_ai-qwen_models",
    "max_input_tokens": 262144,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_regions": [
      "global"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/qwen/qwen3-next-80b-a3b-instruct-maas": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vertex_ai-qwen_models",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_regions": [
      "global"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "vertex_ai/qwen/qwen3-next-80b-a3b-thinking-maas": {
    "input_cost_per_token": 1.5E-7,
    "litellm_provider": "vertex_ai-qwen_models",
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "mode": "chat",
    "output_cost_per_token": 0.0000012,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_regions": [
      "global"
    ],
    "supports_function_calling": true,
    "supports_tool_choice": true
  },
  "voyage/voyage-context-3": {
    "input_cost_per_token": 1.8E-7,
    "litellm_provider": "voyage",
    "max_input_tokens": 120000,
    "max_tokens": 120000,
    "mode": "embedding",
    "output_cost_per_token": 0.0
  },
  "wandb/openai/gpt-oss-120b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 0.015,
    "output_cost_per_token": 0.06,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/openai/gpt-oss-20b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 0.005,
    "output_cost_per_token": 0.02,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/zai-org/GLM-4.5": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 0.055,
    "output_cost_per_token": 0.2,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/Qwen/Qwen3-235B-A22B-Instruct-2507": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 0.01,
    "output_cost_per_token": 0.01,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 0.1,
    "output_cost_per_token": 0.15,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/Qwen/Qwen3-235B-A22B-Thinking-2507": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 0.01,
    "output_cost_per_token": 0.01,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/moonshotai/Kimi-K2-Instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 6E-7,
    "output_cost_per_token": 0.0000025,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/meta-llama/Llama-3.1-8B-Instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 0.022,
    "output_cost_per_token": 0.022,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/deepseek-ai/DeepSeek-V3.1": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 0.055,
    "output_cost_per_token": 0.165,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/deepseek-ai/DeepSeek-R1-0528": {
    "max_tokens": 161000,
    "max_input_tokens": 161000,
    "max_output_tokens": 161000,
    "input_cost_per_token": 0.135,
    "output_cost_per_token": 0.54,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/deepseek-ai/DeepSeek-V3-0324": {
    "max_tokens": 161000,
    "max_input_tokens": 161000,
    "max_output_tokens": 161000,
    "input_cost_per_token": 0.114,
    "output_cost_per_token": 0.275,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/meta-llama/Llama-3.3-70B-Instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 0.071,
    "output_cost_per_token": 0.071,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "wandb/microsoft/Phi-4-mini-instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 0.008,
    "output_cost_per_token": 0.035,
    "litellm_provider": "wandb",
    "mode": "chat"
  },
  "watsonx/mistralai/mistral-large": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "watsonx",
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_audio_input": false,
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "watsonx/meta-llama/llama-3-2-11b-vision-instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 3.5E-7,
    "output_cost_per_token": 3.5E-7,
    "litellm_provider": "watsonx",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": true
  },
  "watsonx/meta-llama/llama-3-2-1b-instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "watsonx",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": false
  },
  "watsonx/meta-llama/llama-3-2-3b-instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 1.5E-7,
    "output_cost_per_token": 1.5E-7,
    "litellm_provider": "watsonx",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": false
  },
  "watsonx/meta-llama/llama-3-2-90b-vision-instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 0.000002,
    "output_cost_per_token": 0.000002,
    "litellm_provider": "watsonx",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": true
  },
  "watsonx/meta-llama/llama-3-3-70b-instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 7.1E-7,
    "output_cost_per_token": 7.1E-7,
    "litellm_provider": "watsonx",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": false
  },
  "watsonx/meta-llama/llama-4-maverick-17b": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 3.5E-7,
    "output_cost_per_token": 0.0000014,
    "litellm_provider": "watsonx",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": false
  },
  "watsonx/meta-llama/llama-guard-3-11b-vision": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 3.5E-7,
    "output_cost_per_token": 3.5E-7,
    "litellm_provider": "watsonx",
    "mode": "chat",
    "supports_function_calling": false,
    "supports_parallel_function_calling": false,
    "supports_vision": true
  },
  "watsonx/mistralai/mistral-medium-2505": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.00001,
    "litellm_provider": "watsonx",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": false
  },
  "watsonx/mistralai/pixtral-12b-2409": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 3.5E-7,
    "output_cost_per_token": 3.5E-7,
    "litellm_provider": "watsonx",
    "mode": "chat",
    "supports_function_calling": false,
    "supports_parallel_function_calling": false,
    "supports_vision": true
  },
  "xai/grok-2": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-2-1212": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-2-latest": {
    "input_cost_per_token": 0.000002,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3": {
    "cache_read_input_token_cost": 7.5E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3-beta": {
    "cache_read_input_token_cost": 7.5E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3-fast-beta": {
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3-fast-latest": {
    "cache_read_input_token_cost": 0.00000125,
    "input_cost_per_token": 0.000005,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000025,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3-latest": {
    "cache_read_input_token_cost": 7.5E-7,
    "input_cost_per_token": 0.000003,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3-mini": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 5E-7,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3-mini-beta": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 5E-7,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3-mini-fast": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3-mini-fast-beta": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3-mini-fast-latest": {
    "cache_read_input_token_cost": 1.5E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000004,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-3-mini-latest": {
    "cache_read_input_token_cost": 7.5E-8,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 5E-7,
    "source": "https://x.ai/api#pricing",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-4": {
    "input_cost_per_token": 0.000003,
    "litellm_provider": "xai",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-4-fast-reasoning": {
    "litellm_provider": "xai",
    "max_input_tokens": 2000000.0,
    "max_output_tokens": 2000000.0,
    "max_tokens": 2000000.0,
    "mode": "chat",
    "input_cost_per_token": 2E-7,
    "input_cost_per_token_above_128k_tokens": 4E-7,
    "output_cost_per_token": 5E-7,
    "output_cost_per_token_above_128k_tokens": 0.000001,
    "cache_read_input_token_cost": 5E-8,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-4-fast-non-reasoning": {
    "litellm_provider": "xai",
    "max_input_tokens": 2000000.0,
    "max_output_tokens": 2000000.0,
    "cache_read_input_token_cost": 5E-8,
    "max_tokens": 2000000.0,
    "mode": "chat",
    "input_cost_per_token": 2E-7,
    "input_cost_per_token_above_128k_tokens": 4E-7,
    "output_cost_per_token": 5E-7,
    "output_cost_per_token_above_128k_tokens": 0.000001,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-4-0709": {
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_128k_tokens": 0.000006,
    "litellm_provider": "xai",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "output_cost_per_token_above_128k_tokens": 0.00003,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-4-latest": {
    "input_cost_per_token": 0.000003,
    "input_cost_per_token_above_128k_tokens": 0.000006,
    "litellm_provider": "xai",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "output_cost_per_token_above_128k_tokens": 0.00003,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_web_search": true
  },
  "xai/grok-4-1-fast": {
    "cache_read_input_token_cost": 5E-8,
    "input_cost_per_token": 2E-7,
    "input_cost_per_token_above_128k_tokens": 4E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 2000000.0,
    "max_output_tokens": 2000000.0,
    "max_tokens": 2000000.0,
    "mode": "chat",
    "output_cost_per_token": 5E-7,
    "output_cost_per_token_above_128k_tokens": 0.000001,
    "source": "https://docs.x.ai/docs/models/grok-4-1-fast-reasoning",
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "xai/grok-4-1-fast-reasoning": {
    "cache_read_input_token_cost": 5E-8,
    "input_cost_per_token": 2E-7,
    "input_cost_per_token_above_128k_tokens": 4E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 2000000.0,
    "max_output_tokens": 2000000.0,
    "max_tokens": 2000000.0,
    "mode": "chat",
    "output_cost_per_token": 5E-7,
    "output_cost_per_token_above_128k_tokens": 0.000001,
    "source": "https://docs.x.ai/docs/models/grok-4-1-fast-reasoning",
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "xai/grok-4-1-fast-reasoning-latest": {
    "cache_read_input_token_cost": 5E-8,
    "input_cost_per_token": 2E-7,
    "input_cost_per_token_above_128k_tokens": 4E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 2000000.0,
    "max_output_tokens": 2000000.0,
    "max_tokens": 2000000.0,
    "mode": "chat",
    "output_cost_per_token": 5E-7,
    "output_cost_per_token_above_128k_tokens": 0.000001,
    "source": "https://docs.x.ai/docs/models/grok-4-1-fast-reasoning",
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "xai/grok-4-1-fast-non-reasoning": {
    "cache_read_input_token_cost": 5E-8,
    "input_cost_per_token": 2E-7,
    "input_cost_per_token_above_128k_tokens": 4E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 2000000.0,
    "max_output_tokens": 2000000.0,
    "max_tokens": 2000000.0,
    "mode": "chat",
    "output_cost_per_token": 5E-7,
    "output_cost_per_token_above_128k_tokens": 0.000001,
    "source": "https://docs.x.ai/docs/models/grok-4-1-fast-non-reasoning",
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "xai/grok-4-1-fast-non-reasoning-latest": {
    "cache_read_input_token_cost": 5E-8,
    "input_cost_per_token": 2E-7,
    "input_cost_per_token_above_128k_tokens": 4E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 2000000.0,
    "max_output_tokens": 2000000.0,
    "max_tokens": 2000000.0,
    "mode": "chat",
    "output_cost_per_token": 5E-7,
    "output_cost_per_token_above_128k_tokens": 0.000001,
    "source": "https://docs.x.ai/docs/models/grok-4-1-fast-non-reasoning",
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "xai/grok-beta": {
    "input_cost_per_token": 0.000005,
    "litellm_provider": "xai",
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "mode": "chat",
    "output_cost_per_token": 0.000015,
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "xai/grok-code-fast": {
    "cache_read_input_token_cost": 2E-8,
    "input_cost_per_token": 2E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "xai/grok-code-fast-1": {
    "cache_read_input_token_cost": 2E-8,
    "input_cost_per_token": 2E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "xai/grok-code-fast-1-0825": {
    "cache_read_input_token_cost": 2E-8,
    "input_cost_per_token": 2E-7,
    "litellm_provider": "xai",
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "max_tokens": 256000,
    "mode": "chat",
    "output_cost_per_token": 0.0000015,
    "source": "https://docs.x.ai/docs/models",
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "zai.glm-4.7": {
    "input_cost_per_token": 6E-7,
    "litellm_provider": "bedrock_converse",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.0000022,
    "supports_function_calling": true,
    "supports_reasoning": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "source": "https://aws.amazon.com/bedrock/pricing/"
  },
  "zai/glm-4.7": {
    "cache_creation_input_token_cost": 0,
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token": 6E-7,
    "output_cost_per_token": 0.0000022,
    "litellm_provider": "zai",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://docs.z.ai/guides/overview/pricing"
  },
  "zai/glm-4.6": {
    "cache_creation_input_token_cost": 0,
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token": 6E-7,
    "output_cost_per_token": 0.0000022,
    "litellm_provider": "zai",
    "max_input_tokens": 200000,
    "max_output_tokens": 128000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true,
    "source": "https://docs.z.ai/guides/overview/pricing"
  },
  "zai/glm-4.5": {
    "input_cost_per_token": 6E-7,
    "output_cost_per_token": 0.0000022,
    "litellm_provider": "zai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "source": "https://docs.z.ai/guides/overview/pricing"
  },
  "zai/glm-4.5v": {
    "input_cost_per_token": 6E-7,
    "output_cost_per_token": 0.0000018,
    "litellm_provider": "zai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "source": "https://docs.z.ai/guides/overview/pricing"
  },
  "zai/glm-4.5-x": {
    "input_cost_per_token": 0.0000022,
    "output_cost_per_token": 0.0000089,
    "litellm_provider": "zai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "source": "https://docs.z.ai/guides/overview/pricing"
  },
  "zai/glm-4.5-air": {
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 0.0000011,
    "litellm_provider": "zai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "source": "https://docs.z.ai/guides/overview/pricing"
  },
  "zai/glm-4.5-airx": {
    "input_cost_per_token": 0.0000011,
    "output_cost_per_token": 0.0000045,
    "litellm_provider": "zai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "source": "https://docs.z.ai/guides/overview/pricing"
  },
  "zai/glm-4-32b-0414-128k": {
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "zai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "source": "https://docs.z.ai/guides/overview/pricing"
  },
  "zai/glm-4.5-flash": {
    "input_cost_per_token": 0,
    "output_cost_per_token": 0,
    "litellm_provider": "zai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "mode": "chat",
    "supports_function_calling": true,
    "supports_tool_choice": true,
    "source": "https://docs.z.ai/guides/overview/pricing"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 4.5E-7,
    "output_cost_per_token": 0.0000018,
    "litellm_provider": "fireworks_ai",
    "mode": "chat",
    "supports_reasoning": true
  },
  "fireworks_ai/accounts/fireworks/models/cogito-671b-v2-p1": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 0.0000012,
    "output_cost_per_token": 0.0000012,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-3b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-70b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-llama-8b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-14b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/cogito-v1-preview-qwen-32b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-base": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 5E-7,
    "output_cost_per_token": 5E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-lite-instruct": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 5E-7,
    "output_cost_per_token": 5E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-prover-v2": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 0.0000012,
    "output_cost_per_token": 0.0000012,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-70b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-llama-8b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-14b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-32b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-r1-distill-qwen-7b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/deepseek-v2-lite-chat": {
    "max_tokens": 163840,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "input_cost_per_token": 5E-7,
    "output_cost_per_token": 5E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/devstral-small-2505": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/dobby-mini-unhinged-plus-llama-3-1-8b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/dobby-unhinged-llama-3-3-70b-new": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/dolphin-2-9-2-qwen2-72b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/fare-20b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/gemma-3-27b-it": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/glm-4p5v": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 0.0000012,
    "output_cost_per_token": 0.0000012,
    "litellm_provider": "fireworks_ai",
    "mode": "chat",
    "supports_reasoning": true
  },
  "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-120b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 0.0000012,
    "output_cost_per_token": 0.0000012,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/gpt-oss-safeguard-20b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 5E-7,
    "output_cost_per_token": 5E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/kat-coder": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/kat-dev-32b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/kat-dev-72b-exp": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/llama-guard-3-1b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/llama-guard-3-8b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p1-70b-instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p2-1b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p2-3b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/llama-v3p3-70b-instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/ministral-3-14b-instruct-2512": {
    "max_tokens": 256000,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/ministral-3-3b-instruct-2512": {
    "max_tokens": 256000,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/ministral-3-8b-instruct-2512": {
    "max_tokens": 256000,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/mistral-large-3-fp8": {
    "max_tokens": 256000,
    "max_input_tokens": 256000,
    "max_output_tokens": 256000,
    "input_cost_per_token": 0.0000012,
    "output_cost_per_token": 0.0000012,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/mistral-nemo-base-2407": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/mistral-nemo-instruct-2407": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-12b-v2": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/nvidia-nemotron-nano-9b-v2": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/phi-3-mini-128k-instruct": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen-v2p5-7b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen2p5-14b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen2p5-32b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen2p5-72b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-32b-instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-3b-instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-72b-instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen2p5-vl-7b-instruct": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-1p7b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 1E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 2.2E-7,
    "output_cost_per_token": 8.8E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-instruct-2507": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 2.2E-7,
    "output_cost_per_token": 8.8E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-235b-a22b-thinking-2507": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 2.2E-7,
    "output_cost_per_token": 8.8E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 1.5E-7,
    "output_cost_per_token": 6E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-instruct-2507": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 5E-7,
    "output_cost_per_token": 5E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-30b-a3b-thinking-2507": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-32b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat",
    "supports_reasoning": true
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-4b-instruct-2507": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-coder-30b-a3b-instruct": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 1.5E-7,
    "output_cost_per_token": 6E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-instruct": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 2.2E-7,
    "output_cost_per_token": 8.8E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-vl-235b-a22b-thinking": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 2.2E-7,
    "output_cost_per_token": 8.8E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-instruct": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 1.5E-7,
    "output_cost_per_token": 6E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwen3-vl-30b-a3b-thinking": {
    "max_tokens": 262144,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "input_cost_per_token": 1.5E-7,
    "output_cost_per_token": 6E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/qwq-32b": {
    "max_tokens": 131072,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/rolm-ocr": {
    "max_tokens": 128000,
    "max_input_tokens": 128000,
    "max_output_tokens": 128000,
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 2E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "fireworks_ai/accounts/fireworks/models/yi-34b-200k-capybara": {
    "max_tokens": 200000,
    "max_input_tokens": 200000,
    "max_output_tokens": 200000,
    "input_cost_per_token": 9E-7,
    "output_cost_per_token": 9E-7,
    "litellm_provider": "fireworks_ai",
    "mode": "chat"
  },
  "novita/deepseek/deepseek-v3.2": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 2.69E-7,
    "output_cost_per_token": 4E-7,
    "max_input_tokens": 163840,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 1.345E-7,
    "input_cost_per_token_cache_hit": 1.345E-7,
    "supports_reasoning": true
  },
  "novita/minimax/minimax-m2.1": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000012,
    "max_input_tokens": 204800,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 3E-8,
    "input_cost_per_token_cache_hit": 3E-8
  },
  "novita/zai-org/glm-4.7": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 6E-7,
    "output_cost_per_token": 0.0000022,
    "max_input_tokens": 204800,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token_cache_hit": 1.1E-7,
    "supports_reasoning": true
  },
  "novita/xiaomimimo/mimo-v2-flash": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 1E-7,
    "output_cost_per_token": 3E-7,
    "max_input_tokens": 262144,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 2E-8,
    "input_cost_per_token_cache_hit": 2E-8,
    "supports_reasoning": true
  },
  "novita/moonshotai/kimi-k2-thinking": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 6E-7,
    "output_cost_per_token": 0.0000025,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "supports_reasoning": true
  },
  "novita/minimax/minimax-m2": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000012,
    "max_input_tokens": 204800,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "cache_read_input_token_cost": 3E-8,
    "input_cost_per_token_cache_hit": 3E-8,
    "supports_reasoning": true
  },
  "novita/deepseek/deepseek-v3.2-exp": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 2.7E-7,
    "output_cost_per_token": 4.1E-7,
    "max_input_tokens": 163840,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "supports_reasoning": true
  },
  "novita/qwen/qwen3-vl-235b-a22b-thinking": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 9.8E-7,
    "output_cost_per_token": 0.00000395,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_reasoning": true
  },
  "novita/zai-org/glm-4.6v": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 9E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 5.5E-8,
    "input_cost_per_token_cache_hit": 5.5E-8,
    "supports_reasoning": true
  },
  "novita/zai-org/glm-4.6": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 5.5E-7,
    "output_cost_per_token": 0.0000022,
    "max_input_tokens": 204800,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token_cache_hit": 1.1E-7,
    "supports_reasoning": true
  },
  "novita/kwaipilot/kat-coder-pro": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000012,
    "max_input_tokens": 256000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 6E-8,
    "input_cost_per_token_cache_hit": 6E-8
  },
  "novita/qwen/qwen3-next-80b-a3b-instruct": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 1.5E-7,
    "output_cost_per_token": 0.0000015,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/qwen/qwen3-next-80b-a3b-thinking": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 1.5E-7,
    "output_cost_per_token": 0.0000015,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "supports_reasoning": true
  },
  "novita/deepseek/deepseek-v3.1-terminus": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 2.7E-7,
    "output_cost_per_token": 0.000001,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 1.35E-7,
    "input_cost_per_token_cache_hit": 1.35E-7,
    "supports_reasoning": true
  },
  "novita/qwen/qwen3-vl-235b-a22b-instruct": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000015,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/qwen/qwen3-max": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 0.00000211,
    "output_cost_per_token": 0.00000845,
    "max_input_tokens": 262144,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/skywork/r1v4-lite": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 6E-7,
    "max_input_tokens": 262144,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/deepseek/deepseek-v3.1": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 2.7E-7,
    "output_cost_per_token": 0.000001,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 1.35E-7,
    "input_cost_per_token_cache_hit": 1.35E-7,
    "supports_reasoning": true
  },
  "novita/moonshotai/kimi-k2-0905": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 6E-7,
    "output_cost_per_token": 0.0000025,
    "max_input_tokens": 262144,
    "max_output_tokens": 262144,
    "max_tokens": 262144,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/qwen/qwen3-coder-480b-a35b-instruct": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.0000013,
    "max_input_tokens": 262144,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/qwen/qwen3-coder-30b-a3b-instruct": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 7E-8,
    "output_cost_per_token": 2.7E-7,
    "max_input_tokens": 160000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/openai/gpt-oss-120b": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 5E-8,
    "output_cost_per_token": 2.5E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "supports_reasoning": true
  },
  "novita/moonshotai/kimi-k2-instruct": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 5.7E-7,
    "output_cost_per_token": 0.0000023,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/deepseek/deepseek-v3-0324": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 2.7E-7,
    "output_cost_per_token": 0.00000112,
    "max_input_tokens": 163840,
    "max_output_tokens": 163840,
    "max_tokens": 163840,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 1.35E-7,
    "input_cost_per_token_cache_hit": 1.35E-7
  },
  "novita/zai-org/glm-4.5": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 6E-7,
    "output_cost_per_token": 0.0000022,
    "max_input_tokens": 131072,
    "max_output_tokens": 98304,
    "max_tokens": 98304,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "cache_read_input_token_cost": 1.1E-7,
    "input_cost_per_token_cache_hit": 1.1E-7,
    "supports_reasoning": true
  },
  "novita/qwen/qwen3-235b-a22b-thinking-2507": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 3E-7,
    "output_cost_per_token": 0.000003,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_reasoning": true
  },
  "novita/google/gemma-3-12b-it": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 5E-8,
    "output_cost_per_token": 1E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/openai/gpt-oss-20b": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 4E-8,
    "output_cost_per_token": 1.5E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "supports_reasoning": true
  },
  "novita/qwen/qwen3-235b-a22b-instruct-2507": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 9E-8,
    "output_cost_per_token": 5.8E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/meta-llama/llama-3.3-70b-instruct": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 1.35E-7,
    "output_cost_per_token": 4E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 120000,
    "max_tokens": 120000,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true
  },
  "novita/minimaxai/minimax-m1-80k": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 5.5E-7,
    "output_cost_per_token": 0.0000022,
    "max_input_tokens": 1000000,
    "max_output_tokens": 40000,
    "max_tokens": 40000,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_reasoning": true
  },
  "novita/deepseek/deepseek-r1-0528": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 7E-7,
    "output_cost_per_token": 0.0000025,
    "max_input_tokens": 163840,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "cache_read_input_token_cost": 3.5E-7,
    "input_cost_per_token_cache_hit": 3.5E-7,
    "supports_reasoning": true
  },
  "novita/deepseek/deepseek-r1-0528-qwen3-8b": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 6E-8,
    "output_cost_per_token": 9E-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "supports_system_messages": true,
    "supports_reasoning": true
  },
  "novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 2.7E-7,
    "output_cost_per_token": 8.5E-7,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "supports_vision": true,
    "supports_system_messages": true
  },
  "novita/meta-llama/llama-4-scout-17b-16e-instruct": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 1.8E-7,
    "output_cost_per_token": 5.9E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "supports_vision": true,
    "supports_system_messages": true
  },
  "novita/baidu/ernie-4.5-21B-a3b-thinking": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 7E-8,
    "output_cost_per_token": 2.8E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "supports_system_messages": true,
    "supports_reasoning": true
  },
  "novita/baichuan/baichuan-m2-32b": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 7E-8,
    "output_cost_per_token": 7E-8,
    "max_input_tokens": 131072,
    "max_output_tokens": 131072,
    "max_tokens": 131072,
    "supports_system_messages": true
  },
  "novita/baidu/ernie-4.5-vl-424b-a47b": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 4.2E-7,
    "output_cost_per_token": 0.00000125,
    "max_input_tokens": 123000,
    "max_output_tokens": 16000,
    "max_tokens": 16000,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_reasoning": true
  },
  "novita/baidu/ernie-4.5-300b-a47b-paddle": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 2.8E-7,
    "output_cost_per_token": 0.0000011,
    "max_input_tokens": 123000,
    "max_output_tokens": 12000,
    "max_tokens": 12000,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/deepseek/deepseek-prover-v2-671b": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 7E-7,
    "output_cost_per_token": 0.0000025,
    "max_input_tokens": 160000,
    "max_output_tokens": 160000,
    "max_tokens": 160000,
    "supports_system_messages": true
  },
  "novita/baidu/ernie-4.5-vl-28b-a3b-thinking": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 3.9E-7,
    "output_cost_per_token": 3.9E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_response_schema": true,
    "supports_reasoning": true
  },
  "novita/qwen/qwen3-vl-8b-instruct": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 8E-8,
    "output_cost_per_token": 5E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/zai-org/glm-4.5-air": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 1.3E-7,
    "output_cost_per_token": 8.5E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 98304,
    "max_tokens": 98304,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true,
    "supports_reasoning": true
  },
  "novita/qwen/qwen3-vl-30b-a3b-instruct": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 7E-7,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/qwen/qwen3-vl-30b-a3b-thinking": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 2E-7,
    "output_cost_per_token": 0.000001,
    "max_input_tokens": 131072,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_system_messages": true,
    "supports_response_schema": true
  },
  "novita/baidu/ernie-4.5-21B-a3b": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 7E-8,
    "output_cost_per_token": 2.8E-7,
    "max_input_tokens": 120000,
    "max_output_tokens": 8000,
    "max_tokens": 8000,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_system_messages": true
  },
  "novita/qwen/qwen3-8b-fp8": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 3.5E-8,
    "output_cost_per_token": 1.38E-7,
    "max_input_tokens": 128000,
    "max_output_tokens": 20000,
    "max_tokens": 20000,
    "supports_system_messages": true,
    "supports_reasoning": true
  },
  "novita/qwen/qwen3-4b-fp8": {
    "litellm_provider": "novita",
    "mode": "chat",
    "input_cost_per_token": 3E-8,
    "output_cost_per_token": 3E-8,
    "max_input_tokens": 128000,
    "max_output_tokens": 20000,
    "max_tokens": 20000,
    "supports_system_messages": true,
    "supports_reasoning": true
  },
  "llamagate/llama-3.1-8b": {
    "max_tokens": 8192,
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "input_cost_per_token": 3E-8,
    "output_cost_per_token": 5E-8,
    "litellm_provider": "llamagate",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_response_schema": true
  },
  "llamagate/llama-3.2-3b": {
    "max_tokens": 8192,
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "input_cost_per_token": 4E-8,
    "output_cost_per_token": 8E-8,
    "litellm_provider": "llamagate",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_response_schema": true
  },
  "llamagate/dolphin3-8b": {
    "max_tokens": 8192,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "input_cost_per_token": 8E-8,
    "output_cost_per_token": 1.5E-7,
    "litellm_provider": "llamagate",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_response_schema": true
  },
  "llamagate/deepseek-r1-7b-qwen": {
    "max_tokens": 16384,
    "max_input_tokens": 131072,
    "max_output_tokens": 16384,
    "input_cost_per_token": 8E-8,
    "output_cost_per_token": 1.5E-7,
    "litellm_provider": "llamagate",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_reasoning": true
  },
  "llamagate/gemma3-4b": {
    "max_tokens": 8192,
    "max_input_tokens": 128000,
    "max_output_tokens": 8192,
    "input_cost_per_token": 3E-8,
    "output_cost_per_token": 8E-8,
    "litellm_provider": "llamagate",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_response_schema": true,
    "supports_vision": true
  },
  "gpt-5-search-api": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-search-api-2025-10-14": {
    "cache_read_input_token_cost": 1.25E-7,
    "input_cost_per_token": 0.00000125,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-realtime-mini-2025-10-06": {
    "cache_creation_input_audio_token_cost": 3E-7,
    "cache_read_input_audio_token_cost": 3E-7,
    "cache_read_input_token_cost": 6E-8,
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_image": 8E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-realtime-mini-2025-12-15": {
    "cache_creation_input_audio_token_cost": 3E-7,
    "cache_read_input_audio_token_cost": 3E-7,
    "cache_read_input_token_cost": 6E-8,
    "input_cost_per_audio_token": 0.00001,
    "input_cost_per_image": 8E-7,
    "input_cost_per_token": 6E-7,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.00002,
    "output_cost_per_token": 0.0000024,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gemini/gemini-2.0-flash-lite-001": {
    "cache_read_input_token_cost": 1.875E-8,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7.5E-8,
    "input_cost_per_token": 7.5E-8,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 50,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3E-7,
    "rpm": 4000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 4000000
  },
  "gemini-2.5-flash-native-audio-latest": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://ai.google.dev/pricing",
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true
  },
  "gemini-2.5-flash-native-audio-preview-09-2025": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://ai.google.dev/pricing",
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true
  },
  "gemini-2.5-flash-native-audio-preview-12-2025": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://ai.google.dev/pricing",
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true
  },
  "gemini/gemini-2.5-flash-native-audio-latest": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://ai.google.dev/pricing",
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "tpm": 250000,
    "rpm": 10
  },
  "gemini/gemini-2.5-flash-native-audio-preview-09-2025": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://ai.google.dev/pricing",
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "tpm": 250000,
    "rpm": 10
  },
  "gemini/gemini-2.5-flash-native-audio-preview-12-2025": {
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 0.0000025,
    "source": "https://ai.google.dev/pricing",
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "tpm": 250000,
    "rpm": 10
  },
  "gemini-flash-latest": {
    "cache_read_input_token_cost": 3E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000
  },
  "gemini-flash-lite-latest": {
    "cache_read_input_token_cost": 1E-8,
    "input_cost_per_audio_token": 3E-7,
    "input_cost_per_token": 1E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4E-7,
    "output_cost_per_token": 4E-7,
    "rpm": 15,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini-pro-latest": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 2000,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 800000
  },
  "gemini/gemini-pro-latest": {
    "cache_read_input_token_cost": 1.25E-7,
    "cache_read_input_token_cost_above_200k_tokens": 2.5E-7,
    "input_cost_per_token": 0.00000125,
    "input_cost_per_token_above_200k_tokens": 0.0000025,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 0.00001,
    "output_cost_per_token_above_200k_tokens": 0.000015,
    "rpm": 2000,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 800000
  },
  "gemini-exp-1206": {
    "cache_read_input_token_cost": 3E-8,
    "input_cost_per_audio_token": 0.000001,
    "input_cost_per_token": 3E-7,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 0.0000025,
    "output_cost_per_token": 0.0000025,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000
  }
}
