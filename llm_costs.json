{
    "gpt-4.1": {
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 8e-6,
        "input_cost_per_token_batches": 1e-6,
        "output_cost_per_token_batches": 4e-6,
        "cache_read_input_token_cost": 5e-7,
        "litellm_provider": "openai",
        "mode": "chat",
        "supported_endpoints": ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
        "supported_modalities": ["text", "image"],
        "supported_output_modalities": ["text"],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_native_streaming": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.03,
            "search_context_size_medium": 0.035,
            "search_context_size_high": 0.05
        }
    },
    "gpt-4.1-2025-04-14": {
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 8e-6,
        "input_cost_per_token_batches": 1e-6,
        "output_cost_per_token_batches": 4e-6,
        "cache_read_input_token_cost": 5e-7,
        "litellm_provider": "openai",
        "mode": "chat",
        "supported_endpoints": ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
        "supported_modalities": ["text", "image"],
        "supported_output_modalities": ["text"],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_native_streaming": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.03,
            "search_context_size_medium": 0.035,
            "search_context_size_high": 0.05
        }
    },
    "gpt-4.1-mini": {
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "input_cost_per_token": 4e-7,
        "output_cost_per_token": 1.6e-6,
        "input_cost_per_token_batches": 2e-7,
        "output_cost_per_token_batches": 8e-7,
        "cache_read_input_token_cost": 1e-7,
        "litellm_provider": "openai",
        "mode": "chat",
        "supported_endpoints": ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
        "supported_modalities": ["text", "image"],
        "supported_output_modalities": ["text"],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_native_streaming": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275,
            "search_context_size_high": 0.03
        }
    },
    "gpt-4.1-mini-2025-04-14": {
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "input_cost_per_token": 4e-7,
        "output_cost_per_token": 1.6e-6,
        "input_cost_per_token_batches": 2e-7,
        "output_cost_per_token_batches": 8e-7,
        "cache_read_input_token_cost": 1e-7,
        "litellm_provider": "openai",
        "mode": "chat",
        "supported_endpoints": ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
        "supported_modalities": ["text", "image"],
        "supported_output_modalities": ["text"],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_native_streaming": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275,
            "search_context_size_high": 0.03
        }
    },
    "gpt-4.1-nano": {
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-7,
        "output_cost_per_token": 4e-7,
        "input_cost_per_token_batches": 5e-8,
        "output_cost_per_token_batches": 2e-7,
        "cache_read_input_token_cost": 2.5e-8,
        "litellm_provider": "openai",
        "mode": "chat",
        "supported_endpoints": ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
        "supported_modalities": ["text", "image"],
        "supported_output_modalities": ["text"],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_native_streaming": true
    },
    "gpt-4.1-nano-2025-04-14": {
        "max_tokens": 32768,
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1e-7,
        "output_cost_per_token": 4e-7,
        "input_cost_per_token_batches": 5e-8,
        "output_cost_per_token_batches": 2e-7,
        "cache_read_input_token_cost": 2.5e-8,
        "litellm_provider": "openai",
        "mode": "chat",
        "supported_endpoints": ["/v1/chat/completions", "/v1/batch", "/v1/responses"],
        "supported_modalities": ["text", "image"],
        "supported_output_modalities": ["text"],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_native_streaming": true
    },
    "gpt-4o": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "input_cost_per_token_batches": 1.25e-6,
        "output_cost_per_token_batches": 5e-6,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.03,
            "search_context_size_medium": 0.035,
            "search_context_size_high": 0.05
        }
    },
    "gpt-4o-search-preview-2025-03-11": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "input_cost_per_token_batches": 1.25e-6,
        "output_cost_per_token_batches": 5e-6,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.03,
            "search_context_size_medium": 0.035,
            "search_context_size_high": 0.05
        }
    },
    "gpt-4o-search-preview": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "input_cost_per_token_batches": 1.25e-6,
        "output_cost_per_token_batches": 5e-6,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.03,
            "search_context_size_medium": 0.035,
            "search_context_size_high": 0.05
        }
    },
    "gpt-4.5-preview": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 7.5e-5,
        "output_cost_per_token": 0.00015,
        "input_cost_per_token_batches": 3.75e-5,
        "output_cost_per_token_batches": 7.5e-5,
        "cache_read_input_token_cost": 3.75e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4.5-preview-2025-02-27": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 7.5e-5,
        "output_cost_per_token": 0.00015,
        "input_cost_per_token_batches": 3.75e-5,
        "output_cost_per_token_batches": 7.5e-5,
        "cache_read_input_token_cost": 3.75e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "input_cost_per_audio_token": 0.0001,
        "output_cost_per_token": 1e-5,
        "output_cost_per_audio_token": 0.0002,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2024-12-17": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "input_cost_per_audio_token": 4e-5,
        "output_cost_per_token": 1e-5,
        "output_cost_per_audio_token": 8e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2024-10-01": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "input_cost_per_audio_token": 0.0001,
        "output_cost_per_token": 1e-5,
        "output_cost_per_audio_token": 0.0002,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-audio-preview-2024-12-17": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1.5e-7,
        "input_cost_per_audio_token": 1e-5,
        "output_cost_per_token": 6e-7,
        "output_cost_per_audio_token": 2e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 6e-7,
        "input_cost_per_token_batches": 7.5e-8,
        "output_cost_per_token_batches": 3e-7,
        "cache_read_input_token_cost": 7.5e-8,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275,
            "search_context_size_high": 0.03
        }
    },
    "gpt-4o-mini-search-preview-2025-03-11": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 6e-7,
        "input_cost_per_token_batches": 7.5e-8,
        "output_cost_per_token_batches": 3e-7,
        "cache_read_input_token_cost": 7.5e-8,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275,
            "search_context_size_high": 0.03
        }
    },
    "gpt-4o-mini-search-preview": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 6e-7,
        "input_cost_per_token_batches": 7.5e-8,
        "output_cost_per_token_batches": 3e-7,
        "cache_read_input_token_cost": 7.5e-8,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275,
            "search_context_size_high": 0.03
        }
    },
    "gpt-4o-mini-2024-07-18": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 6e-7,
        "input_cost_per_token_batches": 7.5e-8,
        "output_cost_per_token_batches": 3e-7,
        "cache_read_input_token_cost": 7.5e-8,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 30,
            "search_context_size_medium": 35,
            "search_context_size_high": 50
        }
    },
    "o1-pro": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.00015,
        "output_cost_per_token": 0.0006,
        "input_cost_per_token_batches": 7.5e-5,
        "output_cost_per_token_batches": 0.0003,
        "litellm_provider": "openai",
        "mode": "responses",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_native_streaming": false,
        "supports_reasoning": true,
        "supported_modalities": ["text", "image"],
        "supported_output_modalities": ["text"],
        "supported_endpoints": ["/v1/responses", "/v1/batch"]
    },
    "o1-pro-2025-03-19": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 0.00015,
        "output_cost_per_token": 0.0006,
        "input_cost_per_token_batches": 7.5e-5,
        "output_cost_per_token_batches": 0.0003,
        "litellm_provider": "openai",
        "mode": "responses",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_native_streaming": false,
        "supports_reasoning": true,
        "supported_modalities": ["text", "image"],
        "supported_output_modalities": ["text"],
        "supported_endpoints": ["/v1/responses", "/v1/batch"]
    },
    "o1": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "cache_read_input_token_cost": 7.5e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_response_schema": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "o1-mini": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 1.1e-6,
        "output_cost_per_token": 4.4e-6,
        "cache_read_input_token_cost": 5.5e-7,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_prompt_caching": true
    },
    "o3-mini": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.1e-6,
        "output_cost_per_token": 4.4e-6,
        "cache_read_input_token_cost": 5.5e-7,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_vision": false,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "o3-mini-2025-01-31": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.1e-6,
        "output_cost_per_token": 4.4e-6,
        "cache_read_input_token_cost": 5.5e-7,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_vision": false,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "o1-mini-2024-09-12": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.2e-5,
        "cache_read_input_token_cost": 1.5e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_reasoning": true,
        "supports_prompt_caching": true
    },
    "o1-preview": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "cache_read_input_token_cost": 7.5e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_reasoning": true,
        "supports_prompt_caching": true
    },
    "o1-preview-2024-09-12": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "cache_read_input_token_cost": 7.5e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_reasoning": true,
        "supports_prompt_caching": true
    },
    "o1-2024-12-17": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "cache_read_input_token_cost": 7.5e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_response_schema": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "chatgpt-4o-latest": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-2024-05-13": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-6,
        "output_cost_per_token": 1.5e-5,
        "input_cost_per_token_batches": 2.5e-6,
        "output_cost_per_token_batches": 7.5e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-2024-08-06": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "input_cost_per_token_batches": 1.25e-6,
        "output_cost_per_token_batches": 5e-6,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_web_search": true,
        "search_context_cost_per_query": {
            "search_context_size_low": 0.03,
            "search_context_size_medium": 0.035,
            "search_context_size_high": 0.05
        }
    },
    "gpt-4o-2024-11-20": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "input_cost_per_token_batches": 1.25e-6,
        "output_cost_per_token_batches": 5e-6,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2024-10-01": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-6,
        "input_cost_per_audio_token": 0.0001,
        "cache_read_input_token_cost": 2.5e-6,
        "cache_creation_input_audio_token_cost": 2e-5,
        "output_cost_per_token": 2e-5,
        "output_cost_per_audio_token": 0.0002,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-6,
        "input_cost_per_audio_token": 4e-5,
        "cache_read_input_token_cost": 2.5e-6,
        "output_cost_per_token": 2e-5,
        "output_cost_per_audio_token": 8e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2024-12-17": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-6,
        "input_cost_per_audio_token": 4e-5,
        "cache_read_input_token_cost": 2.5e-6,
        "output_cost_per_token": 2e-5,
        "output_cost_per_audio_token": 8e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-realtime-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 6e-7,
        "input_cost_per_audio_token": 1e-5,
        "cache_read_input_token_cost": 3e-7,
        "cache_creation_input_audio_token_cost": 3e-7,
        "output_cost_per_token": 2.4e-6,
        "output_cost_per_audio_token": 2e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-realtime-preview-2024-12-17": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 6e-7,
        "input_cost_per_audio_token": 1e-5,
        "cache_read_input_token_cost": 3e-7,
        "cache_creation_input_audio_token_cost": 3e-7,
        "output_cost_per_token": 2.4e-6,
        "output_cost_per_audio_token": 2e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-turbo-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-turbo": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-turbo-2024-04-09": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-1106-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0125-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-vision-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "deprecation_date": "2024-12-06",
        "supports_tool_choice": true
    },
    "gpt-4-1106-vision-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "deprecation_date": "2024-12-06",
        "supports_tool_choice": true
    },
    "ft:gpt-4o-2024-08-06": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 3.75e-6,
        "output_cost_per_token": 1.5e-5,
        "input_cost_per_token_batches": 1.875e-6,
        "output_cost_per_token_batches": 7.5e-6,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4o-2024-11-20": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 3.75e-6,
        "cache_creation_input_token_cost": 1.875e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4o-mini-2024-07-18": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 3e-7,
        "output_cost_per_token": 1.2e-6,
        "input_cost_per_token_batches": 1.5e-7,
        "output_cost_per_token_batches": 6e-7,
        "cache_read_input_token_cost": 1.5e-7,
        "litellm_provider": "openai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-mini-realtime-preview-2024-12-17": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 6e-7,
        "input_cost_per_audio_token": 1e-5,
        "cache_read_input_token_cost": 3e-7,
        "cache_creation_input_audio_token_cost": 3e-7,
        "output_cost_per_token": 2.4e-6,
        "output_cost_per_audio_token": 2e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-mini-realtime-preview-2024-12-17": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 6.6e-7,
        "input_cost_per_audio_token": 1.1e-5,
        "cache_read_input_token_cost": 3.3e-7,
        "cache_creation_input_audio_token_cost": 3.3e-7,
        "output_cost_per_token": 2.64e-6,
        "output_cost_per_audio_token": 2.2e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/us/gpt-4o-mini-realtime-preview-2024-12-17": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 6.6e-7,
        "input_cost_per_audio_token": 1.1e-5,
        "cache_read_input_token_cost": 3.3e-7,
        "cache_creation_input_audio_token_cost": 3.3e-7,
        "output_cost_per_token": 2.64e-6,
        "output_cost_per_audio_token": 2.2e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-realtime-preview-2024-12-17": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-6,
        "input_cost_per_audio_token": 4e-5,
        "cache_read_input_token_cost": 2.5e-6,
        "output_cost_per_token": 2e-5,
        "output_cost_per_audio_token": 8e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supported_modalities": ["text", "audio"],
        "supported_output_modalities": ["text", "audio"],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/us/gpt-4o-realtime-preview-2024-12-17": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5.5e-6,
        "input_cost_per_audio_token": 4.4e-5,
        "cache_read_input_token_cost": 2.75e-6,
        "cache_read_input_audio_token_cost": 2.5e-6,
        "output_cost_per_token": 2.2e-5,
        "output_cost_per_audio_token": 8e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supported_modalities": ["text", "audio"],
        "supported_output_modalities": ["text", "audio"],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-realtime-preview-2024-12-17": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5.5e-6,
        "input_cost_per_audio_token": 4.4e-5,
        "cache_read_input_token_cost": 2.75e-6,
        "cache_read_input_audio_token_cost": 2.5e-6,
        "output_cost_per_token": 2.2e-5,
        "output_cost_per_audio_token": 8e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supported_modalities": ["text", "audio"],
        "supported_output_modalities": ["text", "audio"],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-realtime-preview-2024-10-01": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-6,
        "input_cost_per_audio_token": 0.0001,
        "cache_read_input_token_cost": 2.5e-6,
        "cache_creation_input_audio_token_cost": 2e-5,
        "output_cost_per_token": 2e-5,
        "output_cost_per_audio_token": 0.0002,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/us/gpt-4o-realtime-preview-2024-10-01": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5.5e-6,
        "input_cost_per_audio_token": 0.00011,
        "cache_read_input_token_cost": 2.75e-6,
        "cache_creation_input_audio_token_cost": 2.2e-5,
        "output_cost_per_token": 2.2e-5,
        "output_cost_per_audio_token": 0.00022,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-realtime-preview-2024-10-01": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5.5e-6,
        "input_cost_per_audio_token": 0.00011,
        "cache_read_input_token_cost": 2.75e-6,
        "cache_creation_input_audio_token_cost": 2.2e-5,
        "output_cost_per_token": 2.2e-5,
        "output_cost_per_audio_token": 0.00022,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/o3-mini-2025-01-31": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.1e-6,
        "output_cost_per_token": 4.4e-6,
        "cache_read_input_token_cost": 5.5e-7,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_reasoning": true,
        "supports_vision": false,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/us/o3-mini-2025-01-31": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.21e-6,
        "input_cost_per_token_batches": 6.05e-7,
        "output_cost_per_token": 4.84e-6,
        "output_cost_per_token_batches": 2.42e-6,
        "cache_read_input_token_cost": 6.05e-7,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_vision": false,
        "supports_reasoning": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/eu/o3-mini-2025-01-31": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.21e-6,
        "input_cost_per_token_batches": 6.05e-7,
        "output_cost_per_token": 4.84e-6,
        "output_cost_per_token_batches": 2.42e-6,
        "cache_read_input_token_cost": 6.05e-7,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_vision": false,
        "supports_reasoning": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/o3-mini": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.1e-6,
        "output_cost_per_token": 4.4e-6,
        "cache_read_input_token_cost": 5.5e-7,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_vision": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "azure/o1-mini": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 1.21e-6,
        "output_cost_per_token": 4.84e-6,
        "cache_read_input_token_cost": 6.05e-7,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_reasoning": true,
        "supports_prompt_caching": true
    },
    "azure/o1-mini-2024-09-12": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 1.21e-6,
        "output_cost_per_token": 4.84e-6,
        "cache_read_input_token_cost": 6.05e-7,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_reasoning": true,
        "supports_prompt_caching": true
    },
    "azure/us/o1-mini-2024-09-12": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 1.21e-6,
        "input_cost_per_token_batches": 6.05e-7,
        "output_cost_per_token": 4.84e-6,
        "output_cost_per_token_batches": 2.42e-6,
        "cache_read_input_token_cost": 6.05e-7,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_prompt_caching": true
    },
    "azure/eu/o1-mini-2024-09-12": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 1.21e-6,
        "input_cost_per_token_batches": 6.05e-7,
        "output_cost_per_token": 4.84e-6,
        "output_cost_per_token_batches": 2.42e-6,
        "cache_read_input_token_cost": 6.05e-7,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_prompt_caching": true
    },
    "azure/o1": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "cache_read_input_token_cost": 7.5e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_reasoning": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/o1-2024-12-17": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "cache_read_input_token_cost": 7.5e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_reasoning": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/us/o1-2024-12-17": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.65e-5,
        "output_cost_per_token": 6.6e-5,
        "cache_read_input_token_cost": 8.25e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/eu/o1-2024-12-17": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.65e-5,
        "output_cost_per_token": 6.6e-5,
        "cache_read_input_token_cost": 8.25e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/o1-preview": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "cache_read_input_token_cost": 7.5e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_reasoning": true,
        "supports_prompt_caching": true
    },
    "azure/o1-preview-2024-09-12": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "cache_read_input_token_cost": 7.5e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_reasoning": true,
        "supports_prompt_caching": true
    },
    "azure/us/o1-preview-2024-09-12": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.65e-5,
        "output_cost_per_token": 6.6e-5,
        "cache_read_input_token_cost": 8.25e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_prompt_caching": true
    },
    "azure/eu/o1-preview-2024-09-12": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.65e-5,
        "output_cost_per_token": 6.6e-5,
        "cache_read_input_token_cost": 8.25e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_prompt_caching": true
    },
    "azure/gpt-4.5-preview": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 7.5e-5,
        "output_cost_per_token": 0.00015,
        "input_cost_per_token_batches": 3.75e-5,
        "output_cost_per_token_batches": 7.5e-5,
        "cache_read_input_token_cost": 3.75e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/global/gpt-4o-2024-11-20": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-2024-08-06": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/global/gpt-4o-2024-08-06": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-2024-11-20": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.75e-6,
        "output_cost_per_token": 1.1e-5,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/us/gpt-4o-2024-11-20": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.75e-6,
        "cache_creation_input_token_cost": 1.38e-6,
        "output_cost_per_token": 1.1e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-2024-11-20": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.75e-6,
        "cache_creation_input_token_cost": 1.38e-6,
        "output_cost_per_token": 1.1e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-2024-05-13": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/global-standard/gpt-4o-2024-08-06": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "cache_read_input_token_cost": 1.25e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/us/gpt-4o-2024-08-06": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.75e-6,
        "output_cost_per_token": 1.1e-5,
        "cache_read_input_token_cost": 1.375e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-2024-08-06": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.75e-6,
        "output_cost_per_token": 1.1e-5,
        "cache_read_input_token_cost": 1.375e-6,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/global-standard/gpt-4o-2024-11-20": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "azure/global-standard/gpt-4o-mini": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 6e-7,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-mini": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1.65e-7,
        "output_cost_per_token": 6.6e-7,
        "cache_read_input_token_cost": 7.5e-8,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4o-mini-2024-07-18": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1.65e-7,
        "output_cost_per_token": 6.6e-7,
        "cache_read_input_token_cost": 7.5e-8,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/us/gpt-4o-mini-2024-07-18": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1.65e-7,
        "output_cost_per_token": 6.6e-7,
        "cache_read_input_token_cost": 8.3e-8,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/eu/gpt-4o-mini-2024-07-18": {
        "max_tokens": 16384,
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "input_cost_per_token": 1.65e-7,
        "output_cost_per_token": 6.6e-7,
        "cache_read_input_token_cost": 8.3e-8,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-turbo-2024-04-09": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-0125-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-1106-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-turbo": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "azure/gpt-4-turbo-vision-preview": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-5,
        "output_cost_per_token": 3e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "azure/command-r-plus": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "azure",
        "mode": "chat",
        "supports_function_calling": true
    },
    "azure_ai/deepseek-r1": {
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1.35e-6,
        "output_cost_per_token": 5.4e-6,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_tool_choice": true,
        "supports_reasoning": true,
        "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367"
    },
    "azure_ai/deepseek-v3": {
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1.14e-6,
        "output_cost_per_token": 4.56e-6,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_tool_choice": true,
        "source": "https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438"
    },
    "azure_ai/mistral-nemo": {
        "max_tokens": 4096,
        "max_input_tokens": 131072,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 1.5e-7,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice"
    },
    "azure_ai/mistral-small-2503": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1e-6,
        "output_cost_per_token": 3e-6,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "azure_ai/mistral-large-2407": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 6e-6,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
        "supports_tool_choice": true
    },
    "azure_ai/mistral-large-latest": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 6e-6,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview",
        "supports_tool_choice": true
    },
    "azure_ai/ministral-3b": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 4e-8,
        "output_cost_per_token": 4e-8,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview",
        "supports_tool_choice": true
    },
    "azure_ai/Llama-3.2-11B-Vision-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 3.7e-7,
        "output_cost_per_token": 3.7e-7,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "supports_vision": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview",
        "supports_tool_choice": true
    },
    "azure_ai/Llama-3.3-70B-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 7.1e-7,
        "output_cost_per_token": 7.1e-7,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview",
        "supports_tool_choice": true
    },
    "azure_ai/Llama-3.2-90B-Vision-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 2.04e-6,
        "output_cost_per_token": 2.04e-6,
        "litellm_provider": "azure_ai",
        "supports_function_calling": true,
        "supports_vision": true,
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview",
        "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-8B-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 3e-7,
        "output_cost_per_token": 6.1e-7,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice",
        "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-70B-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 2.68e-6,
        "output_cost_per_token": 3.54e-6,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice",
        "supports_tool_choice": true
    },
    "azure_ai/Meta-Llama-3.1-405B-Instruct": {
        "max_tokens": 2048,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 5.33e-6,
        "output_cost_per_token": 1.6e-5,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "source": "https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-4-mini-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 131072,
        "max_output_tokens": 4096,
        "input_cost_per_token": 7.5e-8,
        "output_cost_per_token": 3e-7,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_function_calling": true,
        "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112"
    },
    "azure_ai/Phi-4-multimodal-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 131072,
        "max_output_tokens": 4096,
        "input_cost_per_token": 8e-8,
        "input_cost_per_audio_token": 4e-6,
        "output_cost_per_token": 3.2e-7,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "source": "https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112"
    },
    "azure_ai/Phi-3.5-mini-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.3e-7,
        "output_cost_per_token": 5.2e-7,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3.5-vision-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.3e-7,
        "output_cost_per_token": 5.2e-7,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": true,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3.5-MoE-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.6e-7,
        "output_cost_per_token": 6.4e-7,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3-mini-128k-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.3e-7,
        "output_cost_per_token": 5.2e-7,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3-small-128k-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 6e-7,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "azure_ai/Phi-3-medium-128k-instruct": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.7e-7,
        "output_cost_per_token": 6.8e-7,
        "litellm_provider": "azure_ai",
        "mode": "chat",
        "supports_vision": false,
        "source": "https://azure.microsoft.com/en-us/pricing/details/phi-3/",
        "supports_tool_choice": true
    },
    "claude-instant-1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 1.63e-6,
        "output_cost_per_token": 5.51e-6,
        "litellm_provider": "anthropic",
        "mode": "chat"
    },
    "mistral/mistral-large-latest": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 6e-6,
        "litellm_provider": "mistral",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-large-2411": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 6e-6,
        "litellm_provider": "mistral",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "mistral/mistral-large-2407": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 9e-6,
        "litellm_provider": "mistral",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "mistral/pixtral-large-latest": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 6e-6,
        "litellm_provider": "mistral",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_assistant_prefill": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "mistral/pixtral-large-2411": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 6e-6,
        "litellm_provider": "mistral",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_assistant_prefill": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "mistral/pixtral-12b-2409": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 1.5e-7,
        "litellm_provider": "mistral",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_assistant_prefill": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "mistral/open-mistral-nemo": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3e-7,
        "output_cost_per_token": 3e-7,
        "litellm_provider": "mistral",
        "mode": "chat",
        "source": "https://mistral.ai/technology/",
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "mistral/open-mistral-nemo-2407": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3e-7,
        "output_cost_per_token": 3e-7,
        "litellm_provider": "mistral",
        "mode": "chat",
        "source": "https://mistral.ai/technology/",
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "mistral/open-codestral-mamba": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 2.5e-7,
        "litellm_provider": "mistral",
        "mode": "chat",
        "source": "https://mistral.ai/technology/",
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "mistral/codestral-mamba-latest": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 2.5e-7,
        "litellm_provider": "mistral",
        "mode": "chat",
        "source": "https://mistral.ai/technology/",
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "xai/grok-beta": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 5e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "xai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "xai/grok-3-beta": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "xai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_response_schema": false,
        "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-fast-beta": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 5e-6,
        "output_cost_per_token": 2.5e-5,
        "litellm_provider": "xai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_response_schema": false,
        "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-fast-latest": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 5e-6,
        "output_cost_per_token": 2.5e-5,
        "litellm_provider": "xai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_response_schema": false,
        "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-mini-beta": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 3e-7,
        "output_cost_per_token": 5e-7,
        "litellm_provider": "xai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-mini-fast-beta": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 6e-7,
        "output_cost_per_token": 4e-6,
        "litellm_provider": "xai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "source": "https://x.ai/api#pricing"
    },
    "xai/grok-3-mini-fast-latest": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 6e-7,
        "output_cost_per_token": 4e-6,
        "litellm_provider": "xai",
        "mode": "chat",
        "supports_reasoning": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_response_schema": false,
        "source": "https://x.ai/api#pricing"
    },
    "xai/grok-2-1212": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 1e-5,
        "litellm_provider": "xai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "xai/grok-2": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 1e-5,
        "litellm_provider": "xai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "xai/grok-2-latest": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 1e-5,
        "litellm_provider": "xai",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "deepseek/deepseek-coder": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.4e-7,
        "input_cost_per_token_cache_hit": 1.4e-8,
        "output_cost_per_token": 2.8e-7,
        "litellm_provider": "deepseek",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true,
        "supports_prompt_caching": true
    },
    "groq/deepseek-r1-distill-llama-70b": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 7.5e-7,
        "output_cost_per_token": 9.9e-7,
        "litellm_provider": "groq",
        "mode": "chat",
        "supports_system_messages": false,
        "supports_function_calling": false,
        "supports_reasoning": true,
        "supports_response_schema": false,
        "supports_tool_choice": true
    },
    "groq/llama-3.3-70b-versatile": {
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 5.9e-7,
        "output_cost_per_token": 7.9e-7,
        "litellm_provider": "groq",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "cerebras/llama3.1-8b": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1e-7,
        "output_cost_per_token": 1e-7,
        "litellm_provider": "cerebras",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "cerebras/llama3.1-70b": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 6e-7,
        "output_cost_per_token": 6e-7,
        "litellm_provider": "cerebras",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "cerebras/llama3.3-70b": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 8.5e-7,
        "output_cost_per_token": 1.2e-6,
        "litellm_provider": "cerebras",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "claude-instant-1.2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 1.63e-7,
        "output_cost_per_token": 5.51e-7,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "claude-2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "anthropic",
        "mode": "chat"
    },
    "claude-2.1": {
        "max_tokens": 8191,
        "max_input_tokens": 200000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "claude-3-haiku-20240307": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 1.25e-6,
        "cache_creation_input_token_cost": 3e-7,
        "cache_read_input_token_cost": 3e-8,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 264,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-03-01",
        "supports_tool_choice": true
    },
    "claude-3-5-haiku-20241022": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 8e-7,
        "output_cost_per_token": 4e-6,
        "cache_creation_input_token_cost": 1e-6,
        "cache_read_input_token_cost": 8e-8,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 264,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-10-01",
        "supports_tool_choice": true
    },
    "claude-3-5-haiku-latest": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1e-6,
        "output_cost_per_token": 5e-6,
        "cache_creation_input_token_cost": 1.25e-6,
        "cache_read_input_token_cost": 1e-7,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 264,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-10-01",
        "supports_tool_choice": true
    },
    "claude-3-opus-latest": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 7.5e-5,
        "cache_creation_input_token_cost": 1.875e-5,
        "cache_read_input_token_cost": 1.5e-6,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 395,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-03-01",
        "supports_tool_choice": true
    },
    "claude-3-opus-20240229": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 7.5e-5,
        "cache_creation_input_token_cost": 1.875e-5,
        "cache_read_input_token_cost": 1.5e-6,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 395,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-03-01",
        "supports_tool_choice": true
    },
    "claude-3-sonnet-20240229": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-07-21",
        "supports_tool_choice": true
    },
    "claude-3-5-sonnet-latest": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "cache_creation_input_token_cost": 3.75e-6,
        "cache_read_input_token_cost": 3e-7,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-06-01",
        "supports_tool_choice": true
    },
    "claude-3-5-sonnet-20240620": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "cache_creation_input_token_cost": 3.75e-6,
        "cache_read_input_token_cost": 3e-7,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-06-01",
        "supports_tool_choice": true
    },
    "claude-3-7-sonnet-latest": {
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "cache_creation_input_token_cost": 3.75e-6,
        "cache_read_input_token_cost": 3e-7,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-06-01",
        "supports_tool_choice": true,
        "supports_reasoning": true
    },
    "claude-3-7-sonnet-20250219": {
        "max_tokens": 128000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "cache_creation_input_token_cost": 3.75e-6,
        "cache_read_input_token_cost": 3e-7,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2026-02-01",
        "supports_tool_choice": true,
        "supports_reasoning": true
    },
    "claude-3-5-sonnet-20241022": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "cache_creation_input_token_cost": 3.75e-6,
        "cache_read_input_token_cost": 3e-7,
        "litellm_provider": "anthropic",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-10-01",
        "supports_tool_choice": true
    },
    "gemini-1.5-pro": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_audio_per_second": 3.125e-5,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_token": 1.25e-6,
        "input_cost_per_character": 3.125e-7,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-5,
        "input_cost_per_token_above_128k_tokens": 2.5e-6,
        "input_cost_per_character_above_128k_tokens": 6.25e-7,
        "output_cost_per_token": 5e-6,
        "output_cost_per_character": 1.25e-6,
        "output_cost_per_token_above_128k_tokens": 1e-5,
        "output_cost_per_character_above_128k_tokens": 2.5e-6,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "gemini-1.5-pro-002": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_audio_per_second": 3.125e-5,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_token": 1.25e-6,
        "input_cost_per_character": 3.125e-7,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-5,
        "input_cost_per_token_above_128k_tokens": 2.5e-6,
        "input_cost_per_character_above_128k_tokens": 6.25e-7,
        "output_cost_per_token": 5e-6,
        "output_cost_per_character": 1.25e-6,
        "output_cost_per_token_above_128k_tokens": 1e-5,
        "output_cost_per_character_above_128k_tokens": 2.5e-6,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_vision": true,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro",
        "deprecation_date": "2025-09-24"
    },
    "gemini-1.5-pro-001": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_audio_per_second": 3.125e-5,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_token": 1.25e-6,
        "input_cost_per_character": 3.125e-7,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-5,
        "input_cost_per_token_above_128k_tokens": 2.5e-6,
        "input_cost_per_character_above_128k_tokens": 6.25e-7,
        "output_cost_per_token": 5e-6,
        "output_cost_per_character": 1.25e-6,
        "output_cost_per_token_above_128k_tokens": 1e-5,
        "output_cost_per_character_above_128k_tokens": 2.5e-6,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_vision": true,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "deprecation_date": "2025-05-24"
    },
    "gemini-1.5-pro-preview-0514": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_audio_per_second": 3.125e-5,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_token": 7.8125e-8,
        "input_cost_per_character": 3.125e-7,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-5,
        "input_cost_per_token_above_128k_tokens": 1.5625e-7,
        "input_cost_per_character_above_128k_tokens": 6.25e-7,
        "output_cost_per_token": 3.125e-7,
        "output_cost_per_character": 1.25e-6,
        "output_cost_per_token_above_128k_tokens": 6.25e-7,
        "output_cost_per_character_above_128k_tokens": 2.5e-6,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "gemini-1.5-pro-preview-0215": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_audio_per_second": 3.125e-5,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_token": 7.8125e-8,
        "input_cost_per_character": 3.125e-7,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-5,
        "input_cost_per_token_above_128k_tokens": 1.5625e-7,
        "input_cost_per_character_above_128k_tokens": 6.25e-7,
        "output_cost_per_token": 3.125e-7,
        "output_cost_per_character": 1.25e-6,
        "output_cost_per_token_above_128k_tokens": 6.25e-7,
        "output_cost_per_character_above_128k_tokens": 2.5e-6,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "gemini-1.5-pro-preview-0409": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_audio_per_second": 3.125e-5,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_token": 7.8125e-8,
        "input_cost_per_character": 3.125e-7,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-5,
        "input_cost_per_token_above_128k_tokens": 1.5625e-7,
        "input_cost_per_character_above_128k_tokens": 6.25e-7,
        "output_cost_per_token": 3.125e-7,
        "output_cost_per_character": 1.25e-6,
        "output_cost_per_token_above_128k_tokens": 6.25e-7,
        "output_cost_per_character_above_128k_tokens": 2.5e-6,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models"
    },
    "gemini-1.5-flash": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 2e-5,
        "input_cost_per_video_per_second": 2e-5,
        "input_cost_per_audio_per_second": 2e-6,
        "input_cost_per_token": 7.5e-8,
        "input_cost_per_character": 1.875e-8,
        "input_cost_per_token_above_128k_tokens": 1e-6,
        "input_cost_per_character_above_128k_tokens": 2.5e-7,
        "input_cost_per_image_above_128k_tokens": 4e-5,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-5,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-6,
        "output_cost_per_token": 3e-7,
        "output_cost_per_character": 7.5e-8,
        "output_cost_per_token_above_128k_tokens": 6e-7,
        "output_cost_per_character_above_128k_tokens": 1.5e-7,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "gemini-1.5-flash-exp-0827": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 2e-5,
        "input_cost_per_video_per_second": 2e-5,
        "input_cost_per_audio_per_second": 2e-6,
        "input_cost_per_token": 4.688e-9,
        "input_cost_per_character": 1.875e-8,
        "input_cost_per_token_above_128k_tokens": 1e-6,
        "input_cost_per_character_above_128k_tokens": 2.5e-7,
        "input_cost_per_image_above_128k_tokens": 4e-5,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-5,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-6,
        "output_cost_per_token": 4.6875e-9,
        "output_cost_per_character": 1.875e-8,
        "output_cost_per_token_above_128k_tokens": 9.375e-9,
        "output_cost_per_character_above_128k_tokens": 3.75e-8,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "gemini-1.5-flash-002": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 2e-5,
        "input_cost_per_video_per_second": 2e-5,
        "input_cost_per_audio_per_second": 2e-6,
        "input_cost_per_token": 7.5e-8,
        "input_cost_per_character": 1.875e-8,
        "input_cost_per_token_above_128k_tokens": 1e-6,
        "input_cost_per_character_above_128k_tokens": 2.5e-7,
        "input_cost_per_image_above_128k_tokens": 4e-5,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-5,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-6,
        "output_cost_per_token": 3e-7,
        "output_cost_per_character": 7.5e-8,
        "output_cost_per_token_above_128k_tokens": 6e-7,
        "output_cost_per_character_above_128k_tokens": 1.5e-7,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash",
        "deprecation_date": "2025-09-24",
        "supports_tool_choice": true
    },
    "gemini-1.5-flash-001": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 2e-5,
        "input_cost_per_video_per_second": 2e-5,
        "input_cost_per_audio_per_second": 2e-6,
        "input_cost_per_token": 7.5e-8,
        "input_cost_per_character": 1.875e-8,
        "input_cost_per_token_above_128k_tokens": 1e-6,
        "input_cost_per_character_above_128k_tokens": 2.5e-7,
        "input_cost_per_image_above_128k_tokens": 4e-5,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-5,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-6,
        "output_cost_per_token": 3e-7,
        "output_cost_per_character": 7.5e-8,
        "output_cost_per_token_above_128k_tokens": 6e-7,
        "output_cost_per_character_above_128k_tokens": 1.5e-7,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "deprecation_date": "2025-05-24",
        "supports_tool_choice": true
    },
    "gemini-1.5-flash-preview-0514": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 2e-5,
        "input_cost_per_video_per_second": 2e-5,
        "input_cost_per_audio_per_second": 2e-6,
        "input_cost_per_token": 7.5e-8,
        "input_cost_per_character": 1.875e-8,
        "input_cost_per_token_above_128k_tokens": 1e-6,
        "input_cost_per_character_above_128k_tokens": 2.5e-7,
        "input_cost_per_image_above_128k_tokens": 4e-5,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-5,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-6,
        "output_cost_per_token": 4.6875e-9,
        "output_cost_per_character": 1.875e-8,
        "output_cost_per_token_above_128k_tokens": 9.375e-9,
        "output_cost_per_character_above_128k_tokens": 3.75e-8,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_tool_choice": true
    },
    "gemini-pro-experimental": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "input_cost_per_character": 0,
        "output_cost_per_character": 0,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_tool_choice": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental"
    },
    "gemini-flash-experimental": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "input_cost_per_character": 0,
        "output_cost_per_character": 0,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_function_calling": false,
        "supports_tool_choice": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental"
    },
    "gemini-2.5-pro-exp-03-25": {
        "max_tokens": 65536,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 1.25e-6,
        "input_cost_per_token_above_200k_tokens": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "output_cost_per_token_above_200k_tokens": 1.5e-5,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_audio_input": true,
        "supports_video_input": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supported_endpoints": ["/v1/chat/completions", "/v1/completions"],
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini-2.0-pro-exp-02-05": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 1.25e-6,
        "input_cost_per_token_above_200k_tokens": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "output_cost_per_token_above_200k_tokens": 1.5e-5,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_audio_input": true,
        "supports_video_input": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supported_endpoints": ["/v1/chat/completions", "/v1/completions"],
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini-2.0-flash-exp": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text", "image"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supports_tool_choice": true
    },
    "gemini-2.0-flash-001": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 1e-6,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 6e-7,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supports_tool_choice": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text", "image"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini-2.0-flash-thinking-exp": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text", "image"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supports_tool_choice": true
    },
    "gemini-2.0-flash-thinking-exp-01-21": {
        "max_tokens": 65536,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": false,
        "supports_vision": true,
        "supports_response_schema": false,
        "supports_audio_output": false,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text", "image"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supports_tool_choice": true
    },
    "gemini-2.0-flash": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 7e-7,
        "input_cost_per_token": 1e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supports_audio_input": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text", "image"],
        "supports_tool_choice": true,
        "source": "https://ai.google.dev/pricing#2_0flash"
    },
    "gemini-2.0-flash-lite": {
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 50,
        "input_cost_per_audio_token": 7.5e-8,
        "input_cost_per_token": 7.5e-8,
        "output_cost_per_token": 3e-7,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supports_tool_choice": true
    },
    "gemini-2.0-flash-lite-001": {
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 50,
        "input_cost_per_audio_token": 7.5e-8,
        "input_cost_per_token": 7.5e-8,
        "output_cost_per_token": 3e-7,
        "litellm_provider": "vertex_ai-language-models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supports_tool_choice": true
    },
    "gemini/gemini-2.0-pro-exp-02-05": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 2,
        "tpm": 1000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_audio_input": true,
        "supports_video_input": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
    },
    "gemini/gemini-2.0-flash": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 7e-7,
        "input_cost_per_token": 1e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 10000,
        "tpm": 10000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supports_audio_input": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text", "image"],
        "supports_tool_choice": true,
        "source": "https://ai.google.dev/pricing#2_0flash"
    },
    "gemini/gemini-2.0-flash-lite": {
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 50,
        "input_cost_per_audio_token": 7.5e-8,
        "input_cost_per_token": 7.5e-8,
        "output_cost_per_token": 3e-7,
        "litellm_provider": "gemini",
        "mode": "chat",
        "tpm": 4000000,
        "rpm": 4000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supports_tool_choice": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text"],
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite"
    },
    "gemini/gemini-2.0-flash-001": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 7e-7,
        "input_cost_per_token": 1e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 10000,
        "tpm": 10000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "supports_tool_choice": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text", "image"],
        "source": "https://ai.google.dev/pricing#2_0flash"
    },
    "gemini/gemini-2.5-pro-preview-03-25": {
        "max_tokens": 65536,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 7e-7,
        "input_cost_per_token": 1.25e-6,
        "input_cost_per_token_above_200k_tokens": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "output_cost_per_token_above_200k_tokens": 1.5e-5,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 10000,
        "tpm": 10000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "supports_tool_choice": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text"],
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview"
    },
    "gemini/gemini-2.0-flash-exp": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "tpm": 4000000,
        "rpm": 10,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text", "image"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supports_tool_choice": true
    },
    "gemini/gemini-2.0-flash-lite-preview-02-05": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 7.5e-8,
        "input_cost_per_token": 7.5e-8,
        "output_cost_per_token": 3e-7,
        "litellm_provider": "gemini",
        "mode": "chat",
        "rpm": 60000,
        "tpm": 10000000,
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "supports_tool_choice": true,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite"
    },
    "gemini/gemini-2.0-flash-thinking-exp": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "tpm": 4000000,
        "rpm": 10,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text", "image"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supports_tool_choice": true
    },
    "gemini/gemini-2.0-flash-thinking-exp-01-21": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "tpm": 4000000,
        "rpm": 10,
        "supported_modalities": ["text", "image", "audio", "video"],
        "supported_output_modalities": ["text", "image"],
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supports_tool_choice": true
    },
    "gemini/gemma-3-27b-it": {
        "max_tokens": 8192,
        "max_input_tokens": 131072,
        "max_output_tokens": 8192,
        "input_cost_per_image": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_token": 0,
        "input_cost_per_character": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_character": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": false,
        "source": "https://aistudio.google.com",
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-sonnet": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-sonnet@20240229": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-5-sonnet": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-5-sonnet@20240620": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-5-sonnet-v2": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-5-sonnet-v2@20241022": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-7-sonnet@20250219": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "cache_creation_input_token_cost": 3.75e-6,
        "cache_read_input_token_cost": 3e-7,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "deprecation_date": "2025-06-01",
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-haiku": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 1.25e-6,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-haiku@20240307": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 1.25e-6,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-5-haiku": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1e-6,
        "output_cost_per_token": 5e-6,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-5-haiku@20241022": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1e-6,
        "output_cost_per_token": 5e-6,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-opus": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 7.5e-5,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/claude-3-opus@20240229": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 7.5e-5,
        "litellm_provider": "vertex_ai-anthropic_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "vertex_ai/meta/llama-3.2-90b-vision-instruct-maas": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 0,
        "output_cost_per_token": 0,
        "litellm_provider": "vertex_ai-llama_models",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_vision": true,
        "source": "https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas",
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-large@latest": {
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 6e-6,
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-large@2411-001": {
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 6e-6,
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-large-2411": {
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 6e-6,
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-large@2407": {
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 6e-6,
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-nemo@latest": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 1.5e-7,
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-small-2503": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1e-6,
        "output_cost_per_token": 3e-6,
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "vertex_ai/jamba-1.5-mini@001": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "vertex_ai-ai21_models",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "vertex_ai/jamba-1.5-large@001": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 8e-6,
        "litellm_provider": "vertex_ai-ai21_models",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "vertex_ai/jamba-1.5": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "vertex_ai-ai21_models",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "vertex_ai/jamba-1.5-mini": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "vertex_ai-ai21_models",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "vertex_ai/jamba-1.5-large": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 8e-6,
        "litellm_provider": "vertex_ai-ai21_models",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "vertex_ai/mistral-nemo@2407": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 3e-6,
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/codestral@latest": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 6e-7,
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/codestral@2405": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 6e-7,
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "vertex_ai/codestral-2501": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 6e-7,
        "litellm_provider": "vertex_ai-mistral_models",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-002": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "cache_read_input_token_cost": 1.875e-8,
        "cache_creation_input_token_cost": 1e-6,
        "input_cost_per_token": 7.5e-8,
        "input_cost_per_token_above_128k_tokens": 1.5e-7,
        "output_cost_per_token": 3e-7,
        "output_cost_per_token_above_128k_tokens": 6e-7,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "deprecation_date": "2025-09-24",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-001": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "cache_read_input_token_cost": 1.875e-8,
        "cache_creation_input_token_cost": 1e-6,
        "input_cost_per_token": 7.5e-8,
        "input_cost_per_token_above_128k_tokens": 1.5e-7,
        "output_cost_per_token": 3e-7,
        "output_cost_per_token_above_128k_tokens": 6e-7,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "deprecation_date": "2025-05-24",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 7.5e-8,
        "input_cost_per_token_above_128k_tokens": 1.5e-7,
        "output_cost_per_token": 3e-7,
        "output_cost_per_token_above_128k_tokens": 6e-7,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-latest": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 7.5e-8,
        "input_cost_per_token_above_128k_tokens": 1.5e-7,
        "output_cost_per_token": 3e-7,
        "output_cost_per_token_above_128k_tokens": 6e-7,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-8b": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-8b-exp-0924": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-exp-1114": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "metadata": {
            "notes": "Rate limits not documented for gemini-exp-1114. Assuming same as gemini-1.5-pro.",
            "supports_tool_choice": true
        }
    },
    "gemini/gemini-exp-1206": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "metadata": {
            "notes": "Rate limits not documented for gemini-exp-1206. Assuming same as gemini-1.5-pro.",
            "supports_tool_choice": true
        }
    },
    "gemini/gemini-1.5-flash-exp-0827": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 2000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-flash-8b-exp-0827": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 4000,
        "source": "https://ai.google.dev/pricing",
        "supports_tool_choice": true
    },
    "gemini/gemini-1.5-pro": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3.5e-6,
        "input_cost_per_token_above_128k_tokens": 7e-6,
        "output_cost_per_token": 1.05e-5,
        "output_cost_per_token_above_128k_tokens": 2.1e-5,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-1.5-pro-002": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3.5e-6,
        "input_cost_per_token_above_128k_tokens": 7e-6,
        "output_cost_per_token": 1.05e-5,
        "output_cost_per_token_above_128k_tokens": 2.1e-5,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "deprecation_date": "2025-09-24"
    },
    "gemini/gemini-1.5-pro-001": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3.5e-6,
        "input_cost_per_token_above_128k_tokens": 7e-6,
        "output_cost_per_token": 1.05e-5,
        "output_cost_per_token_above_128k_tokens": 2.1e-5,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing",
        "deprecation_date": "2025-05-24"
    },
    "gemini/gemini-1.5-pro-exp-0801": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3.5e-6,
        "input_cost_per_token_above_128k_tokens": 7e-6,
        "output_cost_per_token": 1.05e-5,
        "output_cost_per_token_above_128k_tokens": 2.1e-5,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-1.5-pro-exp-0827": {
        "max_tokens": 8192,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing"
    },
    "gemini/gemini-1.5-pro-latest": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3.5e-6,
        "input_cost_per_token_above_128k_tokens": 7e-6,
        "output_cost_per_token": 1.05e-6,
        "output_cost_per_token_above_128k_tokens": 2.1e-5,
        "litellm_provider": "gemini",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true,
        "supports_response_schema": true,
        "tpm": 4000000,
        "rpm": 1000,
        "source": "https://ai.google.dev/pricing"
    },
    "command-r": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 6e-7,
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "command-r-08-2024": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 6e-7,
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "command-r7b-12-2024": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 3.75e-8,
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "supports_function_calling": true,
        "source": "https://docs.cohere.com/v2/docs/command-r7b",
        "supports_tool_choice": true
    },
    "command-r-plus": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "command-r-plus-08-2024": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "litellm_provider": "cohere_chat",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "openrouter/google/gemini-pro-1.5": {
        "max_tokens": 8192,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 7.5e-6,
        "input_cost_per_image": 0.00265,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "openrouter/google/gemini-2.0-flash-001": {
        "max_tokens": 8192,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_images_per_prompt": 3000,
        "max_videos_per_prompt": 10,
        "max_video_length": 1,
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_pdf_size_mb": 30,
        "input_cost_per_audio_token": 7e-7,
        "input_cost_per_token": 1e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_system_messages": true,
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_response_schema": true,
        "supports_audio_output": true,
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-haiku-20240307": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 1.25e-6,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 264,
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-5-haiku-20241022": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 1e-6,
        "output_cost_per_token": 5e-6,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "tool_use_system_prompt_tokens": 264,
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3.5-sonnet": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3.5-sonnet:beta": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3.7-sonnet": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "input_cost_per_image": 0.0048,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_reasoning": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_assistant_prefill": true,
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3.7-sonnet:beta": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "input_cost_per_image": 0.0048,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_reasoning": true,
        "tool_use_system_prompt_tokens": 159,
        "supports_tool_choice": true
    },
    "openrouter/openai/o1": {
        "max_tokens": 100000,
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "cache_read_input_token_cost": 7.5e-6,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "openrouter/openai/o1-mini": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.2e-5,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_tool_choice": true
    },
    "openrouter/openai/o1-mini-2024-09-12": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.2e-5,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_tool_choice": true
    },
    "openrouter/openai/o1-preview": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_tool_choice": true
    },
    "openrouter/openai/o1-preview-2024-09-12": {
        "max_tokens": 32768,
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 6e-5,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_tool_choice": true
    },
    "openrouter/openai/o3-mini": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 1.1e-6,
        "output_cost_per_token": 4.4e-6,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_tool_choice": true
    },
    "openrouter/openai/o3-mini-high": {
        "max_tokens": 65536,
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "input_cost_per_token": 1.1e-6,
        "output_cost_per_token": 4.4e-6,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_parallel_function_calling": true,
        "supports_vision": false,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-4o": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-6,
        "output_cost_per_token": 1e-5,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "openrouter/openai/gpt-4o-2024-05-13": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "openrouter/anthropic/claude-3-opus": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 7.5e-5,
        "litellm_provider": "openrouter",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 395,
        "supports_tool_choice": true
    },
    "jamba-1.5-mini@001": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "ai21",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "jamba-1.5-large@001": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 8e-6,
        "litellm_provider": "ai21",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "jamba-1.5": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "ai21",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "jamba-1.5-mini": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "ai21",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "jamba-1.5-large": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 8e-6,
        "litellm_provider": "ai21",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "jamba-large-1.6": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 8e-6,
        "litellm_provider": "ai21",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "jamba-mini-1.6": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "ai21",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "ai21.jamba-1-5-large-v1:0": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 8e-6,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "ai21.jamba-1-5-mini-v1:0": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 256000,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 4e-7,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "mistral.mistral-large-2407-v1:0": {
        "max_tokens": 8191,
        "max_input_tokens": 128000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 9e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": true
    },
    "amazon.nova-micro-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 300000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3.5e-8,
        "output_cost_per_token": 1.4e-7,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "us.amazon.nova-micro-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 300000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3.5e-8,
        "output_cost_per_token": 1.4e-7,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "eu.amazon.nova-micro-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 300000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 4.6e-8,
        "output_cost_per_token": 1.84e-7,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "amazon.nova-lite-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 6e-8,
        "output_cost_per_token": 2.4e-7,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "us.amazon.nova-lite-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 6e-8,
        "output_cost_per_token": 2.4e-7,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "eu.amazon.nova-lite-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 7.8e-8,
        "output_cost_per_token": 3.12e-7,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "amazon.nova-pro-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 300000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 8e-7,
        "output_cost_per_token": 3.2e-6,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "us.amazon.nova-pro-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 300000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 8e-7,
        "output_cost_per_token": 3.2e-6,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true
    },
    "eu.amazon.nova-pro-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 300000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.05e-6,
        "output_cost_per_token": 4.2e-6,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "source": "https://aws.amazon.com/bedrock/pricing/"
    },
    "anthropic.claude-3-sonnet-20240229-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_tool_choice": true,
        "metadata": {
            "notes": "Anthropic via Invoke route does not currently support pdf input."
        }
    },
    "anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_reasoning": true,
        "supports_tool_choice": true
    },
    "anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "anthropic.claude-3-haiku-20240307-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 1.25e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "anthropic.claude-3-5-haiku-20241022-v1:0": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 8e-7,
        "output_cost_per_token": 4e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_prompt_caching": true,
        "supports_tool_choice": true
    },
    "anthropic.claude-3-opus-20240229-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 7.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "us.anthropic.claude-3-sonnet-20240229-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "us.anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "us.anthropic.claude-3-7-sonnet-20250219-v1:0": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_reasoning": true
    },
    "us.anthropic.claude-3-haiku-20240307-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 1.25e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "us.anthropic.claude-3-5-haiku-20241022-v1:0": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 8e-7,
        "output_cost_per_token": 4e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "us.anthropic.claude-3-opus-20240229-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 7.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "eu.anthropic.claude-3-sonnet-20240229-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "eu.anthropic.claude-3-5-sonnet-20240620-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "eu.anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_assistant_prefill": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "eu.anthropic.claude-3-haiku-20240307-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 1.25e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_pdf_input": true,
        "supports_tool_choice": true
    },
    "eu.anthropic.claude-3-5-haiku-20241022-v1:0": {
        "max_tokens": 8192,
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 2.5e-7,
        "output_cost_per_token": 1.25e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_assistant_prefill": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "eu.anthropic.claude-3-opus-20240229-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-5,
        "output_cost_per_token": 7.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_response_schema": true,
        "supports_vision": true,
        "supports_tool_choice": true
    },
    "anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/us-east-1/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0455,
        "output_cost_per_second": 0.0455,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.02527,
        "output_cost_per_second": 0.02527,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/eu-central-1/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0415,
        "output_cost_per_second": 0.0415,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.02305,
        "output_cost_per_second": 0.02305,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0175,
        "output_cost_per_second": 0.0175,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.00972,
        "output_cost_per_second": 0.00972,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0175,
        "output_cost_per_second": 0.0175,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.00972,
        "output_cost_per_second": 0.00972,
        "litellm_provider": "bedrock",
        "mode": "chat"
    },
    "anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0455,
        "output_cost_per_second": 0.0455,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.02527,
        "output_cost_per_second": 0.02527,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0415,
        "output_cost_per_second": 0.0415,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.02305,
        "output_cost_per_second": 0.02305,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0175,
        "output_cost_per_second": 0.0175,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.00972,
        "output_cost_per_second": 0.00972,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0175,
        "output_cost_per_second": 0.0175,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.00972,
        "output_cost_per_second": 0.00972,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0455,
        "output_cost_per_second": 0.0455,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.02527,
        "output_cost_per_second": 0.02527,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-6,
        "output_cost_per_token": 2.4e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0415,
        "output_cost_per_second": 0.0415,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.02305,
        "output_cost_per_second": 0.02305,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0175,
        "output_cost_per_second": 0.0175,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.00972,
        "output_cost_per_second": 0.00972,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.0175,
        "output_cost_per_second": 0.0175,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.00972,
        "output_cost_per_second": 0.00972,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-7,
        "output_cost_per_token": 2.4e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-7,
        "output_cost_per_token": 2.4e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.011,
        "output_cost_per_second": 0.011,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.00611,
        "output_cost_per_second": 0.00611,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.011,
        "output_cost_per_second": 0.011,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.00611,
        "output_cost_per_second": 0.00611,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/us-west-2/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 8e-7,
        "output_cost_per_token": 2.4e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 2.23e-6,
        "output_cost_per_token": 7.55e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.01475,
        "output_cost_per_second": 0.01475,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.008194,
        "output_cost_per_second": 0.008194,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_token": 2.48e-6,
        "output_cost_per_token": 8.38e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.01635,
        "output_cost_per_second": 0.01635,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1": {
        "max_tokens": 8191,
        "max_input_tokens": 100000,
        "max_output_tokens": 8191,
        "input_cost_per_second": 0.009083,
        "output_cost_per_second": 0.009083,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "cohere.command-r-plus-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "cohere.command-r-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5e-7,
        "output_cost_per_token": 1.5e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_tool_choice": true
    },
    "us.deepseek.r1-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.35e-6,
        "output_cost_per_token": 5.4e-6,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_reasoning": true,
        "supports_function_calling": false,
        "supports_tool_choice": false
    },
    "meta.llama3-3-70b-instruct-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 7.2e-7,
        "output_cost_per_token": 7.2e-7,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-1-8b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 2.2e-7,
        "output_cost_per_token": 2.2e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-1-8b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 2.2e-7,
        "output_cost_per_token": 2.2e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-1-70b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 9.9e-7,
        "output_cost_per_token": 9.9e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-1-70b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 2048,
        "input_cost_per_token": 9.9e-7,
        "output_cost_per_token": 9.9e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-1-405b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5.32e-6,
        "output_cost_per_token": 1.6e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-1-405b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 5.32e-6,
        "output_cost_per_token": 1.6e-5,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-2-1b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-7,
        "output_cost_per_token": 1e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-2-1b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1e-7,
        "output_cost_per_token": 1e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "eu.meta.llama3-2-1b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.3e-7,
        "output_cost_per_token": 1.3e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-2-3b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 1.5e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "us.meta.llama3-2-3b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.5e-7,
        "output_cost_per_token": 1.5e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "eu.meta.llama3-2-3b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.9e-7,
        "output_cost_per_token": 1.9e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "meta.llama3-2-11b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3.5e-7,
        "output_cost_per_token": 3.5e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "us.meta.llama3-2-11b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 3.5e-7,
        "output_cost_per_token": 3.5e-7,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "meta.llama3-2-90b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 2e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "us.meta.llama3-2-90b-instruct-v1:0": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 2e-6,
        "output_cost_per_token": 2e-6,
        "litellm_provider": "bedrock",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "us.meta.llama3-3-70b-instruct-v1:0": {
        "max_tokens": 4096,
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 7.2e-7,
        "output_cost_per_token": 7.2e-7,
        "litellm_provider": "bedrock_converse",
        "mode": "chat",
        "supports_function_calling": true,
        "supports_tool_choice": false
    },
    "deepinfra/01-ai/Yi-6B-200K": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 1.3e-7,
        "output_cost_per_token": 1.3e-7,
        "litellm_provider": "deepinfra",
        "mode": "completion"
    },
    "deepinfra/01-ai/Yi-34B-200K": {
        "max_tokens": 4096,
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "input_cost_per_token": 6e-7,
        "output_cost_per_token": 6e-7,
        "litellm_provider": "deepinfra",
        "mode": "completion"
    },
    "perplexity/llama-3.1-70b-instruct": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-6,
        "output_cost_per_token": 1e-6,
        "litellm_provider": "perplexity",
        "mode": "chat"
    },
    "perplexity/llama-3.1-8b-instruct": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 2e-7,
        "litellm_provider": "perplexity",
        "mode": "chat"
    },
    "perplexity/llama-3.1-sonar-huge-128k-online": {
        "max_tokens": 127072,
        "max_input_tokens": 127072,
        "max_output_tokens": 127072,
        "input_cost_per_token": 5e-6,
        "output_cost_per_token": 5e-6,
        "litellm_provider": "perplexity",
        "mode": "chat",
        "deprecation_date": "2025-02-22"
    },
    "perplexity/llama-3.1-sonar-large-128k-online": {
        "max_tokens": 127072,
        "max_input_tokens": 127072,
        "max_output_tokens": 127072,
        "input_cost_per_token": 1e-6,
        "output_cost_per_token": 1e-6,
        "litellm_provider": "perplexity",
        "mode": "chat",
        "deprecation_date": "2025-02-22"
    },
    "perplexity/llama-3.1-sonar-large-128k-chat": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 1e-6,
        "output_cost_per_token": 1e-6,
        "litellm_provider": "perplexity",
        "mode": "chat",
        "deprecation_date": "2025-02-22"
    },
    "perplexity/llama-3.1-sonar-small-128k-chat": {
        "max_tokens": 131072,
        "max_input_tokens": 131072,
        "max_output_tokens": 131072,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 2e-7,
        "litellm_provider": "perplexity",
        "mode": "chat",
        "deprecation_date": "2025-02-22"
    },
    "perplexity/llama-3.1-sonar-small-128k-online": {
        "max_tokens": 127072,
        "max_input_tokens": 127072,
        "max_output_tokens": 127072,
        "input_cost_per_token": 2e-7,
        "output_cost_per_token": 2e-7,
        "litellm_provider": "perplexity",
        "mode": "chat",
        "deprecation_date": "2025-02-22"
    },
    "perplexity/sonar": {
        "max_tokens": 127072,
        "max_input_tokens": 127072,
        "max_output_tokens": 127072,
        "input_cost_per_token": 1e-6,
        "output_cost_per_token": 1e-6,
        "litellm_provider": "perplexity",
        "mode": "chat"
    },
    "perplexity/sonar-pro": {
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 8096,
        "input_cost_per_token": 3e-6,
        "output_cost_per_token": 1.5e-5,
        "litellm_provider": "perplexity",
        "mode": "chat"
    },
    "fireworks_ai/accounts/fireworks/models/deepseek-v3": {
        "max_tokens": 8192,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "input_cost_per_token": 9e-7,
        "output_cost_per_token": 9e-7,
        "litellm_provider": "fireworks_ai",
        "mode": "chat",
        "supports_response_schema": true,
        "source": "https://fireworks.ai/pricing",
        "supports_tool_choice": true
    },
    "databricks/databricks-claude-3-7-sonnet": {
        "max_tokens": 200000,
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 2.5e-6,
        "input_dbu_cost_per_token": 3.571e-5,
        "output_cost_per_token": 0.00017857,
        "output_db_cost_per_token": 0.000214286,
        "litellm_provider": "databricks",
        "mode": "chat",
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Claude 3.7 conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_reasoning": true
    },
    "databricks/databricks-meta-llama-3-1-405b-instruct": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 5e-6,
        "input_dbu_cost_per_token": 7.1429e-5,
        "output_cost_per_token": 1.500002e-5,
        "output_db_cost_per_token": 0.000214286,
        "litellm_provider": "databricks",
        "mode": "chat",
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "supports_tool_choice": true
    },
    "databricks/databricks-meta-llama-3-1-70b-instruct": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1.00002e-6,
        "input_dbu_cost_per_token": 1.4286e-5,
        "output_cost_per_token": 2.99999e-6,
        "output_dbu_cost_per_token": 4.2857e-5,
        "litellm_provider": "databricks",
        "mode": "chat",
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "supports_tool_choice": true
    },
    "databricks/databricks-meta-llama-3-3-70b-instruct": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1.00002e-6,
        "input_dbu_cost_per_token": 1.4286e-5,
        "output_cost_per_token": 2.99999e-6,
        "output_dbu_cost_per_token": 4.2857e-5,
        "litellm_provider": "databricks",
        "mode": "chat",
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "supports_tool_choice": true
    },
    "databricks/databricks-meta-llama-3-70b-instruct": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 1.00002e-6,
        "input_dbu_cost_per_token": 1.4286e-5,
        "output_cost_per_token": 2.99999e-6,
        "output_dbu_cost_per_token": 4.2857e-5,
        "litellm_provider": "databricks",
        "mode": "chat",
        "source": "https://www.databricks.com/product/pricing/foundation-model-serving",
        "metadata": {
            "notes": "Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation."
        },
        "supports_tool_choice": true
    },
    "sambanova/Meta-Llama-3.1-70B-Instruct": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 128000,
        "input_cost_per_token": 6e-7,
        "output_cost_per_token": 1.2e-6,
        "litellm_provider": "sambanova",
        "supports_function_calling": true,
        "mode": "chat",
        "supports_tool_choice": true
    },
    "snowflake/mistral-large2": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    },
    "snowflake/reka-flash": {
        "max_tokens": 100000,
        "max_input_tokens": 100000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    },
    "snowflake/jamba-instruct": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    },
    "snowflake/jamba-1.5-mini": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    },
    "snowflake/jamba-1.5-large": {
        "max_tokens": 256000,
        "max_input_tokens": 256000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    },
    "snowflake/llama3.1-8b": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    },
    "snowflake/llama3.1-70b": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    },
    "snowflake/llama3.3-70b": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    },
    "snowflake/llama3.1-405b": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    },
    "snowflake/llama3.2-1b": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    },
    "snowflake/llama3.2-3b": {
        "max_tokens": 128000,
        "max_input_tokens": 128000,
        "max_output_tokens": 8192,
        "litellm_provider": "snowflake",
        "mode": "chat"
    }
}
